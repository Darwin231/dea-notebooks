{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fe3302-8de7-46ea-80d9-f36f011c89b8",
   "metadata": {},
   "source": [
    "# Summer Irrigated Cropping Area (SICA) Processing Pipeline Infra Deisgn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c72b10-bc87-4d39-a92a-597515002741",
   "metadata": {},
   "source": [
    "As the SICA design, the whole processing is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6ccdb-d953-4509-86f8-d2abb39955a1",
   "metadata": {},
   "source": [
    "<div id='svgWrapper'>\n",
    "    <img src='sica_overall.svg'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f808e9d-31f4-4f00-865c-11c120a97025",
   "metadata": {},
   "source": [
    "There are two main steps:\n",
    "1. Summer period datasets to Max NDVI result dataset\n",
    "2. Load whole Max NDVI result datasets and mask, and generate crop area polygon\n",
    "\n",
    "The step 1 is close to the `DEA odc-stats` product processing pattern: `Statistician is a framework of tools for generating statistical summaries of large collections of EO data managed in an ODC instance.` Each processing unit will only focus on a single region.\n",
    "The step 2 is loading data from different data sources, and processing. We should custom an application. We would only have one processing unit.\n",
    "\n",
    "What is more, the step 1 should guarantee all processing unit are job done, then start the step 2. Ideally, we can use Argo DAG or Airflow DAG to make sure this happen. The detail AWS infra would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77407dc0-f162-4282-b3d0-1435184728b3",
   "metadata": {},
   "source": [
    "<div id='svgWrapper'>\n",
    "    <img src='SICA.drawio.svg'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091a2b4-72fd-4284-8a19-827a4d046052",
   "metadata": {},
   "source": [
    "###  Argo/Airflow Step 1\n",
    "\n",
    "It will start several EC2 instances (by DEA EKS API) to run odc-stats Max NDVI plugin (via `odc-stats Docker image`), to create summer period Max NDVI result to each region (e.g. one region example: https://explorer.prod.dea.ga.gov.au/product/ga_ls5t_ard_3/regions/099080). The Max NDVI result will be archived in DEA product AWS S3 bucket.\n",
    "\n",
    "### Argo/Airflow Step 2\n",
    "It will start a `SICA custom application` with `SICA custom Docker image` in a huge EC2 instance. This EC2 should have capacity to load all Max NDVI result which belong to same summer period. Because we are using the Argo/Airflow DAG to confirm the step 2 will be run after step 1, so there is `NO` need to run sanity check to confirm all regions have the Max NDVI result. \n",
    "\n",
    "### Conclusion\n",
    "\n",
    "If we plan to add the SICA product to DEA environment, we have to do following tasks:\n",
    "\n",
    "1. a Max NDVI plugin to odc-stats repo\n",
    "2. custom SICA application can load Max NDVI result, masking by other datasets (e.g. rainfall), and generate the polgyons based on thresholds.\n",
    "3. SICA Bitbucket/Github repo + SICA docker image\n",
    "4. new Argo/Airflow DAG\n",
    "5. AWS resource access control (e.g. interface to load rainfall dataset, new SICA resource group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4d538-020b-44e2-b9bd-06c1ccafd587",
   "metadata": {},
   "source": [
    "### TBD / random ideas from Sai\n",
    "\n",
    "1. the step 2 can change to `each region create its own polgyon, and merge them at last step`. But the current desgin is more like the common solution.\n",
    "2. the step 2 application is more like a huge Jupyter Notebook. We can just create a notebook to finish the step 2 job. But the SICA processing is not fully automatic ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b122ad-1d65-42e9-8965-113c65da5f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
