{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Fractional Cover to the reprocessed FC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 Update:\n",
    "We are running this notebook to check that the reprocessed FC in 02/2022 will improve the alignment of Landsat 8 FC with Landsat 5 and 7 FC. Discrepancies were observed after the first full DEA Collection 3 Landsat Vegetation Fractional Cover processing.\n",
    "\n",
    "\n",
    "- This requires us to recalculate the FC to demonstrate the fix\n",
    "\n",
    "- This notebook will ideally demonstrate that the reprocessed FC aligns better with the field data and with LS 5 and LS 7 FC than the original FC C3 data did. \n",
    "\n",
    "- For reprocessed FC, take coefficients from here: https://github.com/GeoscienceAustralia/dea-config/blob/master/prod/services/alchemist/ga_ls_fc_3/ga_ls_fc_3.alchemist.yaml \n",
    "\n",
    "- the updated FC coefficients are applied after the first FC calculation. The first FC calculation is performed using the existing FC module. band * scale + interception will be good enough, e.g. bs * 0.9499 + 2.45 \n",
    "\n",
    " See https://github.com/GeoscienceAustralia/fc/pull/48/files\n",
    "extra_coefficients:\n",
    " \n",
    " bs:\n",
    " - 2.45\n",
    "- 0.9499\n",
    "\n",
    "pv:\n",
    "- 2.77\n",
    "- 0.9481\n",
    "\n",
    "npv:\n",
    "- -0.73\n",
    "- 0.9578 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find field data; this field data is the Star transects from [the JRSRP geoserver wfs service](https://field-geoserver.jrsrp.com/geoserver/aus/wfs?service=wfs&version=1.1.0&request=GetFeature&typeNames=aus:star_transects&outputFormat=csv) which can be visualised through [the TERN Landscapes-JRSRP Field Data Portal](https://field.jrsrp.com/) and is available as a csv\n",
    "- Load corresponding surface reflectance from datacube or save file\n",
    "- Calculate FC and compare to field data using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "\n",
    "To run this analysis, choose the satellite you are comparing to the field data in the next cell by uncommenting its name \n",
    "e.g. `sensor_name = 'Landsat 8'`\n",
    "Then run all the cells in the notebook, starting with the \"Define sensor name\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose which sensor we are comparing to the field data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import datacube\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec \n",
    "from shapely import wkt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "import warnings\n",
    "\n",
    "from datacube.utils.geometry import CRS, Geometry, GeoBox\n",
    "from datacube.testutils.io import native_geobox, native_load\n",
    "from odc.algo.io import load_with_native_transform\n",
    "from odc.algo._masking import _xr_fuse, _fuse_mean_np\n",
    "from odc.stats.utils import fuse_ds\n",
    "from odc.algo import keep_good_only\n",
    "from functools import partial\n",
    "from itertools import groupby\n",
    "\n",
    "# instantiate a datacube\n",
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to compute the fractional covers as viewed by the satellite for the site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the fractional covers as viewed by the satellite for the site\n",
    "# Required a site properties object\n",
    "\n",
    "def fractionalCoverSatView(siteProperties):\n",
    "    '''equations to calculate fractional cover from the csv data'''\n",
    "    nTotal = siteProperties['num_points']\n",
    "    \n",
    "    # Canopy Layer\n",
    "    nCanopyBranch = siteProperties['over_b'] * nTotal / 100.0\n",
    "    nCanopyDead = siteProperties['over_d'] * nTotal / 100.0\n",
    "    nCanopyGreen = siteProperties['over_g'] * nTotal / 100.0\n",
    "    \n",
    "    # Midstory Layer\n",
    "    nMidBranch = siteProperties['mid_b'] * nTotal / 100.0\n",
    "    nMidGreen = siteProperties['mid_g'] * nTotal / 100.0\n",
    "    nMidDead = siteProperties['mid_d'] * nTotal / 100.0\n",
    "    \n",
    "    # Ground Layer\n",
    "    nGroundDeadLitter = (siteProperties['dead'] + siteProperties['litter']) * nTotal / 100.0\n",
    "    nGroundCrustDistRock = (siteProperties['crust'] + siteProperties['dist'] + siteProperties['rock']) * nTotal / 100.0\n",
    "    nGroundGreen = siteProperties['green'] * nTotal / 100.0\n",
    "    nGroundCrypto = siteProperties['crypto'] * nTotal / 100.0\n",
    "    \n",
    "    # Work out the canopy elements as viewed from above\n",
    "    canopyFoliageProjectiveCover = nCanopyGreen / (nTotal - nCanopyBranch)\n",
    "    canopyDeadProjectiveCover = nCanopyDead / (nTotal - nCanopyBranch)\n",
    "    canopyBranchProjectiveCover = nCanopyBranch / nTotal * (1.0 - canopyFoliageProjectiveCover - canopyDeadProjectiveCover)\n",
    "    canopyPlantProjectiveCover = (nCanopyGreen+nCanopyDead + nCanopyBranch) / nTotal\n",
    "    \n",
    "    # Work out the midstorey fractions\n",
    "    midFoliageProjectiveCover = nMidGreen / nTotal\n",
    "    midDeadProjectiveCover = nMidDead / nTotal\n",
    "    midBranchProjectiveCover = nMidBranch / nTotal\n",
    "    midPlantProjectiveCover = (nMidGreen + nMidDead + nMidBranch) / nTotal\n",
    "    \n",
    "    # Work out the midstorey  elements as viewed by the satellite using a gap fraction method\n",
    "    satMidFoliageProjectiveCover = midFoliageProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidDeadProjectiveCover = midDeadProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidBranchProjectiveCover = midBranchProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    satMidPlantProjectiveCover = midPlantProjectiveCover * (1 - canopyPlantProjectiveCover)\n",
    "    \n",
    "    # Work out the groundcover fractions as seen by the observer\n",
    "    groundPVCover = nGroundGreen / nTotal\n",
    "    groundNPVCover = nGroundDeadLitter / nTotal\n",
    "    groundBareCover = nGroundCrustDistRock / nTotal\n",
    "    groundCryptoCover = nGroundCrypto / nTotal\n",
    "    groundTotalCover = (nGroundGreen + nGroundDeadLitter + nGroundCrustDistRock) / nTotal\n",
    "    \n",
    "    # Work out the ground cover proportions as seen by the satellite\n",
    "    satGroundPVCover = groundPVCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundNPVCover = groundNPVCover * ( 1- midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundBareCover = groundBareCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundCryptoCover = groundCryptoCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    satGroundTotalCover = groundTotalCover * (1 - midPlantProjectiveCover) * (1 - canopyPlantProjectiveCover)\n",
    "    \n",
    "    # Final total covers calculated using gap probabilities through all layers\n",
    "    totalPVCover = canopyFoliageProjectiveCover + satMidFoliageProjectiveCover + satGroundPVCover\n",
    "    totalNPVCover = canopyDeadProjectiveCover + canopyBranchProjectiveCover + satMidDeadProjectiveCover + satMidBranchProjectiveCover + satGroundNPVCover\n",
    "    totalBareCover = satGroundBareCover\n",
    "    totalCryptoCover = satGroundCryptoCover\n",
    "    \n",
    "    return np.array([totalPVCover,totalNPVCover+totalCryptoCover,totalBareCover])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is to load and mask FC in native projection\n",
    "def _native_tr(xx):\n",
    "    \"\"\"\n",
    "    Loads data in its native projection. It performs the following:\n",
    "\n",
    "    1. Load all fc and WOfS bands\n",
    "    2. Set the high terrain slope flag to 0\n",
    "    3. Set all pixels that are not clear and dry to NODATA\n",
    "    4. Calculate the clear wet pixels\n",
    "    5. Drop the WOfS band\n",
    "    \"\"\"\n",
    "    water = xx.water & 0b1110_1111\n",
    "    dry = water == 0\n",
    "    xx = xx.drop_vars([\"water\"])\n",
    "    xx = keep_good_only(xx, dry, nodata=255)\n",
    "    return xx\n",
    "\n",
    "def _fuser(xx):\n",
    "    xx = _xr_fuse(xx, partial(_fuse_mean_np, nodata=255), '')\n",
    "    return xx\n",
    "\n",
    "def filter(groups, size=2):\n",
    "    for _, ds_group in groups:\n",
    "        ds_group = tuple(ds_group)\n",
    "        if len(ds_group) == size:\n",
    "            yield ds_group\n",
    "\n",
    "def ds_align(datasets):\n",
    "    datasets.sort(key=lambda ds: (ds.center_time, ds.metadata.region_code))\n",
    "    paired_dss = groupby(datasets, key=lambda ds: (ds.center_time, ds.metadata.region_code))\n",
    "    paired_dss = filter(paired_dss)\n",
    "    map_fuse_func = lambda x: fuse_ds(*x)\n",
    "    dss = map(map_fuse_func, paired_dss)\n",
    "    return dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fc(query, platform=\"landsat-8\", coef=None, nday=True):\n",
    "    \"\"\"\n",
    "        Load FC by query and platform\n",
    "        inputs:\n",
    "            query: query dict to dc.find_datasets\n",
    "            platfrom: to load data by different sensor\n",
    "            coef: the regression coefficients applied to LS8\n",
    "            nday: average over the days (True) or select the closest day (False)\n",
    "        outputs:\n",
    "            a numpy array of FC\n",
    "    \"\"\"\n",
    "    print('query time', query.obs_time)\n",
    "    c3_query = {'geopolygon': Geometry(query.query_poly, crs=CRS('EPSG:3577'))}\n",
    "    c3_query['time'] = (query.start_time, query.end_time)\n",
    "    geobox = GeoBox.from_geopolygon(c3_query['geopolygon'], (-30, 30), crs='epsg:3577')\n",
    "    c3_ls8_datasets = dc.find_datasets(product=['ga_ls_fc_3', 'ga_ls_wo_3'], **c3_query,\n",
    "                 platform=platform, group_by=\"solar_day\")\n",
    "    c3_ls8_datasets = ds_align(c3_ls8_datasets)\n",
    "    try:\n",
    "        c3_ls8 = load_with_native_transform(\n",
    "            c3_ls8_datasets,\n",
    "            bands=[\"water\", \"pv\", \"bs\", \"npv\"],\n",
    "            geobox=geobox,\n",
    "            native_transform=_native_tr,\n",
    "            fuser=_fuser,\n",
    "            groupby=\"solar_day\",\n",
    "            resampling=\"bilinear\",\n",
    "            chunks={'y': -1, 'x': -1},\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return np.array([np.nan]*3)\n",
    "    c3_ls8 = c3_ls8.where(c3_ls8 < 255)\n",
    "    if coef is not None:\n",
    "        for var in c3_ls8.data_vars:\n",
    "            print(f\"apply coef {coef[var]} on {var}\")\n",
    "            c3_ls8[var] = (c3_ls8[var] * coef[var][1] + coef[var][0]).clip(min=0)\n",
    "    if not nday:\n",
    "        c3_ls8 = c3_ls8.isel(dict(spec=np.argmin(np.abs(np.datetime64(query.obs_time) - c3_ls8.solar_day.data))))\n",
    "    return c3_ls8.drop('spatial_ref').mean().compute().to_array().data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3 Reprocessing coefficients for updated FC C3 computation for Landsat 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra fc coefficients updated as per https://github.com/GeoscienceAustralia/dea-config/blob/master/prod/services/alchemist/ga_ls_fc_3/ga_ls_fc_3.alchemist.yaml . Ran into a namespace issue, do not call these' fc_coefficients'\n",
    "extra_coefficients = {'bs':[2.45, 0.9499],\n",
    "                   'pv':[2.77, 0.9481],\n",
    "                   'npv':[-0.73, 0.9578]}                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load field data in from csv -modify here to get all rows of data when not testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load star_transects field data \n",
    "field = pd.read_csv('star_transects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read field data from file into 'field' dataframe and create a geopandas geodataframe of all the points\n",
    "field = field.rename(columns={'geom': 'geometry'})\n",
    "field['geometry'] = field.geometry.apply(wkt.loads)\n",
    "field = gpd.GeoDataFrame(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field data comes in in WGS84\n",
    "field.crs = {'init': 'EPSG:4326'}\n",
    "#transform to Australian Albers Equal Area \n",
    "field = field.to_crs({'init':'EPSG:3577'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by date - get dates later than the first observation of the satellite\n",
    "field['obs_time'] = pd.to_datetime(field.obs_time)\n",
    "field = field.loc[field['obs_time'] > np.datetime64('2013-06-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate field measured fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate field measured fractions\n",
    "field = field.merge(\n",
    "    field.apply(fractionalCoverSatView, axis=1, result_type= 'expand').rename(\n",
    "        columns = {0:'total_pv',1:'total_npv',2:'total_bs'}),\n",
    "    left_index=True, right_index=True)\n",
    "field = field[field.apply(lambda x: x['total_pv']+x['total_npv']+x['total_bs'], axis=1) >0.95]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate fractional cover for satellite observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = pd.DataFrame({'obs_time': field.obs_time,\n",
    "                        'start_time': field.obs_time - timedelta(days=15),\n",
    "                           'end_time':field.obs_time + timedelta(days=15),\n",
    "                           'query_poly': field.geometry.buffer(50, cap_style=3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc_loaded_ls7 = query.apply(load_fc, platform='landsat-7', nday=False, axis=1, result_type= 'expand')\n",
    "fc_loaded_ls7 = fc_loaded_ls7.rename(columns={0: 'pv_ls7', 1: 'bs_ls7', 2: 'npv_ls7'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc_loaded = query.apply(load_fc, nday=False, axis=1, result_type= 'expand')\n",
    "fc_loaded = fc_loaded.rename(columns={0: 'pv_o', 1: 'bs_o', 2: 'npv_o'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc_loaded_with_coef = query.apply(load_fc, nday=False, coef=extra_coefficients, axis=1, result_type= 'expand')\n",
    "fc_loaded_with_coef = fc_loaded_with_coef.rename(columns={0: 'pv', 1: 'bs', 2: 'npv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# join everything into a huge dataframe\n",
    "# not really necessary other than recycling the plot function\n",
    "field = field.merge(fc_loaded_with_coef, how = 'inner', left_index=True, right_index=True)\n",
    "field = field.merge(fc_loaded, how = 'inner', left_index=True, right_index=True)\n",
    "field = field.merge(fc_loaded_ls7, how = 'inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  `field` is a massive geodataframe full of results which we can write to a shapefile to preserve our results\n",
    "Within this GeoDataFrame, the columns `bs, pv, npv` are from LS8 FC after applying the treatment,\n",
    "`bs_o, pv_o, npv_o` are from LS8 FC before applying the treatment, `bs_ls7, pv_ls7, npv_ls7` are from LS7 FC\n",
    "\n",
    "The columns `total_pv, total_npc, total_bs` are calculated from the field-measured fractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.to_file('field_reprocessed_fc_%s.shp'%''.join(sensor_name.split()))\n",
    "field = gpd.read_file('field_reprocessed_fc_%s.shp'%''.join(sensor_name.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot field and satellite data comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(field_all, title=None):\n",
    "    bands = ['pv','npv','bs']\n",
    "    columns = ['total_%s'%s for s in bands] + bands\n",
    "    field_ls8 = field_all[columns][(field_all[bands]>=0.).all(axis=1)]\n",
    "    columns = ['total_%s'%s for s in bands] + ['%s_o'%s for s in bands]\n",
    "    field_ls8_o =  field_all[columns][(field_all[['%s_o'%s for s in bands]]>=0.).all(axis=1)]\n",
    "    columns = ['total_%s'%s for s in bands] + ['%s_ls7'%s for s in bands]\n",
    "    field_ls7 =  field_all[columns][(field_all[['%s_ls7'%s for s in bands]]>=0.).all(axis=1)]\n",
    "    print(\"# of validation points:\", len(field_all), '\\n')\n",
    "    \n",
    "    regr = linear_model.RANSACRegressor() #create linear regression model, use ransac to factor in the noises\n",
    "    \n",
    "    #set up plot for results\n",
    "    f = plt.figure(figsize=(20,20))\n",
    "    gs = gridspec.GridSpec(2,2)\n",
    "    xedges=yedges=list(np.arange(0,102,2))\n",
    "    X, Y = np.meshgrid(xedges, yedges)\n",
    "    cmname='YlGnBu'\n",
    "    if title: plt.suptitle(title)\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    field.plot(markersize=10, ax= ax1, color='r')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_title('Field Sites')\n",
    "    ax1.text(0.05, 0.05, \"%d points\"%len(field), transform=ax1.transAxes)\n",
    "    \n",
    "    for band_id, band in enumerate(bands): \n",
    "\n",
    "        sr = spearmanr((field_ls8['total_%s'%band].to_numpy() * 100).reshape(-1, 1),\n",
    "                 (field_ls8[band].to_numpy()).reshape(-1, 1))[0]\n",
    "        rmse = np.sqrt(mean_squared_error((field_ls8['total_%s'%band].to_numpy() * 100).reshape(-1, 1),\n",
    "                 (field_ls8[band].to_numpy()).reshape(-1, 1)))\n",
    "        \n",
    "        ax1 = plt.subplot(gs[band_id+1])\n",
    "        ax1.scatter(field_ls8['total_%s'%band].to_numpy() * 100, field_ls8[band].to_numpy(), s=20,\n",
    "                    facecolors='darkorange', edgecolor='face', alpha=0.5, label='After')\n",
    "        ax1.scatter(field_ls8_o['total_%s'%band].to_numpy() * 100, field_ls8_o[\"%s_o\"%band].to_numpy(), s=20,\n",
    "                    facecolors='SteelBlue', edgecolor='face', marker='d', alpha=0.5, label='Before')\n",
    "        ax1.scatter(field_ls7['total_%s'%band].to_numpy() * 100, field_ls7[\"%s_ls7\"%band].to_numpy(), s=20,\n",
    "                    facecolors='brown', edgecolor='face', marker='s', alpha=0.5, label='LS7')\n",
    "        ax1.set_title(band)\n",
    "        \n",
    "        ax1.plot([0,100],[0,100])\n",
    "        regr.fit((field_ls8['total_%s'%band].to_numpy() * 100).reshape(-1, 1),\n",
    "                 (field_ls8[band].to_numpy()).reshape(-1, 1)) # plot the linear regression fit\n",
    "        ax1.plot(np.arange(0,110,10), regr.predict(np.arange(0,110,10)[:,np.newaxis]), \n",
    "                 '--', linewidth=2, color='red', label='After')\n",
    "        regr.fit((field_ls8_o['total_%s'%band].to_numpy() * 100).reshape(-1, 1), \n",
    "                 (field_ls8_o[\"%s_o\"%band].to_numpy()).reshape(-1, 1)) # plot the linear regression fit\n",
    "        ax1.plot(np.arange(0,110,10), regr.predict(np.arange(0,110,10)[:,np.newaxis]),\n",
    "                 '--', linewidth=2, color='blue', label='Before')      \n",
    "        regr.fit((field_ls7['total_%s'%band].to_numpy() * 100).reshape(-1, 1), \n",
    "                 (field_ls7[\"%s_ls7\"%band].to_numpy()).reshape(-1, 1)) # plot the linear regression fit\n",
    "        ax1.plot(np.arange(0,110,10), regr.predict(np.arange(0,110,10)[:,np.newaxis]),\n",
    "                 '--', linewidth=2, color='black', label='LS7')    \n",
    "        ax1.text(5, 95, 'spearmanr = {0:.2f}'.format(sr))\n",
    "        ax1.text(5, 90, 'rmse = {0:.2f}'.format(rmse))\n",
    "        ax1.set_xlabel('Field Measured')\n",
    "        ax1.set_ylabel('%s FC'%title.upper())\n",
    "        ax1.set_xlim((0,100))\n",
    "        ax1.set_ylim((0,100))\n",
    "    plt.tight_layout()\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    f.legend(handles, labels, loc='upper left', ncol=2)\n",
    "    \n",
    "    f.savefig('validate_reprocessed_%s.png'%''.join(title.split()),  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(field, title='LS8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
