{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: this notebook was recently moved into this folder.\n",
    "\n",
    "**Updating required for links etc**\n",
    "\n",
    "**Modified scripts from dea-notebooks also moved into this folder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and run analysis on multiple polygons <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with both the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Many users need to run analyses on their own areas of interest. \n",
    "A common use case involves running the same analysis across multiple polygons in a vector file (e.g. ESRI Shapefile or GeoJSON). \n",
    "This notebook will demonstrate how to use a vector file and the Open Data Cube to extract satellite data from Digital Earth Australia corresponding to individual polygon geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "If we have a vector file containing multiple polygons, we can use the python package [geopandas](https://geopandas.org/) to open it as a `GeoDataFrame`. \n",
    "We can then iterate through each geometry and extract satellite data corresponding with the extent of each geometry. \n",
    "Further anlaysis can then be conducted on each resulting `xarray.Dataset`.\n",
    "\n",
    "We can retrieve data for each polygon, perform an analysis like calculating NDVI and plot the data.\n",
    "\n",
    "1. First we open the vector file as a `geopandas.GeoDataFrame`\n",
    "2. Iterate through each polygon in the `GeoDataFrame`, and extract satellite data from DEA\n",
    "3. Calculate NDVI as an example analysis on one of the extracted satellite timeseries\n",
    "4. Plot NDVI for the polygon extent\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Please note the use of `datacube.utils` package `geometry`: \n",
    "this is important for saving the coordinate reference system of the incoming shapefile in a format that the Digital Earth Australia query can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "/env/lib/python3.6/site-packages/datacube/storage/masking.py:8: DeprecationWarning: datacube.storage.masking has moved to datacube.utils.masking\n",
      "  category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "\n",
    "import datacube\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.crs\n",
    "import rioxarray\n",
    "from datacube.utils import geometry\n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import datacube.utils.cog\n",
    "\n",
    "# import geopandas as gpd\n",
    "import ipyleaflet\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import odc.ui\n",
    "import rasterio.features\n",
    "import rioxarray\n",
    "import skimage.color as colour\n",
    "import skimage.io\n",
    "import sklearn.metrics\n",
    "import xarray as xr\n",
    "\n",
    "# import sys\n",
    "# import datacube\n",
    "from datacube.storage.masking import make_mask\n",
    "\n",
    "# from dea_datahandling import load_ard\n",
    "from dea_bandindices import calculate_indices\n",
    "from CP_dea_coastaltools import tidal_stats, tidal_tag\n",
    "from dea_dask import create_local_dask_cluster\n",
    "from dea_datahandling import array_to_geotiff, load_ard\n",
    "from CP_dea_plotting import display_map, map_shapefile, rgb\n",
    "from dea_spatialtools import xr_rasterize\n",
    "from dea_temporaltools import time_buffer\n",
    "from IPython.display import display\n",
    "from odc.ui import with_ui_cbk\n",
    "from shapely.geometry import shape, Polygon\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Connect to the datacube database to enable loading Digital Earth Australia data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/drivers/postgres/_connections.py:87: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44441</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/cp/proxy/8787/status' target='_blank'>/user/cp/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>15</li>\n",
       "  <li><b>Memory: </b>125.85 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44441' processes=1 threads=15, memory=125.85 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc = datacube.Datacube(app=\"Analyse_multiple_polygons\")\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Load predetermined polygons and select a region of interest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dev/dea-notebooks/Claire\n"
     ]
    }
   ],
   "source": [
    "## User defines path to polygon vector file, file name and \n",
    "## the column name for unique integer identifiers for each vector object.\n",
    "%cd '/home/jovyan/dev/dea-notebooks/Claire/'\n",
    "vector_file = \"QISMCQ_polygons.shp\"\n",
    "attribute_col = \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intertidal mangroves and other trees & shrubs'\n",
      " 'Intertidal grass-herb-sedge-other succulent' 'Intertidal seagrass']\n",
      "The attribute values for each class are as follows: [['Intertidal mangroves and other trees & shrubs', 0], ['Intertidal grass-herb-sedge-other succulent', 1], ['Intertidal seagrass', 2]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0147ce3acd8b4a9da4d6794247738fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-23.952787292499956, 151.32995860600005], controls=(ZoomControl(options=['position', 'zoom_in_textâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the polygon vector file\n",
    "gdf_master = gpd.read_file(vector_file)\n",
    "\n",
    "# Set the crs to match the imagery data retrieved\n",
    "gdf_master.to_crs(epsg=3577, inplace=True)\n",
    "\n",
    "# #  View the unique classes\n",
    "# print(gdf_master[\"BRD_HAB\"].unique())\n",
    "\n",
    "#  Drop unrequired classes\n",
    "gdf_master = gdf_master.drop(\n",
    "    gdf_master[\n",
    "        (gdf_master.BRD_HAB == 'Subtidal consolidated substrate')\n",
    "        | (gdf_master.BRD_HAB == 'Subtidal coral')\n",
    "        | (gdf_master.BRD_HAB == 'Subtidal unconsolidated substrate') \n",
    "        | (gdf_master.BRD_HAB == 'Subtidal seagrass')\n",
    "        | (gdf_master.BRD_HAB == 'Subtidal algae')        \n",
    "        | (gdf_master.BRD_HAB == 'Intertidal consolidated substrate')\n",
    "        | (gdf_master.BRD_HAB == 'Intertidal coral')\n",
    "        | (gdf_master.BRD_HAB == \"Intertidal unconsolidated substrate\")\n",
    "        | (gdf_master.BRD_HAB == 'Intertidal algae')\n",
    "#         | (gdf_master.BRD_HAB == 'Intertidal mangroves and other trees & shrubs')\n",
    "#         | (gdf_master.BRD_HAB == 'Intertidal grass-herb-sedge-other succulent')\n",
    "#         | (gdf_master.BRD_HAB == 'Intertidal seagrass')        \n",
    "    ].index\n",
    ")\n",
    "\n",
    "#  Reset the index of the gdf to infill dropped values\n",
    "gdf_master.reset_index(inplace=True)\n",
    "\n",
    "#  Check that correct classes remain\n",
    "print(gdf_master[\"BRD_HAB\"].unique())\n",
    "\n",
    "# Attribute each class with an integer value\n",
    "val = (gdf_master[\"BRD_HAB\"].unique()).tolist()\n",
    "\n",
    "num_list = []\n",
    "attr_key = []\n",
    "\n",
    "d = 0\n",
    "for x in range(len(gdf_master)):\n",
    "    for d in range(len(val)):\n",
    "        if gdf_master[\"BRD_HAB\"].values[x] == str(val[d]):\n",
    "            num_list.append(d)\n",
    "        # Create a key to interpret the integer attribute for each class\n",
    "        for y in num_list:\n",
    "            if y not in attr_key:\n",
    "                attr_key.append(y)\n",
    "\n",
    "val = [[el] for el in val]\n",
    "for x in attr_key:\n",
    "    val[x].append(attr_key[x])\n",
    "\n",
    "\n",
    "print(\"The attribute values for each class are as follows: \" + str(val))\n",
    "\n",
    "# Update the geodataframe of vector polygons with the integer attribution for each class\n",
    "gdf_master[\"id\"] = num_list\n",
    "\n",
    "# Map the shapefiles from imported vector set\n",
    "roi = map_shapefile(gdf_master, attribute=attribute_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give a name to your roi for file saving\n",
    "name = 'seagrass_substrates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This selection includes  15  individual polygons\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcbe36dc400>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "After identifying an analysis region of interest(roi) on the map,\n",
    "intersect the roi with the master polygon gdf from which imagery \n",
    "will be extracted. Note that when multiple areas are drawn on the\n",
    "map above, it is the final roi that is used for analysis in the \n",
    "following cells\n",
    "'''\n",
    "\n",
    "##  Form a shapely polygon from the coordinates defined by the user on the map\n",
    "polygon_roi = Polygon(roi[-1]['geometry']['coordinates'][0])\n",
    "\n",
    "##  Generate a new geodataframe containing the user defined polygon geometry\n",
    "newdf = gpd.GeoDataFrame(gpd.GeoSeries(polygon_roi), columns=['geometry'], crs='EPSG:4326')\n",
    "newdf = newdf.to_crs(gdf_master.crs)\n",
    "\n",
    "##  Intersect the user-defined region of interest with the master\n",
    "##  to create the working gdf from which imagery will be extracted\n",
    "gdf = gpd.overlay(gdf_master, newdf, how='intersection')\n",
    "print('This selection includes ', len(gdf), ' individual polygons')\n",
    "gdf.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load imagery for the region of interest\n",
    "\n",
    "*user to define time-period of interest in the query*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1/15\n",
      "Intertidal grass-herb-sedge-other succulent\n",
      "0\n",
      "index                                                      1864\n",
      "OBJECTID                                                   1865\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                      1\n",
      "DOM_LABEL                   Grass-herb-sedge (undifferentiated)\n",
      "CO_TYPES                                                   None\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB             Intertidal grass-herb-sedge-other succulent\n",
      "Shape_Leng                                            0.0201395\n",
      "Shape_Area                                          1.16055e-05\n",
      "id                                                            1\n",
      "geometry      POLYGON ((1958397.354112937 -2749402.393490809...\n",
      "Name: 0, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 12 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 12 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.08\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (18, 17)\n",
      "1 0\n",
      "----------------------\n",
      "Feature: 2/15\n",
      "Intertidal seagrass\n",
      "1\n",
      "index                                                      3524\n",
      "OBJECTID                                                   3525\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                   None\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                            0.0135562\n",
      "Shape_Area                                          2.12611e-06\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1958825.350369396 -2749952.144247592...\n",
      "Name: 1, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 12 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 12 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.55, -24.08\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (20, 10)\n",
      "2 1\n",
      "----------------------\n",
      "Feature: 3/15\n",
      "Intertidal seagrass\n",
      "2\n",
      "index                                                      3626\n",
      "OBJECTID                                                   3627\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                           0.00421809\n",
      "Shape_Area                                          5.19227e-07\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1958193.132650619 -2750371.111629014...\n",
      "Name: 2, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 12 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 12 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.09\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (5, 5)\n",
      "2 2\n",
      "----------------------\n",
      "Feature: 4/15\n",
      "Intertidal seagrass\n",
      "3\n",
      "index                                                      3627\n",
      "OBJECTID                                                   3628\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                            0.0134842\n",
      "Shape_Area                                          1.95035e-06\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1958553.481084442 -2750249.449632833...\n",
      "Name: 3, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 10 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 10 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.09\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (8, 19)\n",
      "2 3\n",
      "----------------------\n",
      "Feature: 5/15\n",
      "Intertidal seagrass\n",
      "4\n",
      "index                                                      3629\n",
      "OBJECTID                                                   3630\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                              0.12153\n",
      "Shape_Area                                           0.00012066\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1958993.382995301 -2750346.716013419...\n",
      "Name: 4, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 11 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 11 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.55, -24.08\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (24, 7)\n",
      "2 4\n",
      "----------------------\n",
      "Feature: 6/15\n",
      "Intertidal seagrass\n",
      "5\n",
      "index                                                      3631\n",
      "OBJECTID                                                   3632\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                           0.00319241\n",
      "Shape_Area                                          4.05578e-07\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1957837.279614981 -2749002.0619639, ...\n",
      "Name: 5, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 11 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 11 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (6, 4)\n",
      "2 5\n",
      "----------------------\n",
      "Feature: 7/15\n",
      "Intertidal seagrass\n",
      "6\n",
      "index                                                      3634\n",
      "OBJECTID                                                   3635\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                           0.00476337\n",
      "Shape_Area                                          5.89287e-07\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1957283.586143881 -2748618.545967553...\n",
      "Name: 6, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 7 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 7 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.53, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (7, 7)\n",
      "2 6\n",
      "----------------------\n",
      "Feature: 8/15\n",
      "Intertidal seagrass\n",
      "7\n",
      "index                                                      3635\n",
      "OBJECTID                                                   3636\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                            0.0207083\n",
      "Shape_Area                                          2.32874e-05\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1958075.043255965 -2748485.631927858...\n",
      "Name: 7, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 8 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 8 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.53, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (21, 26)\n",
      "2 7\n",
      "----------------------\n",
      "Feature: 9/15\n",
      "Intertidal seagrass\n",
      "8\n",
      "index                                                      3636\n",
      "OBJECTID                                                   3637\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                            0.0334706\n",
      "Shape_Area                                          3.56059e-05\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1958509.564606643 -2748989.883640794...\n",
      "Name: 8, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 8 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 8 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (39, 40)\n",
      "2 8\n",
      "----------------------\n",
      "Feature: 10/15\n",
      "Intertidal seagrass\n",
      "9\n",
      "index                                                      3644\n",
      "OBJECTID                                                   3645\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                            0.0711887\n",
      "Shape_Area                                          0.000113815\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1958846.1048125 -2748575.301096613, ...\n",
      "Name: 9, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 9 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 9 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (9, 14)\n",
      "2 9\n",
      "----------------------\n",
      "Feature: 11/15\n",
      "Intertidal seagrass\n",
      "10\n",
      "index                                                      3710\n",
      "OBJECTID                                                   3711\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                     12\n",
      "DOM_LABEL                                 Strap (wide) seagrass\n",
      "CO_TYPES                                                     13\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB                                     Intertidal seagrass\n",
      "Shape_Leng                                            0.0130331\n",
      "Shape_Area                                           1.0601e-05\n",
      "id                                                            2\n",
      "geometry      POLYGON ((1957932.100818936 -2750037.3021506, ...\n",
      "Name: 10, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 9 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 9 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.09\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (11, 18)\n",
      "2 10\n",
      "----------------------\n",
      "Feature: 12/15\n",
      "Intertidal mangroves and other trees & shrubs\n",
      "11\n",
      "index                                                      9437\n",
      "OBJECTID                                                   9438\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                      5\n",
      "DOM_LABEL          Mangroves and other trees (undifferentiated)\n",
      "CO_TYPES                                                   None\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB           Intertidal mangroves and other trees & shrubs\n",
      "Shape_Leng                                           0.00571195\n",
      "Shape_Area                                          2.33084e-06\n",
      "id                                                            0\n",
      "geometry      POLYGON ((1957462.825780243 -2750051.303161786...\n",
      "Name: 11, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 9 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 9 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.53, -24.08\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (9, 7)\n",
      "0 11\n",
      "----------------------\n",
      "Feature: 13/15\n",
      "Intertidal mangroves and other trees & shrubs\n",
      "12\n",
      "index                                                      9443\n",
      "OBJECTID                                                   9444\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                      5\n",
      "DOM_LABEL          Mangroves and other trees (undifferentiated)\n",
      "CO_TYPES                                                   None\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB           Intertidal mangroves and other trees & shrubs\n",
      "Shape_Leng                                            0.0566064\n",
      "Shape_Area                                          6.84034e-05\n",
      "id                                                            0\n",
      "geometry      POLYGON ((1958853.387807065 -2749686.697445208...\n",
      "Name: 12, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 10 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 10 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.08\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (39, 37)\n",
      "0 12\n",
      "----------------------\n",
      "13 is a multipolygon and is excluded from this analysis\n",
      "----------------------\n",
      "Feature: 15/15\n",
      "Intertidal mangroves and other trees & shrubs\n",
      "14\n",
      "index                                                      9883\n",
      "OBJECTID                                                   9884\n",
      "CONSOL                                                        U\n",
      "DOM_TYPE                                                      5\n",
      "DOM_LABEL          Mangroves and other trees (undifferentiated)\n",
      "CO_TYPES                                                  12|11\n",
      "TIDE_ZONE                                            Intertidal\n",
      "BRD_HAB           Intertidal mangroves and other trees & shrubs\n",
      "Shape_Leng                                           0.00848502\n",
      "Shape_Area                                          1.08161e-06\n",
      "id                                                            0\n",
      "geometry      POLYGON ((1958534.686278717 -2750322.955597232...\n",
      "Name: 14, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 12 out of 22 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 12 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.54, -24.09\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (4, 14)\n",
      "0 14\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Setup the general query and variables for later\n",
    "products = [\"ga_ls5t_ard_3\",\n",
    "            \"ga_ls7e_ard_3\",\n",
    "            \"ga_ls8c_ard_3\",\n",
    "            'nidem',\n",
    "            'item_v2',\n",
    "            'item_v2_conf']\n",
    "align = (0, 0)\n",
    "\n",
    "# Query\n",
    "query = {\n",
    "    \"time\": (\"2020-01-01\", \"2021-01-01\"),\n",
    "    \"measurements\": [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"nbart_nir\", \"nbart_swir_1\"],\n",
    "    \"output_crs\": \"EPSG:3577\", # Do not change th\n",
    "    \"resolution\": (-30, 30),\n",
    "    \"group_by\": \"solar_day\",\n",
    "    \"dask_chunks\": {\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "}\n",
    "\n",
    "# Designate dask chunks\n",
    "# It doesn't really matter how big the chunks we load are, as long as time ~ 1.\n",
    "# chunks = {\"time\": 1, \"x\": 3000, \"y\": 3000}\n",
    "\n",
    "# Load data for predetermined polygons\n",
    "# Dictionary to save results\n",
    "results = {}\n",
    "\n",
    "'''List of saved tideposts. In the event that a polygon centroid geometry fails\n",
    "to return an associated tideheight, the tidal_tag function will bring in this list\n",
    "and use the most recent successful polygon centroid geometry to calculate a tideheight\n",
    "for the current polygon'''\n",
    "tideposts = [[0,0]]\n",
    "\n",
    "# Loop through polygons in geodataframe and extract satellite data\n",
    "for index, row in gdf.iterrows():\n",
    "\n",
    "    ## Skip multipolygons which break the loops\n",
    "    if type(row.geometry) == Polygon: \n",
    "    \n",
    "        print(f\"Feature: {index + 1}/{len(gdf)}\")\n",
    "        print(gdf[\"BRD_HAB\"].values[index])\n",
    "        print(str(index))\n",
    "        print(str(row))\n",
    "\n",
    "        if not (str(row[attribute_col]) in results.keys()):\n",
    "            results[str(row[attribute_col])] = {}\n",
    "\n",
    "        # Extract the feature's geometry as a datacube geometry object\n",
    "        geom = geometry.Geometry(geom=row.geometry, crs=gdf.crs)\n",
    "\n",
    "        # Update the query to include our geopolygon\n",
    "        query.update({\"geopolygon\": geom})\n",
    "\n",
    "        # Load landsat\n",
    "        ds = load_ard(\n",
    "            dc=dc,\n",
    "            products=products,\n",
    "            min_gooddata=0.90,  # only take uncloudy scenes\n",
    "            ls7_slc_off=False,\n",
    "            skip_broken_datasets=True, ## New line 25/02/2021 TEMP fix while lingering ARD issue sorted\n",
    "            **query,\n",
    "        )\n",
    "\n",
    "        ## Tidally tag datasets\n",
    "        ds, tidepost_lon, tidepost_lat = tidal_tag(ds,\n",
    "                                                   tideposts[-1],\n",
    "                                                   return_tideposts=True,\n",
    "                                                   ebb_flow=True)\n",
    "        tideposts.append([tidepost_lon, tidepost_lat])\n",
    "\n",
    "        # Generate a polygon mask to keep only data within the polygon\n",
    "        mask = xr_rasterize(gdf.iloc[[index]], ds)\n",
    "\n",
    "        # Mask dataset to set pixels outside the polygon to `NaN`\n",
    "        ds = ds.where(mask)\n",
    "\n",
    "        ## Attach unique polygon id to each dataset\n",
    "        attrs = {'pgid': row['OBJECTID']}\n",
    "        ds.attrs = attrs\n",
    "\n",
    "        ## Append results to a dictionary using the attribute\n",
    "        ## column as an key\n",
    "        results[str(row[attribute_col])][str(index)] = ds\n",
    "\n",
    "        print(row[attribute_col], index)\n",
    "        print(\"----------------------\")\n",
    "        \n",
    "    else:\n",
    "        print ('Feature', index +1, 'is a multipolygon and is excluded from this analysis')\n",
    "        print(\"----------------------\")\n",
    "        continue\n",
    "\n",
    "## Drop gdf rows associated with multipolygons\n",
    "for index, row in gdf.iterrows():\n",
    "    if type(row.geometry) == Polygon: \n",
    "        pass\n",
    "    else:\n",
    "        gdf.drop(labels=index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter results by tide height, calculate indices and build ITEM masks\n",
    "\n",
    "*user to define tide_range to keep - set the desired quantile value in `lowest_20` variable*\n",
    "\n",
    "*user defines required indices in the `calculate_indices` function call*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed feature: 1/15\n",
      "Completed feature: 2/15\n",
      "Completed feature: 3/15\n",
      "Completed feature: 4/15\n",
      "Completed feature: 5/15\n",
      "Completed feature: 6/15\n",
      "Completed feature: 7/15\n",
      "Completed feature: 8/15\n",
      "Completed feature: 9/15\n",
      "Completed feature: 10/15\n",
      "Completed feature: 11/15\n",
      "Completed feature: 12/15\n",
      "Completed feature: 13/15\n",
      "Completed feature: 14/15\n"
     ]
    }
   ],
   "source": [
    "results2 = {}\n",
    "x=1\n",
    "\n",
    "for k in results:\n",
    "\n",
    "    if not (str(k) in results2.keys()):\n",
    "        results2[str(k)] = {}\n",
    "        \n",
    "    for kk in results[k]:\n",
    "        \n",
    "        ds = results[k][kk] \n",
    "        \n",
    "        ## Save attributes to reattach later\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        ## Filter data by tide height\n",
    "        lowest_10 = ds.tide_height.quantile([0.10]).values\n",
    "        lowest_20 = ds.tide_height.quantile([0.20]).values  \n",
    "        results2[k][kk] = ds.where(ds.tide_height <= lowest_20, drop=True)      \n",
    "        \n",
    "        ## Compute data from dask - WARNING: time consuming step!\n",
    "        results2[k][kk] = results2[k][kk].compute()       \n",
    "        ds = results2[k][kk]\n",
    "       \n",
    "        ## Drop tide_height and ebb_flow variables\n",
    "        '''\n",
    "        works around the calculate_indices function which was stalling on the additional \n",
    "        coastal variables, drop tide_height and ebb_flow variables\n",
    "        '''\n",
    "        tide_height = ds['tide_height']\n",
    "        ebb_flow = ds['ebb_flow']\n",
    "        ds = ds.drop_vars(names = ('tide_height', 'ebb_flow'))\n",
    "        \n",
    "        # calculate ndvi for pixels inside the polygon\n",
    "        ds = calculate_indices(ds, index=['NDVI', 'MNDWI', 'NDAVI', 'WAVI', 'EVI', 'SAVI', 'NDWI', 'LAI'], \n",
    "                               collection='ga_ls_3', inplace=True)\n",
    "        \n",
    "        # Add tide_height back in to calculate ITEM mask\n",
    "        ds['tide_height'] = tide_height\n",
    "\n",
    "        ## Prepare data to calculate ITEM masks\n",
    "        lowest_10 = ds.where(ds.tide_height <= lowest_10, drop=True)\n",
    "        lowest_20 = ds.where(ds.tide_height <= lowest_20, drop=True)\n",
    "\n",
    "        ## Calculate ITEM layers\n",
    "        lowest_10_mask = lowest_10[['NDWI', 'tide_height']].median(dim='time')\n",
    "        lowest_20_mask = lowest_20[['NDWI', 'tide_height']].median(dim='time')\n",
    "        \n",
    "#         # Add ITEM mask layers to results2 datasets\n",
    "        results2[k][kk]['lowest_10_mask'] = lowest_10_mask.NDWI <= 0 \n",
    "        results2[k][kk]['lowest_20_mask'] = lowest_20_mask.NDWI <= 0 \n",
    "        \n",
    "        results2[str(k)][str(kk)] = xr.merge([results2[str(k)][str(kk)], ds])\n",
    "        \n",
    "        ## Attach unique polygon id to each dataset\n",
    "        results2[str(k)][str(kk)].attrs = attrs\n",
    "        \n",
    "        print(f\"Completed feature: {x}/{len(gdf)}\") \n",
    "        \n",
    "        x=x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save loaded results\n",
    "*By default, save the imagery and polygon sub-sampled datasets every time.*\n",
    "\n",
    "*If required to load last dataset, hash out the `save` calls and unhash the `load` calls*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save variables\n",
    "\n",
    "## Save imagery dict\n",
    "with open('results2_' + query['time'][0] + '_'+ name +'.pickle', 'wb') as handle:\n",
    "    pickle.dump(results2, handle)\n",
    " \n",
    "## Save polygon gdf   \n",
    "with open('gdf_' + query['time'][0] + '_'+ name +'.pickle', 'wb') as handle:\n",
    "    pickle.dump(gdf, handle)\n",
    "    \n",
    "'''-----------------------------------------'''\n",
    "\n",
    "# # Load saved variables (hashed out by default)\n",
    "\n",
    "# ## Load the name for your roi\n",
    "# name = 'Rodds_Bay'\n",
    "\n",
    "# ## Re-load the query\n",
    "\n",
    "# # Setup the general query and variables for later\n",
    "# products = [\"ga_ls8c_ard_3\"]\n",
    "# align = (0, 0)\n",
    "\n",
    "# # Query\n",
    "# query = {\n",
    "#     \"time\": (\"2013-01-01\", \"2020-08-01\"),\n",
    "#     \"measurements\": [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"nbart_nir\", \"nbart_swir_1\"],\n",
    "#     \"output_crs\": \"EPSG:3577\", # Do not change th\n",
    "#     \"resolution\": (-30, 30),\n",
    "#     \"group_by\": \"solar_day\",\n",
    "#     \"dask_chunks\": {\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "# }\n",
    "\n",
    "# ## ensure that you are working from the same directory as the files are stored\n",
    "# %cd '/home/jovyan/dev/dea-notebooks/Claire'\n",
    "\n",
    "# ## Load imagery dict\n",
    "# with open('results2_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     results2 = pickle.load(handle)\n",
    "\n",
    "# ## Load polygon gdf    \n",
    "# with open('gdf_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     gdf = pickle.load(handle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "Load the following cell to define the functions that enable data interrogation and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### funcs for py script\n",
    "\n",
    "## Testing updated coastal_wit func. Drafted in BKUP notebook and copied over to this cell\n",
    "\n",
    "def coastal_wit(\n",
    "               results2,\n",
    "               pg,\n",
    "               ITEM_mask = 'lowest_20_mask',\n",
    "               classes = False\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Takes a polygon or polygons in a region of interest ([pg]) from the gdf of polygon shapefiles and extracts \n",
    "    and plots the frequency of pixels as assigned into class ranges of NDVI. Also includes pixels identified\n",
    "    as wet. All NDVI pixels are masked by 'dry' range of NDWI and everything is masked by the ITEM mask.\n",
    "    If conditional dataset dropping is required, set drop=True and nominate the percent of wet pixels\n",
    "    tolerated and the minimum number of allowable pixels (e.g. pc_drop=90 means drop any timestep dataset\n",
    "    when more than 90% of pixels are wet; px_min=5 means that a timestep dataset will only be dropped\n",
    "    when more than pc_drop pixels are wet AND the remaining pixels sum to less than or = px_min - or\n",
    "    5 in this case)\n",
    "    If the WIT datasets have already been generated and included in the xarray dataset (`results2`) then \n",
    "    set `classes = True` to avoid re-calculation. Default is False.\n",
    "    ITEM_mask is the layer to nominate for ITEM masking. If no masking required, select one of the \n",
    "    original bands such as 'nbart_red'\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    ## Set up lists to extract pixel counts per timestep into\n",
    "    ls_pixels = []\n",
    "    ls_ndwi = []\n",
    "    ls_unveg = []\n",
    "    ls_ndvilow = []\n",
    "    ls_ndvimid = []\n",
    "    ls_ndvihigh = []\n",
    "    ls_pxsum = []\n",
    "    ls_tide = []\n",
    "    ls_index = []\n",
    "\n",
    "    ##  Data prep for WIT prototype (automated for all timesteps for all polygons)\n",
    "\n",
    "    ##  Generate all datasets for the stacked line plot (WIT) by adding as variables to results dataset\n",
    "    for k in results2:\n",
    "        for kk in results2[k]: \n",
    "\n",
    "            if classes == False:\n",
    "\n",
    "                ##  Add a non-water pixel mask variable\n",
    "                results2[k][kk]['mask'] = ((results2[k][kk].NDWI)\n",
    "                                           .where(results2[k][kk][ITEM_mask]) <= 0)\n",
    "\n",
    "                ##  Generate the NDWI_water class\n",
    "                results2[k][kk]['ndwi_water'] = ((results2[k][kk].NDWI)\n",
    "                                                  .where(results2[k][kk][ITEM_mask]) > 0)\n",
    "\n",
    "                ##  Generate NDVI classes\n",
    "\n",
    "                ##  NDVI less than 0.1\n",
    "                results2[k][kk]['unveg'] = (results2[k][kk].NDVI\n",
    "                                            .where((results2[k][kk].NDVI < 0.1).astype(int))\n",
    "                                            .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ##  NDVI 0.1 to 0.33\n",
    "                results2[k][kk]['ndvi_low'] = (results2[k][kk].NDVI\n",
    "                                               .where((results2[k][kk].NDVI >= 0.1).astype(int) & \n",
    "                                                      (results2[k][kk].NDVI < 0.333).astype(int))\n",
    "                                               .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ##  NDVI 0.33 to 0.66\n",
    "                results2[k][kk]['ndvi_mid'] = (results2[k][kk].NDVI\n",
    "                                               .where((results2[k][kk].NDVI >= 0.333).astype(int) & \n",
    "                                                      (results2[k][kk].NDVI < 0.666).astype(int))\n",
    "                                               .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ### NDVI 0.66 to 1\n",
    "                results2[k][kk]['ndvi_high'] = (results2[k][kk].NDVI\n",
    "                                                .where((results2[k][kk].NDVI >= 0.666).astype(int) & \n",
    "                                                       (results2[k][kk].NDVI <= 1).astype(int))\n",
    "                                                .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ##  Mask the NDVI classes to show non-water pixels only\n",
    "                results2[k][kk]['unveg'] = results2[k][kk]['unveg'].where(results2[k][kk]['mask'])\n",
    "                results2[k][kk]['ndvi_low'] = results2[k][kk]['ndvi_low'].where(results2[k][kk]['mask'])\n",
    "                results2[k][kk]['ndvi_mid'] = results2[k][kk]['ndvi_mid'].where(results2[k][kk]['mask'])\n",
    "                results2[k][kk]['ndvi_high'] = results2[k][kk]['ndvi_high'].where(results2[k][kk]['mask'])\n",
    "\n",
    "                for x in pg:\n",
    "                    if x == results2[str(k)][str(kk)].attrs['pgid']:\n",
    "                         ##  Populate pixel count lists per class per timestep\n",
    "                        for t in range (0, len(results2[str(k)][str(kk)].time)):\n",
    "                            ls_pixels.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].where(results2[k][kk][ITEM_mask]).isel(time=t).nbart_red)))\n",
    "                            ls_ndwi.append(np.count_nonzero(results2[str(k)][str(kk)].isel(time=t).ndwi_water))\n",
    "                            ls_unveg.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).unveg)))\n",
    "                            ls_ndvilow.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).ndvi_low)))\n",
    "                            ls_ndvimid.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).ndvi_mid)))\n",
    "                            ls_ndvihigh.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).ndvi_high)))\n",
    "                            ls_pxsum.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].where(results2[k][kk][ITEM_mask]).isel(time=t).nbart_red)))\n",
    "                            ls_tide.append(results2[str(k)][str(kk)].isel(time=t).tide_height.median().values)\n",
    "\n",
    "                        ls_index.append(results2[str(k)][str(kk)].time.values)\n",
    "    ls_index = np.concatenate(ls_index).tolist()\n",
    "#                                 index = results2[str(k)][str(kk)].time.values\n",
    "\n",
    "#         if classes == True:\n",
    "\n",
    "#              ##  Populate pixel count lists per class per timestep\n",
    "#             for t in range (0, len(results2.time)):\n",
    "#                 ls_pixels.append(np.count_nonzero(~np.isnan(results2.isel(time=t).nbart_red)))\n",
    "# #                 ls_mndwi.append(np.count_nonzero((results2.isel(time=t).mndwi_water)))\n",
    "#                 ls_mndwi.append(np.count_nonzero(~np.isnan(mWIT1.isel(time=t).mndwi_water.where(mWIT1.isel(time=t).mndwi_water == True))))\n",
    "#                 ls_unveg.append(np.count_nonzero(~np.isnan(results2.isel(time=t).unveg)))\n",
    "#                 ls_ndvilow.append(np.count_nonzero(~np.isnan(results2.isel(time=t).ndvi_low)))\n",
    "#                 ls_ndvimid.append(np.count_nonzero(~np.isnan(results2.isel(time=t).ndvi_mid)))\n",
    "#                 ls_ndvihigh.append(np.count_nonzero(~np.isnan(results2.isel(time=t).ndvi_high)))\n",
    "#                 ls_pxsum.append(np.count_nonzero(~np.isnan(results2.isel(time=t).nbart_red)))\n",
    "#                 ls_tide.append(results2.isel(time=t).tide_height.median().values)\n",
    "\n",
    "#                 index = results2.time.values\n",
    "\n",
    "\n",
    "    ## Return index values to datetime64\n",
    "    for x in range(0, len(ls_index)):\n",
    "        ls_index[x] = np.datetime64(int(ls_index[x]), 'ns')\n",
    "\n",
    "    ##  Generate a dataframe summarising class pixel counts per timestep\n",
    "    classes_df = pd.DataFrame(\n",
    "                {\"pixels\": ls_pixels,\n",
    "                \"water\": ls_ndwi,\n",
    "                \"unveg\": ls_unveg,\n",
    "                \"ndvi_low\": ls_ndvilow,\n",
    "                \"ndvi_mid\": ls_ndvimid,\n",
    "                \"ndvi_high\": ls_ndvihigh,\n",
    "                \"px_sum\": ls_pxsum,\n",
    "                \"tide_height\": ls_tide},\n",
    "                index = ls_index\n",
    "                )\n",
    "\n",
    "    ## Aggregate the datasets to account for identical imagery dates spanning different polygons\n",
    "    ## All pixel values are summed. Tide_height values are averaged\n",
    "    ## Separate tide_height dataset and convert to dataframe\n",
    "    classes_df_th = classes_df.tide_height\n",
    "    classes_df_th = pd.DataFrame(classes_df_th)\n",
    "\n",
    "    ## Drop tide_height from main df then group rows with duplicate indices and then sum them up\n",
    "    classes_df = classes_df.drop(['tide_height'], axis=1)\n",
    "    classes_df = classes_df.groupby(classes_df.index).sum()\n",
    "\n",
    "    ## Take tide-height values and convert from array to int\n",
    "    intlist=[]\n",
    "    for x in range (0,len(classes_df_th.tide_height.values.tolist())):\n",
    "        intlist.append(classes_df_th.tide_height.values.tolist()[x].tolist())\n",
    "\n",
    "    ## Add integer list to tide_height dataframe and drop array list\n",
    "    classes_df_th['th_int'] = intlist\n",
    "    classes_df_th = classes_df_th.drop('tide_height', axis=1)\n",
    "\n",
    "    ## Group by index dates as per classes_df and calculate mean tide_height value\n",
    "    classes_df_th = classes_df_th.groupby(classes_df_th.index).mean()\n",
    "\n",
    "    ## Merge the pixel and tide_height datasets back together\n",
    "    classes_df = classes_df.merge(classes_df_th, left_on = classes_df.index, right_on = classes_df_th.index)\n",
    "\n",
    "    ## Rename tide_height column to something sensible\n",
    "    classes_df = classes_df.rename(columns={'th_int':'tide_height'})\n",
    "\n",
    "    ## Reset the index to observation dates\n",
    "    classes_df.set_index('key_0', inplace=True)\n",
    "\n",
    "    ##  Normalise pixel counts per class per timestep\n",
    "    classes_df['pc_water'] = classes_df['water']/classes_df['pixels']*100\n",
    "    classes_df['pc_unveg'] = classes_df['unveg']/classes_df['pixels']*100\n",
    "    classes_df['pc_ndvi_low'] = classes_df['ndvi_low']/classes_df['pixels']*100\n",
    "    classes_df['pc_ndvi_mid'] = classes_df['ndvi_mid']/classes_df['pixels']*100\n",
    "    classes_df['pc_ndvi_high'] = classes_df['ndvi_high']/classes_df['pixels']*100\n",
    "    classes_df['pc_total'] = (classes_df['pc_water']+\n",
    "                              classes_df['pc_unveg']+\n",
    "                              classes_df['pc_ndvi_low']+\n",
    "                              classes_df['pc_ndvi_mid']+\n",
    "                              classes_df['pc_ndvi_high'])\n",
    "    classes_df['pc_exposedpx'] = (classes_df['unveg']+\n",
    "                                  classes_df['ndvi_low']+\n",
    "                                  classes_df['ndvi_mid']+\n",
    "                                  classes_df['ndvi_high'])/classes_df['px_sum']*100\n",
    "\n",
    "\n",
    "    return classes_df, results2\n",
    "\n",
    "def onclick_timeseries(event):\n",
    "    '''\n",
    "    This widget allows the user to select a time point from a plotted time series. \n",
    "    It then translates the chosen point back into the approriate datetime object so\n",
    "    that it can be used to find the location of this time point within the extracted\n",
    "    datasets. The index location of this time step is also returned. \n",
    "    \n",
    "    '''\n",
    "    global time_slice, TimeIndex, pixelx, pixely\n",
    "    \n",
    "    # Get time from x axis of plot \n",
    "    timeOfInterest = event.xdata\n",
    "    \n",
    "    # Get x and y coordinates from click\n",
    "    pixelx, pixely = int(event.xdata), int(event.ydata)\n",
    "    \n",
    "    # Add point to image\n",
    "    plt.plot(pixelx, pixely, 'ro', markersize=5)\n",
    "    \n",
    "    # Convert clicked int to datetime format\n",
    "    time_slice = matplotlib.dates.num2date(timeOfInterest).date()\n",
    "    \n",
    "    # Convert clicked value to str\n",
    "    time_slice = str(time_slice)\n",
    "    \n",
    "    # Convert clicked value to correct datetime format\n",
    "    time_slice = pd.to_datetime(time_slice, format='%Y-%m-%d')\n",
    "    \n",
    "    # Find the time index of the chosen time slice\n",
    "    TimeIndex = results2[str(cl)][str(pg1)].indexes['time'].get_loc(time_slice, method='nearest')\n",
    "    \n",
    "    # Print the date of the image closest to clicked pixel\n",
    "    ClosestImage = results2[str(cl)][str(pg1)].time[TimeIndex].values\n",
    "    \n",
    "    # Update text below plot\n",
    "    w2.value = 'Closest imagery date : {}'.format(ClosestImage)\n",
    "    \n",
    "        \n",
    "def temporal_stats (gdf, \n",
    "                    results2,\n",
    "                    zonal=True,\n",
    "                    pixel=True,\n",
    "                    mask= 'lowest_20_mask'):\n",
    "\n",
    "    '''\n",
    "    This function calculates and returns the temporal mean and standard deviation\n",
    "    for a range of indices for every polygon and every pixel within\n",
    "    every polygon in the form of a geodataframe.  \n",
    "    For now, leave zonal and pixel set to True to calculate all results. Func may\n",
    "    not work if either of these vars are set to False.\n",
    "    ITEM masking is available using the `mask` variable. If no masking is required, set\n",
    "    this variable to one of the bands such as 'nbart_nir'. If masking, two ITEM\n",
    "    layers are generated by default to choose from. Either 'lowest_20_mask' for\n",
    "    all images except those associated with the lowest 20% of observed tides, or\n",
    "    'lowest_10_mask' to mask by the equivalent in the 10% range.\n",
    "    '''\n",
    "    ##  Spectral indices available in the `calculate_indices` function (dea_bandindices.py)\n",
    "    index_ls = [\n",
    "        \"NDVI\",\n",
    "        \"EVI\",\n",
    "        \"NDAVI\", \n",
    "        \"WAVI\",\n",
    "        \"LAI\",\n",
    "        \"SAVI\",\n",
    "        \"MSAVI\",\n",
    "        \"NDMI\",\n",
    "        \"NBR\",\n",
    "        \"BAI\",\n",
    "        \"NDCI\",\n",
    "        \"NDSI\",\n",
    "        \"NDTI\",\n",
    "        \"NDWI\",\n",
    "        \"MNDWI\",\n",
    "        \"NDBI\",\n",
    "        \"BUI\",\n",
    "        \"BAEI\",\n",
    "        \"NBI\",\n",
    "        \"BSI\",\n",
    "        \"AWEI_ns\",\n",
    "        \"AWEI_sh\",\n",
    "        \"WI\",\n",
    "        \"TCW\",\n",
    "        \"TCG\",\n",
    "        \"TCB\",\n",
    "        \"CMR\",\n",
    "        \"FMR\",\n",
    "        \"IOR\",\n",
    "    ]\n",
    "\n",
    "       \n",
    "    \n",
    "    ## Calculate zonal polygon results\n",
    "    if zonal:\n",
    "        \n",
    "        gdf_zonal = gdf \n",
    "        \n",
    "        ##  Generate a list of keys for polygons in class '0' of results2\n",
    "        keylist = list(results2['0'].keys())\n",
    "\n",
    "        ##  For each nominated indice:\n",
    "        for var in index_ls:\n",
    "            if var in results2[\"0\"][keylist[0]].var():\n",
    "\n",
    "                lsmean = []\n",
    "                lsstd = []\n",
    "\n",
    "                ##  Generate zonal indice stats for polygon followed by temporal statistic\n",
    "                ##  Append polygon id and temporal statistic to gdf\n",
    "                for k in results2:\n",
    "\n",
    "                    for kk in results2[k]:\n",
    "                        temporalmean = ((results2[k][kk][var]\n",
    "                                         .where(results2[k][kk][mask])\n",
    "                                         .mean('y')\n",
    "                                         .mean('x'))\n",
    "                                         .mean())\n",
    "                        lsmean.append([int(kk), temporalmean.values])\n",
    "                        name1 = str(var) + ' zonal mean'\n",
    "                        results2[str(k)][str(kk)][name1] = (temporalmean.values)\n",
    "                        \n",
    "                        temporalstd = ((results2[k][kk][var]\n",
    "                                        .where(results2[k][kk][mask])\n",
    "                                        .std('y')\n",
    "                                        .std('x'))\n",
    "                                        .std())\n",
    "                        lsstd.append([int(kk), temporalstd.values])  \n",
    "                        name2 = str(var) + ' zonal std'\n",
    "                        results2[str(k)][str(kk)][name2] = (temporalstd.values)                        \n",
    "\n",
    "                ##  Sort the list by polygon id to match up to the original polygon gdf\n",
    "                lsmean = sorted(lsmean)\n",
    "                lsstd = sorted(lsstd)\n",
    "\n",
    "                ##  Separate the sorted polygon ids from the indice statistic to build into a pd.DataFrame\n",
    "                indicemean = []\n",
    "                indicestd = []\n",
    "                polyid = []\n",
    "\n",
    "                for x in lsmean:\n",
    "                    polyid.append(x[0])\n",
    "                    indicemean.append(x[1])\n",
    "\n",
    "                for x in lsstd:\n",
    "                    indicestd.append(x[1])\n",
    "\n",
    "                # Build a pd.DataFrame from the sorted polygon id and indice statistics. \n",
    "                # Nominate a name for the new column.\n",
    "                indexstats = pd.DataFrame(\n",
    "                    indicemean, index=polyid, columns=[str(var) + \" zonal mean\"]\n",
    "                )\n",
    "\n",
    "#                 indexstats[str(var) + ' zonal mean'] = indicemean\n",
    "#                 indexstats['polyid'] = polyid \n",
    "    \n",
    "                indexstats[str(var) + \" zonal std\"] = None\n",
    "                indexstats.loc[polyid, (str(var) + \" zonal std\")] = indicestd\n",
    "\n",
    "                # Workaround to handle automatic addition of key_0 column at merge step\n",
    "                if \"key_0\" in gdf_zonal.columns:\n",
    "                    gdf_zonal.drop(columns=[\"key_0\"], inplace=True)\n",
    "\n",
    "                # # Merge the indice statistic for each polygon into the original polygon gdf\n",
    "                gdf_zonal = gdf_zonal.merge(indexstats, on=indexstats.index)\n",
    "\n",
    "        ## Rename the 'index' column to avoid confusion with the gdf.index\n",
    "        gdf_zonal.rename(columns={'OBJECTID' : 'pgid'}, inplace=True)\n",
    "        gdf_zonal.rename(columns={'geometry' : 'pg_geometry'}, inplace=True)\n",
    "\n",
    "#                         return gdf\n",
    "\n",
    "    ## Calculate pixel results\n",
    "    if pixel:\n",
    "\n",
    "        ## New dict to store arrays\n",
    "#         pxsummary = {}\n",
    "\n",
    "        ## Master gdf\n",
    "        gdf_px = gpd.GeoDataFrame()\n",
    "        gdf_px['geometry'] = None\n",
    "\n",
    "        ## List to store geom, unique pixel id \n",
    "        # pxid = []\n",
    "        uniquepx = []\n",
    "        pxgeom = []\n",
    "\n",
    "        ##  Generate a list of keys for polygons in class '0' of results2\n",
    "        keylist = list(results2['0'].keys())\n",
    "\n",
    "\n",
    "        ##  Generate zonal indice stats for polygon followed by temporal statistic\n",
    "        ##  Append polygon id and temporal statistic to gdf\n",
    "        for k in results2:\n",
    "\n",
    "#             if not (str(k) in pxsummary.keys()):\n",
    "#                 pxsummary[str(k)] = {}\n",
    "\n",
    "            for kk in results2[k]:\n",
    "\n",
    "                lon = []\n",
    "                for value in results2[k][kk].x.values:\n",
    "                    lon.append(value)\n",
    "\n",
    "                lat = []\n",
    "                for value in results2[k][kk].y.values:\n",
    "                    lat.append(value)\n",
    "\n",
    "                ds = xr.Dataset()\n",
    "\n",
    "                ##  For each nominated indice:\n",
    "                for var in index_ls:\n",
    "                    if var in results2[\"0\"][keylist[0]].var():\n",
    "\n",
    "                        temporalmean = (results2[str(k)][str(kk)][var]\n",
    "                                        .where(results2[k][kk][mask])\n",
    "                                        .mean(dim='time'))\n",
    "                        name1 = str(var) + ' px mean'\n",
    "                        ds[name1] = (('y', 'x'), temporalmean)\n",
    "                        results2[str(k)][str(kk)][name1] = (('y', 'x'), temporalmean)\n",
    "\n",
    "                        temporalstd = (results2[k][kk][var]\n",
    "                                       .where(results2[k][kk][mask])\n",
    "                                       .std(dim='time'))\n",
    "                        name2 = str(var) + ' px std'\n",
    "                        ds[name2] = (('y', 'x'), temporalstd)\n",
    "                        results2[str(k)][str(kk)][name2] = (('y', 'x'), temporalstd)\n",
    "\n",
    "                ds.coords['lon'] = ('x'), lon\n",
    "                ds.coords['lat'] = ('y'), lat\n",
    "\n",
    "\n",
    "                ## Extract pixel geometry/shape for input into gdf for choropleth plotting\n",
    "                # Extract dataset matching polygon\n",
    "                closest_ds = results2[k][kk]\n",
    "\n",
    "                ## Extract pgid attributes to attach later\n",
    "                attrs = closest_ds.attrs\n",
    "                ds.attrs = attrs\n",
    "\n",
    "                ## Skip empty arrays\n",
    "                if closest_ds.x.size == 0:\n",
    "                    print('Empty arrays: k: ', k, 'kk: ', kk)\n",
    "                    continue\n",
    "                else:       \n",
    "                    # Input array (based on red band) to segment and vectorise\n",
    "                    input_array = closest_ds.nbart_red\n",
    "                    input_transform = closest_ds.affine  \n",
    "                    input_crs = input_array.crs\n",
    "\n",
    "                    # Create array with a unique value per cell\n",
    "                    unique_pixels = np.arange(input_array.size).reshape(input_array.shape)\n",
    "\n",
    "                    # Vectorise each unique feature in array\n",
    "                    vectors = rasterio.features.shapes(\n",
    "                        source=unique_pixels.astype(np.int16), transform=input_transform\n",
    "                    )\n",
    "\n",
    "                    # Extract polygons and values from generator\n",
    "                    vectors = list(vectors)\n",
    "                    values = [value for polygon, value in vectors]\n",
    "                    polygons = [shape(polygon) for polygon, value in vectors]\n",
    "                    pp = np.array(polygons)\n",
    "                    pp = pp.reshape(len(input_array.y), len(input_array.x))\n",
    "\n",
    "#              # Create a geopandas dataframe populated with the polygon shapes\n",
    "#              closestdate_poly_gdf = gpd.GeoDataFrame(data={\"id\": values}, geometry=polygons, crs=input_crs)\n",
    "\n",
    "                    ds['geometry'] = (('y', 'x'), pp)\n",
    "\n",
    "                results2[k][kk]['geometry'] = (('y', 'x'), pp)\n",
    "                results2[k][kk].set_coords('geometry')\n",
    "\n",
    "\n",
    "                ## Append [geom, unique pixel id] to list for later addition to gdf, merging on geom\n",
    "                pxid2 = []\n",
    "                pgid2 = []\n",
    "\n",
    "                for x in ds['x']:\n",
    "                    for y in ds['y']:\n",
    "                        pxid1 = str(attrs['pgid'])+'_'+str(ds['y'][y].item())+'_'+str(ds['x'][x].item())\n",
    "                        gm = pp[ds['y'][y].item()][ds['x'][x].item()]\n",
    "\n",
    "                        uniquepx.append(pxid1)\n",
    "                        pxgeom.append(gm)\n",
    "                        pxid2.append(pxid1)\n",
    "                        pgid2.append(attrs['pgid'])\n",
    "\n",
    "                pxid2 = np.array(pxid2).reshape(ds.y.shape[0], ds.x.shape[0])\n",
    "                pgid2 = np.array(pgid2).reshape(ds.y.shape[0], ds.x.shape[0])\n",
    "                results2[k][kk]['pxid'] = (('y', 'x'), pxid2)\n",
    "\n",
    "                ds['pgid'] = (('y', 'x'), pgid2)\n",
    "\n",
    "                ## Reattach attrs\n",
    "                results2[k][kk].attrs = attrs\n",
    "\n",
    "#                 pxsummary[k][kk] = ds\n",
    "\n",
    "                ## Append ds to gdf_px\n",
    "                ds = ds.to_dataframe()\n",
    "                gdf_px = gdf_px.append(ds)\n",
    "                gdf_px.crs = gdf.crs\n",
    "\n",
    "        pxid = gpd.GeoDataFrame(uniquepx, geometry=pxgeom, columns=['pxid'], crs=input_crs)\n",
    "\n",
    "        gdf_px.reset_index(inplace=True)\n",
    "\n",
    "        gdf_px = gdf_px.merge(pxid)\n",
    "        gdf_px.set_index('pxid', inplace=True, drop=False)\n",
    "        gdf_px.dropna(axis=0, inplace=True)\n",
    "        gdf_px.sort_index(level='pxid', inplace=True)\n",
    "\n",
    "    if zonal == True & pixel == True:\n",
    "        ## Merge the (zonal) gdf and gdf_px\n",
    "        gdf_merged = gdf_px.merge(gdf_zonal, on = 'pgid')\n",
    "\n",
    "        ## Drop the pg_geometry to use the pixel geometry default\n",
    "        gdf_merged.drop(columns='pg_geometry', inplace=True)\n",
    "\n",
    "        ##  Create new gdf's for each class to plot\n",
    "#         grasses = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal grass-herb-sedge-other succulent\"].index\n",
    "#         )\n",
    "#         mangroves = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal mangroves and other trees & shrubs\"].index\n",
    "#         )\n",
    "        seagrass = gdf_merged.drop(gdf_merged[gdf_merged.BRD_HAB != \"Intertidal seagrass\"].index)\n",
    "\n",
    "        ##  Drop polygons containing NaN values\n",
    "        ##  ASSUMPTION: if NDVI contains NaNs, all indices will contain NaNs. \n",
    "        ##  ToDo: write a loop or func that looks for NaNs in any of the supplied indices\n",
    "#         grasses = grasses.dropna(axis=0, how='any', subset=[\n",
    "#                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "#                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "#         mangroves = mangroves.dropna(axis=0, how='any', subset=[\n",
    "#                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "#                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "        seagrass = seagrass.dropna(axis=0, how='any', subset=[\n",
    "                                                   'NDVI zonal mean', \n",
    "                                                   'NDVI px mean', \n",
    "                                                   'NDVI zonal std', \n",
    "                                                   'NDVI px std']) \n",
    "    if zonal == False:\n",
    "        \n",
    "         ## Merge the (zonal) gdf and gdf_px\n",
    "        gdf_merged = gdf_px.merge(gdf, on = 'pgid')\n",
    "\n",
    "        ## Drop the pg_geometry to use the pixel geometry default\n",
    "        gdf_merged.drop(columns='pg_geometry', inplace=True)        \n",
    "\n",
    "        ##  Create new gdf's for each class to plot\n",
    "#         grasses = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal grass-herb-sedge-other succulent\"].index\n",
    "#         )\n",
    "#         mangroves = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal mangroves and other trees & shrubs\"].index\n",
    "#         )\n",
    "        seagrass = gdf_merged.drop(gdf_merged[gdf_merged.BRD_HAB != \"Intertidal seagrass\"].index)\n",
    "\n",
    "        ##  Drop polygons containing NaN values\n",
    "        ##  ASSUMPTION: if NDVI contains NaNs, all indices will contain NaNs. \n",
    "        ##  ToDo: write a loop or func that looks for NaNs in any of the supplied indices\n",
    "#         grasses = grasses.dropna(axis=0, how='any', subset=[\n",
    "# #                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "# #                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "#         mangroves = mangroves.dropna(axis=0, how='any', subset=[\n",
    "# #                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "# #                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "        seagrass = seagrass.dropna(axis=0, how='any', subset=[\n",
    "#                                                    'NDVI zonal mean', \n",
    "                                                   'NDVI px mean', \n",
    "#                                                    'NDVI zonal std', \n",
    "                                                   'NDVI px std']) \n",
    "\n",
    "    return gdf_merged, seagrass#, results2, grasses, mangroves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Temp - data loading cell\n",
    "\n",
    "# # # ## Delete all variables, leaving imported modules # https://stackoverflow.com/questions/26545051/is-there-a-way-to-delete-created-variables-functions-etc-from-the-memory-of-th\n",
    "# # for name in dir():\n",
    "# #     if not name.startswith('_'):\n",
    "# #         del globals()[name]\n",
    "# # # OR\n",
    "# # # reset # as per https://stackoverflow.com/questions/26545051/is-there-a-way-to-delete-created-variables-functions-etc-from-the-memory-of-th\n",
    "\n",
    "# # # Load saved variables (hashed out by default)\n",
    "\n",
    "# ## Load the name for your roi\n",
    "# name = 'Gladstone_Harbour_upperreach'\n",
    "\n",
    "# ## Re-load the query\n",
    "\n",
    "# # Setup the general query and variables for later\n",
    "# products = [\"ga_ls8c_ard_3\"]\n",
    "# align = (0, 0)\n",
    "\n",
    "# # Query\n",
    "# query = {\n",
    "#     \"time\": (\"2013-01-01\", \"2020-08-01\"),\n",
    "#     \"measurements\": [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"nbart_nir\", \"nbart_swir_1\"],\n",
    "#     \"output_crs\": \"EPSG:3577\", # Do not change th\n",
    "#     \"resolution\": (-30, 30),\n",
    "#     \"group_by\": \"solar_day\",\n",
    "#     \"dask_chunks\": {\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "# }\n",
    "\n",
    "# ## ensure that you are working from the same directory as the files are stored\n",
    "# %cd '/home/jovyan/dev/dea-notebooks/Claire'\n",
    "\n",
    "# ## Load imagery dict\n",
    "# with open('results2_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     results2 = pickle.load(handle)\n",
    "\n",
    "# ## Load polygon gdf    \n",
    "# with open('gdf_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     gdf = pickle.load(handle)\n",
    "\n",
    "# # gdf.drop(labels=8, axis=0, inplace=True)\n",
    "# len(results2['0']) + len(results2['1']) + len(results2['3'])\n",
    "# # len(gdf)\n",
    "# len(results['1']) + len(results['2'])+ len(results['0'])\n",
    "# # results.keys()\n",
    "# print(len(results['0']))\n",
    "# gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate zonal and temporal stats for each polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate zonal and pixel stats and attach to class polygons\n",
    "# gdf_merged, results2, grasses, mangroves, seagrass = temporal_stats(gdf, \n",
    "#                                                                     results2, \n",
    "#                                                                     mask='lowest_20_mask')\n",
    "\n",
    "gdf_merged, seagrass = temporal_stats(gdf, \n",
    "                                    results2, \n",
    "#                                     zonal = False,\n",
    "#                                     pixel = True,\n",
    "                                    mask='lowest_20_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate zonal and pixel stats and attach to class polygons\n",
    "gdf_merged, results2 = temporal_stats(gdf, \n",
    "                                        results2, \n",
    "                                        mask='lowest_20_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the zonal statistics temporal summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grasses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-3850edfc1408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print('Select attribute from: ', gdf_merged.columns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_shapefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NDVI px std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grasses' is not defined"
     ]
    }
   ],
   "source": [
    "##  Plot grasses\n",
    "# print('Select attribute from: ', gdf_merged.columns)\n",
    "\n",
    "roi = map_shapefile(grasses, attribute=\"NDVI px std\", continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Plot mangroves\n",
    "roi = map_shapefile(mangroves, attribute=\"NDVI px std\", continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6230148a134bf8ac0f1c062f044f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-24.078852591926342, 151.5400850652211], controls=(ZoomControl(options=['position', 'zoom_in_text'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  Plot seagrass\n",
    "roi = map_shapefile(seagrass, attribute=\"NDVI px std\", continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Plot seagrass\n",
    "# roi = map_shapefile(gdf_merged, attribute=\"NDVI px std\", continuous=True)\n",
    "gdf_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIT Preparation - single habitat polygon \n",
    "For single polygon interrogation, manually identify the polygon ID from the popup window above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ******From the interactive zonal summary plots above, IDENTIFY A POLYGON to interrogate*******\n",
    "pg = [3552]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIT preparation\n",
    "To select any region for interrogation, use the 'draw a polygon' option on any of the above 3 plots.\n",
    "Upon completion of the polygon, the geometry will automatically be saved to memory and the following cell\n",
    "will prepare the data for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pg:\n",
    "    ## For single polygon interrogation\n",
    "    classes_df, results2 = coastal_wit(results2, pg)\n",
    "else:\n",
    "\n",
    "    ## WIT preparation from a roi\n",
    "\n",
    "    ##  Form a shapely polygon from the coordinates defined by the user on the map\n",
    "    miniwit_roi = Polygon(roi[-1]['geometry']['coordinates'][0])\n",
    "\n",
    "    ##  Generate a new geodataframe containing the user defined polygon geometry\n",
    "    miniwit_df = gpd.GeoDataFrame(gpd.GeoSeries(miniwit_roi), columns=['geometry'], crs='EPSG:4326')\n",
    "    miniwit_df = miniwit_df.to_crs(gdf.crs)\n",
    "\n",
    "    ##  Intersect the user-defined region of interest with the master\n",
    "    ##  to create the working gdf from which imagery will be extracted\n",
    "    miniwit_gdf = gpd.overlay(roi[0], miniwit_df, how='intersection')  \n",
    "\n",
    "    # miniwit_gdf.plot()\n",
    "\n",
    "    ## Isolate the pgid's in the roi and convert to ints\n",
    "    roi_pg = miniwit_gdf.pgid.unique()\n",
    "    roi_pg = [int(x) for x in roi_pg]\n",
    "\n",
    "    ## Isolate the pxid's in the roi\n",
    "    roi_px = miniwit_gdf.pxid.to_list()\n",
    "    roi_px = [str(x) for x in roi_px]\n",
    "\n",
    "    print('This selection includes ', len(roi_px), ' individual pixel polygons from ', len(roi_pg), ' individual habitat class polygons')\n",
    "\n",
    "    ## Find the associated class and polygon keys in results2\n",
    "    ## Save results for an roi search to this new xarray dict (`roi_results2`)\n",
    "    roi_results2 = {}\n",
    "\n",
    "    for k in results2:\n",
    "\n",
    "        if not (str(k) in roi_results2.keys()):\n",
    "            roi_results2[str(k)] = {}\n",
    "\n",
    "        for kk in results2[k]:\n",
    "            for x in roi_pg:\n",
    "                if x == results2[str(k)][str(kk)].attrs['pgid']:\n",
    "    #                 print('True')\n",
    "    #                 print ('[k][kk]: ', k, ',', kk)\n",
    "\n",
    "                    ## Mask results2 by pixels in roi\n",
    "                    mask = (np.isin(results2[str(k)][str(kk)].pxid, roi_px))\n",
    "                    mask = mask.reshape(mask.shape[-1], mask.shape[0])\n",
    "\n",
    "                    results2[str(k)][str(kk)]['roi_mask'] = (('x', 'y'), mask)\n",
    "\n",
    "                    roi_results2[str(k)][str(kk)] = (results2[str(k)][str(kk)]\n",
    "                                                     .where((results2[str(k)][str(kk)]\n",
    "                                                             .roi_mask == True)))\n",
    "\n",
    "    miniwit_gdf.plot()\n",
    "\n",
    "    ## For region of interest interrogation\n",
    "    classes_df, results2 = coastal_wit(roi_results2, roi_pg)\n",
    "    pg = roi_pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIT plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell prepares the nominated WIT data for plotting\n",
    "%matplotlib widget\n",
    "pal = [\n",
    "       sns.xkcd_rgb[\"cobalt blue\"],\n",
    "       sns.xkcd_rgb[\"beige\"],\n",
    "       sns.xkcd_rgb[\"light green\"],\n",
    "       sns.xkcd_rgb[\"green\"],\n",
    "       sns.xkcd_rgb[\"dark green\"]]\n",
    "\n",
    "plt.clf()\n",
    "plt.close(fig=None)\n",
    "\n",
    "## `cl` and `pg1` are required for the interactive date selection from the plot\n",
    "cl = gdf.loc[gdf['OBJECTID'] == pg[0]].id.values.item()\n",
    "pg1 = gdf.loc[gdf['OBJECTID'] == pg[0]].index.values.item()\n",
    "\n",
    "fig = plt.figure(figsize=(12,8), constrained_layout=False)\n",
    "gs = fig.add_gridspec(8,1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0:2, :])\n",
    "ax1.set_title('% of polygon exposed')\n",
    "ax2 = fig.add_subplot(gs[4:, :])\n",
    "ax2.set_title('% cover in exposed polygon')\n",
    "ax3 = fig.add_subplot(gs[2:4, :])\n",
    "ax3.set_title('modelled tide height')\n",
    "\n",
    "ax2.stackplot(classes_df.index, \n",
    "              classes_df['pc_water'], \n",
    "              classes_df['pc_unveg'],\n",
    "              classes_df['pc_ndvi_low'], \n",
    "              classes_df['pc_ndvi_mid'], \n",
    "              classes_df['pc_ndvi_high'],\n",
    "              labels=[\n",
    "                  'water',\n",
    "                  'unveg',\n",
    "                  'low veg',\n",
    "                  'medium veg',\n",
    "                  'dense veg',\n",
    "                 ], \n",
    "              baseline='zero',\n",
    "              colors=pal, \n",
    "              alpha = 0.6\n",
    "             )\n",
    "\n",
    "ax1.plot(classes_df.index, \n",
    "        classes_df['pc_exposedpx'], \n",
    "        color='black', \n",
    "        linewidth=0.2, \n",
    "        marker='o',\n",
    "        markersize=3\n",
    "       )\n",
    "\n",
    "ax3.plot(classes_df.index, \n",
    "        classes_df['tide_height'], \n",
    "        color='black', \n",
    "        linewidth=0.2, \n",
    "        marker='o',\n",
    "        markersize=3\n",
    "       )\n",
    "\n",
    "\n",
    "# plt.ylim((0,100))\n",
    "ax1.set_ylim([0,100])\n",
    "ax3.set_ylim([-1,0])\n",
    "\n",
    "#add a legend and a tight plot box\n",
    "ax2.legend(loc='best', framealpha=0.0)#, bbox_to_anchor=(1.00,1.00))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Run on click event\n",
    "w2 = widgets.HTML(\"Click on the pixel you would like to interrogate\")\n",
    "ka = fig.canvas.mpl_connect('button_press_event', onclick_timeseries)\n",
    "display(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial WIT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Still buggy with roi areas. TimeIndex recalls wrong dates - needs debugging\n",
    "\n",
    "pglen=0\n",
    "# pg=roi_pg\n",
    "\n",
    "# Plot raster data\n",
    "plt.clf()\n",
    "plt.close()#'all')\n",
    "\n",
    "\n",
    "# ## Colour palette as per WIT\n",
    "# ndvi_pal = [\n",
    "# #        sns.xkcd_rgb[\"cobalt blue\"],\n",
    "#        sns.xkcd_rgb[\"beige\"],\n",
    "#        sns.xkcd_rgb[\"light green\"],\n",
    "#        sns.xkcd_rgb[\"green\"],\n",
    "#        sns.xkcd_rgb[\"dark green\"]]\n",
    "\n",
    "ndvi_pal = [\n",
    "#        sns.xkcd_rgb[\"cobalt blue\"],\n",
    "       sns.xkcd_rgb[\"dark green\"],\n",
    "       sns.xkcd_rgb[\"beige\"],\n",
    "       sns.xkcd_rgb[\"light green\"],\n",
    "       sns.xkcd_rgb[\"green\"]\n",
    "]\n",
    "\n",
    "# ndvi_pal = [\n",
    "# #        sns.xkcd_rgb[\"cobalt blue\"],\n",
    "\n",
    "#        sns.xkcd_rgb[\"light green\"],\n",
    "#        sns.xkcd_rgb[\"green\"],\n",
    "#        sns.xkcd_rgb[\"dark green\"],\n",
    "#        sns.xkcd_rgb[\"beige\"]]\n",
    "\n",
    "ndwi_pal = [\n",
    "    sns.xkcd_rgb[\"white\"],\n",
    "    sns.xkcd_rgb[\"cobalt blue\"]]\n",
    "\n",
    "# for x in range(0,len(pg)):\n",
    "    \n",
    "## Data preparation - pg must be a single value\n",
    "cl = gdf.loc[gdf['OBJECTID'] == pg[pglen]].id.values.item()\n",
    "#     print(cl)\n",
    "## class polygon\n",
    "pg1 = gdf.loc[gdf['OBJECTID'] == pg[pglen]].index.values.item()\n",
    "#     print(pg1)\n",
    "\n",
    "## Extract dataset matching polygon and date selected from WIT plot\n",
    "sWIT = results2[str(cl)][str(pg1)].isel(time=TimeIndex)\n",
    "# sWIT = results2[str(cl)][str(pg1)].isel(time=8)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=[8,8])#nrows = len(pg),\n",
    "#                         ncols = 1)#figsize=[8, 8])\n",
    "sWIT.NDWI.where(sWIT.lowest_20_mask).where(sWIT.NDWI > 0).plot(ax=ax1, levels=[-1, 0, 1], colors=ndwi_pal)\n",
    "sWIT.NDVI.where(sWIT.lowest_20_mask).where(sWIT.mask).plot(ax=ax1, levels=[0, 0.1, 0.33, 0.66, 1], colors = ndvi_pal)\n",
    "\n",
    "mpl.axes.Axes.set_aspect(ax1, aspect=1)#, anchor='C')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "045ab485daf24868b7c2382f424cbcb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_b0ea6054510a498e8a7c56ce35cc5c4c",
       "style": "IPY_MODEL_f660eac494c147198a27997ad8b22470"
      }
     },
     "0746427347e2416f920f9ce96228b721": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletGeoJSONModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "data": {
        "bbox": [
         142.4524578701443,
         -32.36320549945,
         142.54736615559136,
         -32.29586369982442
        ],
        "features": [
         {
          "bbox": [
           142.51524944800926,
           -32.31838789697648,
           142.54736615559136,
           -32.29586369982442
          ],
          "geometry": {
           "coordinates": [
            [
             [
              142.51524944800926,
              -32.296091685646715
             ],
             [
              142.546601533663,
              -32.29586369982442
             ],
             [
              142.54736615559136,
              -32.3183698586848
             ],
             [
              142.51526741493365,
              -32.31838789697648
             ],
             [
              142.51524944800926,
              -32.296091685646715
             ]
            ]
           ],
           "type": "Polygon"
          },
          "id": "0",
          "properties": {
           "id": 2,
           "style": {
            "color": "black",
            "fillColor": "#ffffcc",
            "fillOpacity": 0.8,
            "weight": 0.9
           }
          },
          "type": "Feature"
         },
         {
          "bbox": [
           142.4524578701443,
           -32.36320549945,
           142.4845749551165,
           -32.34069269280065
          ],
          "geometry": {
           "coordinates": [
            [
             [
              142.4524578701443,
              -32.340907825281136
             ],
             [
              142.483823262827,
              -32.34069269280065
             ],
             [
              142.4845749551165,
              -32.36320063502121
             ],
             [
              142.45246271443352,
              -32.36320549945
             ],
             [
              142.4524578701443,
              -32.340907825281136
             ]
            ]
           ],
           "type": "Polygon"
          },
          "id": "1",
          "properties": {
           "id": 1,
           "style": {
            "color": "black",
            "fillColor": "#800026",
            "fillOpacity": 0.8,
            "weight": 0.9
           }
          },
          "type": "Feature"
         }
        ],
        "type": "FeatureCollection"
       },
       "style": {
        "fillOpacity": 0.8
       }
      }
     },
     "140008a05899493688edb1cfd07bb91d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_8563b85ab05a465b900584182485dc98"
      }
     },
     "215e008ea30446418c9489a3fc2a3509": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     },
     "2f3cbd62daf645a4a47a3132fde027d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "height": "600px",
       "width": "800px"
      }
     },
     "331f5be31bf049e4a4c2ab49668abcdd": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "472e3957cd724d3fb57312a3fa86dae1": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     },
     "8563b85ab05a465b900584182485dc98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8912f038ad0947a7ae08ed0ccdb15644": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapModel",
      "state": {
       "_dom_classes": [],
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "basemap": {
        "attribution": "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community",
        "max_zoom": 20,
        "name": "Esri.WorldImagery",
        "url": "http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}"
       },
       "center": [
        -32.32953459963721,
        142.4999120128678
       ],
       "controls": [
        "IPY_MODEL_331f5be31bf049e4a4c2ab49668abcdd",
        "IPY_MODEL_472e3957cd724d3fb57312a3fa86dae1"
       ],
       "default_style": "IPY_MODEL_d14c0de5ce3b48bd9eb7729afbe8d701",
       "dragging_style": "IPY_MODEL_a6bbab8038c3446a93e3a549b8f8dd79",
       "east": 142.5685501098633,
       "fullscreen": false,
       "interpolation": "bilinear",
       "layers": [
        "IPY_MODEL_99119a1935514365b929a6d6c4b31a95",
        "IPY_MODEL_0746427347e2416f920f9ce96228b721"
       ],
       "layout": "IPY_MODEL_2f3cbd62daf645a4a47a3132fde027d0",
       "modisdate": "yesterday",
       "north": -32.28597166993233,
       "options": [
        "basemap",
        "bounce_at_zoom_limits",
        "box_zoom",
        "center",
        "close_popup_on_click",
        "double_click_zoom",
        "dragging",
        "fullscreen",
        "inertia",
        "inertia_deceleration",
        "inertia_max_speed",
        "interpolation",
        "keyboard",
        "keyboard_pan_offset",
        "keyboard_zoom_offset",
        "max_zoom",
        "min_zoom",
        "scroll_wheel_zoom",
        "tap",
        "tap_tolerance",
        "touch_zoom",
        "world_copy_jump",
        "zoom",
        "zoom_animation_threshold",
        "zoom_start"
       ],
       "south": -32.373002604986546,
       "style": "IPY_MODEL_215e008ea30446418c9489a3fc2a3509",
       "west": 142.4312210083008,
       "zoom": 13
      }
     },
     "99119a1935514365b929a6d6c4b31a95": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletTileLayerModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "attribution": "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community",
       "base": true,
       "max_native_zoom": 18,
       "max_zoom": 20,
       "min_native_zoom": 0,
       "min_zoom": 1,
       "name": "Esri.WorldImagery",
       "no_wrap": false,
       "options": [
        "attribution",
        "detect_retina",
        "max_native_zoom",
        "max_zoom",
        "min_native_zoom",
        "min_zoom",
        "no_wrap",
        "tile_size"
       ],
       "url": "http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}"
      }
     },
     "a6bbab8038c3446a93e3a549b8f8dd79": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "move"
      }
     },
     "b0ea6054510a498e8a7c56ce35cc5c4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d14c0de5ce3b48bd9eb7729afbe8d701": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     },
     "f660eac494c147198a27997ad8b22470": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
