{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: this notebook was recently moved into this folder.\n",
    "\n",
    "**Updating required for links etc**\n",
    "\n",
    "**Modified scripts from dea-notebooks also moved into this folder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and run analysis on multiple polygons <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with both the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[ga_ls8c_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Many users need to run analyses on their own areas of interest. \n",
    "A common use case involves running the same analysis across multiple polygons in a vector file (e.g. ESRI Shapefile or GeoJSON). \n",
    "This notebook will demonstrate how to use a vector file and the Open Data Cube to extract satellite data from Digital Earth Australia corresponding to individual polygon geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "If we have a vector file containing multiple polygons, we can use the python package [geopandas](https://geopandas.org/) to open it as a `GeoDataFrame`. \n",
    "We can then iterate through each geometry and extract satellite data corresponding with the extent of each geometry. \n",
    "Further anlaysis can then be conducted on each resulting `xarray.Dataset`.\n",
    "\n",
    "We can retrieve data for each polygon, perform an analysis like calculating NDVI and plot the data.\n",
    "\n",
    "1. First we open the vector file as a `geopandas.GeoDataFrame`\n",
    "2. Iterate through each polygon in the `GeoDataFrame`, and extract satellite data from DEA\n",
    "3. Calculate NDVI as an example analysis on one of the extracted satellite timeseries\n",
    "4. Plot NDVI for the polygon extent\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Please note the use of `datacube.utils` package `geometry`: \n",
    "this is important for saving the coordinate reference system of the incoming shapefile in a format that the Digital Earth Australia query can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "/env/lib/python3.6/site-packages/datacube/storage/masking.py:8: DeprecationWarning: datacube.storage.masking has moved to datacube.utils.masking\n",
      "  category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "\n",
    "import datacube\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.crs\n",
    "import rioxarray\n",
    "from datacube.utils import geometry\n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import datacube.utils.cog\n",
    "\n",
    "# import geopandas as gpd\n",
    "import ipyleaflet\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.cm\n",
    "import matplotlib.colors\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import odc.ui\n",
    "import rasterio.features\n",
    "import rioxarray\n",
    "import skimage.color as colour\n",
    "import skimage.io\n",
    "import sklearn.metrics\n",
    "import xarray as xr\n",
    "\n",
    "# import sys\n",
    "# import datacube\n",
    "from datacube.storage.masking import make_mask\n",
    "\n",
    "# from dea_datahandling import load_ard\n",
    "from dea_bandindices import calculate_indices\n",
    "from CP_dea_coastaltools import tidal_stats, tidal_tag\n",
    "from dea_dask import create_local_dask_cluster\n",
    "from dea_datahandling import array_to_geotiff, load_ard\n",
    "from CP_dea_plotting import display_map, map_shapefile, rgb\n",
    "from dea_spatialtools import xr_rasterize\n",
    "from dea_temporaltools import time_buffer\n",
    "from IPython.display import display\n",
    "from odc.ui import with_ui_cbk\n",
    "from shapely.geometry import shape, Polygon\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Connect to the datacube database to enable loading Digital Earth Australia data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/drivers/postgres/_connections.py:87: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n",
      "/env/lib/python3.6/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 44333 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44293</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/cp/proxy/44333/status' target='_blank'>/user/cp/proxy/44333/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>15</li>\n",
       "  <li><b>Memory: </b>125.85 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44293' processes=1 threads=15, memory=125.85 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc = datacube.Datacube(app=\"Analyse_multiple_polygons\")\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Load predetermined polygons and select a region of interest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dev/dea-notebooks/Claire\n"
     ]
    }
   ],
   "source": [
    "## User defines path to polygon vector file, file name and \n",
    "## the column name for unique integer identifiers for each vector object.\n",
    "%cd '/home/jovyan/dev/dea-notebooks/Claire/'\n",
    "# vector_file = \"QISMCQ_polygons.shp\"\n",
    "# attribute_col = \"id\"\n",
    "\n",
    "vector_file = \"GBR_NESP-TWQ-3-1_JCU_Seagrass_1984-2014_Meadow-boundaries.shp\"\n",
    "attribute_col = \"Unique_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b45ffa6dc9459184680e79e7456439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-17.623559, 147.327934], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_titleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the polygon vector file\n",
    "gdf_master = gpd.read_file(vector_file)\n",
    "\n",
    "# Set the crs to match the imagery data retrieved\n",
    "gdf_master.to_crs(epsg=3577, inplace=True)\n",
    "\n",
    "# # #  View the unique classes\n",
    "# # print(gdf_master[\"BRD_HAB\"].unique())\n",
    "\n",
    "# #  Drop unrequired classes\n",
    "# gdf_master = gdf_master.drop(\n",
    "#     gdf_master[\n",
    "#         (gdf_master.BRD_HAB == 'Subtidal consolidated substrate')\n",
    "#         | (gdf_master.BRD_HAB == 'Subtidal coral')\n",
    "#         | (gdf_master.BRD_HAB == 'Subtidal unconsolidated substrate') \n",
    "#         | (gdf_master.BRD_HAB == 'Subtidal seagrass')\n",
    "#         | (gdf_master.BRD_HAB == 'Subtidal algae')        \n",
    "#         | (gdf_master.BRD_HAB == 'Intertidal consolidated substrate')\n",
    "#         | (gdf_master.BRD_HAB == 'Intertidal coral')\n",
    "#         | (gdf_master.BRD_HAB == \"Intertidal unconsolidated substrate\")\n",
    "#         | (gdf_master.BRD_HAB == 'Intertidal algae')\n",
    "# #         | (gdf_master.BRD_HAB == 'Intertidal mangroves and other trees & shrubs')\n",
    "# #         | (gdf_master.BRD_HAB == 'Intertidal grass-herb-sedge-other succulent')\n",
    "# #         | (gdf_master.BRD_HAB == 'Intertidal seagrass')        \n",
    "#     ].index\n",
    "# )\n",
    "\n",
    "# #  Reset the index of the gdf to infill dropped values\n",
    "# gdf_master.reset_index(inplace=True)\n",
    "\n",
    "# #  Check that correct classes remain\n",
    "# print(gdf_master[\"BRD_HAB\"].unique())\n",
    "\n",
    "# # Attribute each class with an integer value\n",
    "# val = (gdf_master[\"BRD_HAB\"].unique()).tolist()\n",
    "\n",
    "# num_list = []\n",
    "# attr_key = []\n",
    "\n",
    "# d = 0\n",
    "# for x in range(len(gdf_master)):\n",
    "#     for d in range(len(val)):\n",
    "#         if gdf_master[\"BRD_HAB\"].values[x] == str(val[d]):\n",
    "#             num_list.append(d)\n",
    "#         # Create a key to interpret the integer attribute for each class\n",
    "#         for y in num_list:\n",
    "#             if y not in attr_key:\n",
    "#                 attr_key.append(y)\n",
    "\n",
    "# val = [[el] for el in val]\n",
    "# for x in attr_key:\n",
    "#     val[x].append(attr_key[x])\n",
    "\n",
    "\n",
    "# print(\"The attribute values for each class are as follows: \" + str(val))\n",
    "\n",
    "# # Update the geodataframe of vector polygons with the integer attribution for each class\n",
    "# gdf_master[\"id\"] = num_list\n",
    "\n",
    "# Map the shapefiles from imported vector set\n",
    "roi = map_shapefile(gdf_master, attribute=attribute_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give a name to your roi for file saving\n",
    "name = 'seagrass_substrates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This selection includes  11  individual polygons\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f77e3421828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "After identifying an analysis region of interest(roi) on the map,\n",
    "intersect the roi with the master polygon gdf from which imagery \n",
    "will be extracted. Note that when multiple areas are drawn on the\n",
    "map above, it is the final roi that is used for analysis in the \n",
    "following cells\n",
    "'''\n",
    "\n",
    "##  Form a shapely polygon from the coordinates defined by the user on the map\n",
    "polygon_roi = Polygon(roi[-1]['geometry']['coordinates'][0])\n",
    "\n",
    "##  Generate a new geodataframe containing the user defined polygon geometry\n",
    "newdf = gpd.GeoDataFrame(gpd.GeoSeries(polygon_roi), columns=['geometry'], crs='EPSG:4326')\n",
    "newdf = newdf.to_crs(gdf_master.crs)\n",
    "\n",
    "##  Intersect the user-defined region of interest with the master\n",
    "##  to create the working gdf from which imagery will be extracted\n",
    "gdf = gpd.overlay(gdf_master, newdf, how='intersection')\n",
    "print('This selection includes ', len(gdf), ' individual polygons')\n",
    "gdf.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load imagery for the region of interest\n",
    "\n",
    "*user to define time-period of interest in the query*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1/11\n",
      "0\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1306\n",
      "Survey_Dat                                               Nov 02\n",
      "Method                                          GPS; helicopter\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                                           Intertidal\n",
      "Density                                                 Unknown\n",
      "Dominant_s                                   Zostera capricorni\n",
      "Spp_presen                                   Zostera capricorni\n",
      "Mean_bioma                                                  n/a\n",
      "Area_ha                                                 0.10 ha\n",
      "Hectares                                              0.0876546\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1967297.065786773 -2749893.180841732...\n",
      "Name: 0, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 658 out of 1125 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 658 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.63, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (1, 3)\n",
      "1306.0 0\n",
      "----------------------\n",
      "Feature 2 is a multipolygon and is excluded from this analysis\n",
      "----------------------\n",
      "Feature: 3/11\n",
      "2\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1314\n",
      "Survey_Dat    Nov 02; Nov 04; Oct 05; Oct 06; Oct 07; Nov 08...\n",
      "Method                                          GPS; helicopter\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                                           Intertidal\n",
      "Density                                                   Light\n",
      "Dominant_s                  Halophila ovalis/Zostera capricorni\n",
      "Spp_presen                 Halophila ovalis, Zostera capricorni\n",
      "Mean_bioma                 0.01 +/- 0 to 28.11 +/- 7.67 g DW m2\n",
      "Area_ha                       2.16 +/- 0.35 to 3.90 +/- 1.10 ha\n",
      "Hectares                                                5.23567\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1969753.322244055 -2751303.756782566...\n",
      "Name: 2, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 644 out of 1146 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 644 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.66, -24.08\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (14, 11)\n",
      "1314.0 2\n",
      "----------------------\n",
      "Feature: 4/11\n",
      "3\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1308\n",
      "Survey_Dat    Nov 02; Nov 04; Oct 05; Oct 06; Oct 07; Nov 08...\n",
      "Method                                          GPS; helicopter\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                                           Intertidal\n",
      "Density                                                   Light\n",
      "Dominant_s                                   Zostera capricorni\n",
      "Spp_presen    Halophila decipiens, Halophila ovalis, Zostera...\n",
      "Mean_bioma              0.67 +/- 0.34 to 24.84 +/- 5.01 g DW m2\n",
      "Area_ha                     10.14 +/- 1.32 to 329.9 +/- 11.6 ha\n",
      "Hectares                                                 367.67\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1969741.722116891 -2748614.127950293...\n",
      "Name: 3, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 471 out of 1146 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 471 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.66, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (139, 103)\n",
      "1308.0 3\n",
      "----------------------\n",
      "Feature 5 is a multipolygon and is excluded from this analysis\n",
      "----------------------\n",
      "Feature: 6/11\n",
      "5\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1310\n",
      "Survey_Dat                                               Nov 02\n",
      "Method                                          GPS; helicopter\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                                           Intertidal\n",
      "Density                                                   Light\n",
      "Dominant_s                                     Halophila ovalis\n",
      "Spp_presen                                     Halophila ovalis\n",
      "Mean_bioma                                   0.25 +/- 0 g DW m2\n",
      "Area_ha                                                 2.10 ha\n",
      "Hectares                                                2.05952\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1972056.363828558 -2753531.030259382...\n",
      "Name: 5, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 605 out of 1146 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 605 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.68, -24.10\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (14, 5)\n",
      "1310.0 5\n",
      "----------------------\n",
      "Feature: 7/11\n",
      "6\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1316\n",
      "Survey_Dat                       Nov 02; Nov 09; Nov 13; Nov 14\n",
      "Method                                          GPS; helicopter\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                                           Intertidal\n",
      "Density                                                   Light\n",
      "Dominant_s                                   Zostera capricorni\n",
      "Spp_presen    Halodule uninervis, Halophila decipiens, Halop...\n",
      "Mean_bioma              2.71 +/- 1.44 to 11.49 +/- 5.11 g DW m2\n",
      "Area_ha                           111.22 +/- 10.18 to 879.30 ha\n",
      "Hectares                                                937.286\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1970890.815143373 -2748528.955301277...\n",
      "Name: 6, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 517 out of 1146 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 517 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.67, -24.06\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (76, 78)\n",
      "1316.0 6\n",
      "----------------------\n",
      "Feature: 8/11\n",
      "7\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1311\n",
      "Survey_Dat    Nov 02; Nov 04; Oct 05; Oct 06; Oct 07; Nov 08...\n",
      "Method                                          GPS; helicopter\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                                           Intertidal\n",
      "Density                                                   Light\n",
      "Dominant_s                                   Zostera capricorni\n",
      "Spp_presen    Halophila decipiens, Halophila ovalis, Zostera...\n",
      "Mean_bioma              0.48 +/- 0.19 to 25.20 +/- 7.09 g DW m2\n",
      "Area_ha                                       0.008 to 47.70 ha\n",
      "Hectares                                                108.143\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1970379.012727735 -2751515.240684755...\n",
      "Name: 7, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 514 out of 1146 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 514 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.67, -24.09\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (97, 69)\n",
      "1311.0 7\n",
      "----------------------\n",
      "Feature: 9/11\n",
      "8\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1312\n",
      "Survey_Dat                               Nov 02; Nov 09; Nov 14\n",
      "Method                                          GPS; helicopter\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                                           Intertidal\n",
      "Density                                                   Light\n",
      "Dominant_s                  Halophila ovalis/Zostera capricorni\n",
      "Spp_presen    Halophila decipiens, Halophila ovalis, Zostera...\n",
      "Mean_bioma               0.72 +/- 0.33 to 1.31 +/- 0.96 g DW m2\n",
      "Area_ha                              50.73 +/- 4.10 to 76.80 ha\n",
      "Hectares                                                90.1294\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1970171.856802691 -2751918.968065874...\n",
      "Name: 8, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 513 out of 1146 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 513 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.66, -24.09\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (72, 58)\n",
      "1312.0 8\n",
      "----------------------\n",
      "Feature: 10/11\n",
      "9\n",
      "NRM_Region                                         Burnett Mary\n",
      "Unique_ID                                                  1307\n",
      "Survey_Dat                       Nov 02; Nov 09; Nov 13; Nov 14\n",
      "Method                          GPS; boat - camera, diver, grab\n",
      "Persistenc                                      Variable meadow\n",
      "Meadow_loc                        Intertidal - shallow subtidal\n",
      "Density                                                   Light\n",
      "Dominant_s                                   Zostera capricorni\n",
      "Spp_presen    Halodule uninervis, Halophila decipiens, Halop...\n",
      "Mean_bioma                 0.18 +/- 0 to 16.89 +/- 7.45 g DW m2\n",
      "Area_ha                         2.50 +/- 0.50 to 52.60 +/- 0 ha\n",
      "Hectares                                                98.3098\n",
      "Percent_co                                                  n/a\n",
      "Custodian                      TropWATER; James Cook University\n",
      "Comments                                                   None\n",
      "geometry      POLYGON ((1968293.501907992 -2749455.640992146...\n",
      "Name: 9, dtype: object\n",
      "Finding datasets\n",
      "    ga_ls5t_ard_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Scripts/dea_datahandling.py:238: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\"Setting 'min_gooddata' percentage to > 0.0 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ga_ls7e_ard_3 (ignoring SLC-off observations)\n",
      "    ga_ls8c_ard_3\n",
      "    nidem\n",
      "    item_v2\n",
      "    item_v2_conf\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 517 out of 1146 time steps with at least 90.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 517 time steps as a dask array\n",
      "Setting tide modelling location from dataset centroid: 151.64, -24.07\n",
      "Modelling tidal phase (e.g. ebb or flow)\n",
      "Rasterizing to match xarray.DataArray dimensions (99, 65)\n",
      "1307.0 9\n",
      "----------------------\n",
      "Feature 11 is a multipolygon and is excluded from this analysis\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Setup the general query and variables for later\n",
    "products = [\"ga_ls5t_ard_3\",\n",
    "            \"ga_ls7e_ard_3\",\n",
    "            \"ga_ls8c_ard_3\",\n",
    "            'nidem',\n",
    "            'item_v2',\n",
    "            'item_v2_conf']\n",
    "align = (0, 0)\n",
    "\n",
    "# Query\n",
    "query = {\n",
    "    \"time\": (\"1988-01-01\", \"2021-01-01\"),\n",
    "    \"measurements\": [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"nbart_nir\", \"nbart_swir_1\"],\n",
    "    \"output_crs\": \"EPSG:3577\", # Do not change th\n",
    "    \"resolution\": (-30, 30),\n",
    "    \"group_by\": \"solar_day\",\n",
    "    \"dask_chunks\": {\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "}\n",
    "\n",
    "# Designate dask chunks\n",
    "# It doesn't really matter how big the chunks we load are, as long as time ~ 1.\n",
    "# chunks = {\"time\": 1, \"x\": 3000, \"y\": 3000}\n",
    "\n",
    "# Load data for predetermined polygons\n",
    "# Dictionary to save results\n",
    "results = {}\n",
    "\n",
    "'''List of saved tideposts. In the event that a polygon centroid geometry fails\n",
    "to return an associated tideheight, the tidal_tag function will bring in this list\n",
    "and use the most recent successful polygon centroid geometry to calculate a tideheight\n",
    "for the current polygon'''\n",
    "tideposts = [[0,0]]\n",
    "\n",
    "# Loop through polygons in geodataframe and extract satellite data\n",
    "for index, row in gdf.iterrows():\n",
    "\n",
    "    ## Skip multipolygons which break the loops\n",
    "    if type(row.geometry) == Polygon: \n",
    "    \n",
    "        print(f\"Feature: {index + 1}/{len(gdf)}\")\n",
    "#         print(gdf[\"BRD_HAB\"].values[index])\n",
    "        print(str(index))\n",
    "        print(str(row))\n",
    "\n",
    "        if not (str(row[attribute_col]) in results.keys()):\n",
    "            results[str(row[attribute_col])] = {}\n",
    "\n",
    "        # Extract the feature's geometry as a datacube geometry object\n",
    "        geom = geometry.Geometry(geom=row.geometry, crs=gdf.crs)\n",
    "\n",
    "        # Update the query to include our geopolygon\n",
    "        query.update({\"geopolygon\": geom})\n",
    "\n",
    "        # Load landsat\n",
    "        ds = load_ard(\n",
    "            dc=dc,\n",
    "            products=products,\n",
    "            min_gooddata=0.90,  # only take uncloudy scenes\n",
    "            ls7_slc_off=False,\n",
    "            skip_broken_datasets=True, ## New line 25/02/2021 TEMP fix while lingering ARD issue sorted\n",
    "            **query,\n",
    "        )\n",
    "\n",
    "        ## Tidally tag datasets\n",
    "        ds, tidepost_lon, tidepost_lat = tidal_tag(ds,\n",
    "                                                   tideposts[-1],\n",
    "                                                   return_tideposts=True,\n",
    "                                                   ebb_flow=True)\n",
    "        tideposts.append([tidepost_lon, tidepost_lat])\n",
    "\n",
    "        # Generate a polygon mask to keep only data within the polygon\n",
    "        mask = xr_rasterize(gdf.iloc[[index]], ds)\n",
    "\n",
    "        # Mask dataset to set pixels outside the polygon to `NaN`\n",
    "        ds = ds.where(mask)\n",
    "\n",
    "#         ## Attach unique polygon id to each dataset\n",
    "#         attrs = {'pgid': row['OBJECTID']}\n",
    "#         ds.attrs = attrs\n",
    "\n",
    "        ## Append results to a dictionary using the attribute\n",
    "        ## column as an key\n",
    "        results[str(row[attribute_col])][str(index)] = ds\n",
    "\n",
    "        print(row[attribute_col], index)\n",
    "        print(\"----------------------\")\n",
    "        \n",
    "    else:\n",
    "        print ('Feature', index +1, 'is a multipolygon and is excluded from this analysis')\n",
    "        print(\"----------------------\")\n",
    "        continue\n",
    "\n",
    "## Drop gdf rows associated with multipolygons\n",
    "for index, row in gdf.iterrows():\n",
    "    if type(row.geometry) == Polygon: \n",
    "        pass\n",
    "    else:\n",
    "        gdf.drop(labels=index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter results by tide height, calculate indices and build ITEM masks\n",
    "\n",
    "*user to define tide_range to keep - set the desired quantile value in `lowest_20` variable*\n",
    "\n",
    "*user defines required indices in the `calculate_indices` function call*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-daf62acd3667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NDVI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NDWI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#,'MNDWI', 'NDAVI', 'WAVI', 'EVI', 'SAVI',  'LAI'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                \u001b[0mcollection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ga_ls_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                inplace=True)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#         # Add tide_height back in to calculate ITEM mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/dea-notebooks/Scripts/dea_bandindices.py\u001b[0m in \u001b[0;36mcalculate_indices\u001b[0;34m(ds, index, collection, custom_varname, normalise, drop, inplace)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;31m# If normalised=True, divide data by 10,000 before applying func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mmult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalise\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands_to_rename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             raise ValueError(f'Please verify that all bands required to '\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4957\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4958\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4959\u001b[0;31m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_binary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4960\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_calculate_binary_op\u001b[0;34m(self, f, other, join, inplace)\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5029\u001b[0m             \u001b[0mother_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"variable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5030\u001b[0;31m             \u001b[0mnew_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_variable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5031\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5032\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5029\u001b[0m             \u001b[0mother_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"variable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5030\u001b[0;31m             \u001b[0mnew_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_variable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5031\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5032\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 new_data = (\n\u001b[1;32m   2130\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m                 )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "results2 = {}\n",
    "x=1\n",
    "\n",
    "for k in results:\n",
    "\n",
    "    if not (str(k) in results2.keys()):\n",
    "        results2[str(k)] = {}\n",
    "        \n",
    "    for kk in results[k]:\n",
    "        \n",
    "        ds = results[k][kk] \n",
    "        \n",
    "        ## Save attributes to reattach later\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        ## Filter data by tide height\n",
    "        lowest_10 = ds.tide_height.quantile([0.10]).values\n",
    "        lowest_20 = ds.tide_height.quantile([0.20]).values  \n",
    "        results2[k][kk] = ds.where(ds.tide_height <= lowest_20, drop=True)      \n",
    "        \n",
    "        ## Compute data from dask - WARNING: time consuming step!\n",
    "        results2[k][kk] = results2[k][kk].compute()       \n",
    "        ds = results2[k][kk]\n",
    "       \n",
    "        ## Drop tide_height and ebb_flow variables\n",
    "        '''\n",
    "        works around the calculate_indices function which was stalling on the additional \n",
    "        coastal variables, drop tide_height and ebb_flow variables\n",
    "        '''\n",
    "#         tide_height = ds['tide_height']\n",
    "#         ebb_flow = ds['ebb_flow']\n",
    "#         ds = ds.drop_vars(names = ('tide_height', 'ebb_flow'))\n",
    "        \n",
    "        # calculate ndvi for pixels inside the polygon\n",
    "        ds = calculate_indices(ds, \n",
    "                               index=['NDVI', 'NDWI'], #,'MNDWI', 'NDAVI', 'WAVI', 'EVI', 'SAVI',  'LAI'], \n",
    "                               collection='ga_ls_3', \n",
    "                               inplace=True)\n",
    "        \n",
    "#         # Add tide_height back in to calculate ITEM mask\n",
    "#         ds['tide_height'] = tide_height\n",
    "\n",
    "        ## Prepare data to calculate ITEM masks\n",
    "        lowest_10 = ds.where(ds.tide_height <= lowest_10, drop=True)\n",
    "        lowest_20 = ds.where(ds.tide_height <= lowest_20, drop=True)\n",
    "\n",
    "        ## Calculate ITEM layers\n",
    "        lowest_10_mask = lowest_10[['NDWI', 'tide_height']].median(dim='time')\n",
    "        lowest_20_mask = lowest_20[['NDWI', 'tide_height']].median(dim='time')\n",
    "        \n",
    "#         # Add ITEM mask layers to results2 datasets\n",
    "        results2[k][kk]['lowest_10_mask'] = lowest_10_mask.NDWI <= 0 \n",
    "        results2[k][kk]['lowest_20_mask'] = lowest_20_mask.NDWI <= 0 \n",
    "        \n",
    "        results2[str(k)][str(kk)] = xr.merge([results2[str(k)][str(kk)], ds])\n",
    "        \n",
    "        ## Attach unique polygon id to each dataset\n",
    "        results2[str(k)][str(kk)].attrs = attrs\n",
    "        \n",
    "        print(f\"Completed feature: {x}/{len(gdf)}\") \n",
    "        \n",
    "        x=x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save loaded results\n",
    "*By default, save the imagery and polygon sub-sampled datasets every time.*\n",
    "\n",
    "*If required to load last dataset, hash out the `save` calls and unhash the `load` calls*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-----------------------------------------'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save variables\n",
    "\n",
    "## Save imagery dict\n",
    "with open('results2_' + query['time'][0] + '_'+ name +'.pickle', 'wb') as handle:\n",
    "    pickle.dump(results2, handle)\n",
    " \n",
    "## Save polygon gdf   \n",
    "with open('gdf_' + query['time'][0] + '_'+ name +'.pickle', 'wb') as handle:\n",
    "    pickle.dump(gdf, handle)\n",
    "    \n",
    "'''-----------------------------------------'''\n",
    "\n",
    "# # Load saved variables (hashed out by default)\n",
    "\n",
    "# ## Load the name for your roi\n",
    "# name = 'Rodds_Bay'\n",
    "\n",
    "# ## Re-load the query\n",
    "\n",
    "# # Setup the general query and variables for later\n",
    "# products = [\"ga_ls8c_ard_3\"]\n",
    "# align = (0, 0)\n",
    "\n",
    "# # Query\n",
    "# query = {\n",
    "#     \"time\": (\"2013-01-01\", \"2020-08-01\"),\n",
    "#     \"measurements\": [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"nbart_nir\", \"nbart_swir_1\"],\n",
    "#     \"output_crs\": \"EPSG:3577\", # Do not change th\n",
    "#     \"resolution\": (-30, 30),\n",
    "#     \"group_by\": \"solar_day\",\n",
    "#     \"dask_chunks\": {\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "# }\n",
    "\n",
    "# ## ensure that you are working from the same directory as the files are stored\n",
    "# %cd '/home/jovyan/dev/dea-notebooks/Claire'\n",
    "\n",
    "# ## Load imagery dict\n",
    "# with open('results2_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     results2 = pickle.load(handle)\n",
    "\n",
    "# ## Load polygon gdf    \n",
    "# with open('gdf_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     gdf = pickle.load(handle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "Load the following cell to define the functions that enable data interrogation and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### funcs for py script\n",
    "\n",
    "## Testing updated coastal_wit func. Drafted in BKUP notebook and copied over to this cell\n",
    "\n",
    "def coastal_wit(\n",
    "               results2,\n",
    "               pg,\n",
    "               ITEM_mask = 'lowest_20_mask',\n",
    "               classes = False\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Takes a polygon or polygons in a region of interest ([pg]) from the gdf of polygon shapefiles and extracts \n",
    "    and plots the frequency of pixels as assigned into class ranges of NDVI. Also includes pixels identified\n",
    "    as wet. All NDVI pixels are masked by 'dry' range of NDWI and everything is masked by the ITEM mask.\n",
    "    If conditional dataset dropping is required, set drop=True and nominate the percent of wet pixels\n",
    "    tolerated and the minimum number of allowable pixels (e.g. pc_drop=90 means drop any timestep dataset\n",
    "    when more than 90% of pixels are wet; px_min=5 means that a timestep dataset will only be dropped\n",
    "    when more than pc_drop pixels are wet AND the remaining pixels sum to less than or = px_min - or\n",
    "    5 in this case)\n",
    "    If the WIT datasets have already been generated and included in the xarray dataset (`results2`) then \n",
    "    set `classes = True` to avoid re-calculation. Default is False.\n",
    "    ITEM_mask is the layer to nominate for ITEM masking. If no masking required, select one of the \n",
    "    original bands such as 'nbart_red'\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    ## Set up lists to extract pixel counts per timestep into\n",
    "    ls_pixels = []\n",
    "    ls_ndwi = []\n",
    "    ls_unveg = []\n",
    "    ls_ndvilow = []\n",
    "    ls_ndvimid = []\n",
    "    ls_ndvihigh = []\n",
    "    ls_pxsum = []\n",
    "    ls_tide = []\n",
    "    ls_index = []\n",
    "\n",
    "    ##  Data prep for WIT prototype (automated for all timesteps for all polygons)\n",
    "\n",
    "    ##  Generate all datasets for the stacked line plot (WIT) by adding as variables to results dataset\n",
    "    for k in results2:\n",
    "        for kk in results2[k]: \n",
    "\n",
    "            if classes == False:\n",
    "\n",
    "                ##  Add a non-water pixel mask variable\n",
    "                results2[k][kk]['mask'] = ((results2[k][kk].NDWI)\n",
    "                                           .where(results2[k][kk][ITEM_mask]) <= 0)\n",
    "\n",
    "                ##  Generate the NDWI_water class\n",
    "                results2[k][kk]['ndwi_water'] = ((results2[k][kk].NDWI)\n",
    "                                                  .where(results2[k][kk][ITEM_mask]) > 0)\n",
    "\n",
    "                ##  Generate NDVI classes\n",
    "\n",
    "                ##  NDVI less than 0.1\n",
    "                results2[k][kk]['unveg'] = (results2[k][kk].NDVI\n",
    "                                            .where((results2[k][kk].NDVI < 0.1).astype(int))\n",
    "                                            .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ##  NDVI 0.1 to 0.33\n",
    "                results2[k][kk]['ndvi_low'] = (results2[k][kk].NDVI\n",
    "                                               .where((results2[k][kk].NDVI >= 0.1).astype(int) & \n",
    "                                                      (results2[k][kk].NDVI < 0.333).astype(int))\n",
    "                                               .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ##  NDVI 0.33 to 0.66\n",
    "                results2[k][kk]['ndvi_mid'] = (results2[k][kk].NDVI\n",
    "                                               .where((results2[k][kk].NDVI >= 0.333).astype(int) & \n",
    "                                                      (results2[k][kk].NDVI < 0.666).astype(int))\n",
    "                                               .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ### NDVI 0.66 to 1\n",
    "                results2[k][kk]['ndvi_high'] = (results2[k][kk].NDVI\n",
    "                                                .where((results2[k][kk].NDVI >= 0.666).astype(int) & \n",
    "                                                       (results2[k][kk].NDVI <= 1).astype(int))\n",
    "                                                .where(results2[k][kk][ITEM_mask]))\n",
    "\n",
    "                ##  Mask the NDVI classes to show non-water pixels only\n",
    "                results2[k][kk]['unveg'] = results2[k][kk]['unveg'].where(results2[k][kk]['mask'])\n",
    "                results2[k][kk]['ndvi_low'] = results2[k][kk]['ndvi_low'].where(results2[k][kk]['mask'])\n",
    "                results2[k][kk]['ndvi_mid'] = results2[k][kk]['ndvi_mid'].where(results2[k][kk]['mask'])\n",
    "                results2[k][kk]['ndvi_high'] = results2[k][kk]['ndvi_high'].where(results2[k][kk]['mask'])\n",
    "\n",
    "                for x in pg:\n",
    "                    if x == results2[str(k)][str(kk)].attrs['pgid']:\n",
    "                         ##  Populate pixel count lists per class per timestep\n",
    "                        for t in range (0, len(results2[str(k)][str(kk)].time)):\n",
    "                            ls_pixels.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].where(results2[k][kk][ITEM_mask]).isel(time=t).nbart_red)))\n",
    "                            ls_ndwi.append(np.count_nonzero(results2[str(k)][str(kk)].isel(time=t).ndwi_water))\n",
    "                            ls_unveg.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).unveg)))\n",
    "                            ls_ndvilow.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).ndvi_low)))\n",
    "                            ls_ndvimid.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).ndvi_mid)))\n",
    "                            ls_ndvihigh.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].isel(time=t).ndvi_high)))\n",
    "                            ls_pxsum.append(np.count_nonzero(~np.isnan(results2[str(k)][str(kk)].where(results2[k][kk][ITEM_mask]).isel(time=t).nbart_red)))\n",
    "                            ls_tide.append(results2[str(k)][str(kk)].isel(time=t).tide_height.median().values)\n",
    "\n",
    "                        ls_index.append(results2[str(k)][str(kk)].time.values)\n",
    "    ls_index = np.concatenate(ls_index).tolist()\n",
    "#                                 index = results2[str(k)][str(kk)].time.values\n",
    "\n",
    "#         if classes == True:\n",
    "\n",
    "#              ##  Populate pixel count lists per class per timestep\n",
    "#             for t in range (0, len(results2.time)):\n",
    "#                 ls_pixels.append(np.count_nonzero(~np.isnan(results2.isel(time=t).nbart_red)))\n",
    "# #                 ls_mndwi.append(np.count_nonzero((results2.isel(time=t).mndwi_water)))\n",
    "#                 ls_mndwi.append(np.count_nonzero(~np.isnan(mWIT1.isel(time=t).mndwi_water.where(mWIT1.isel(time=t).mndwi_water == True))))\n",
    "#                 ls_unveg.append(np.count_nonzero(~np.isnan(results2.isel(time=t).unveg)))\n",
    "#                 ls_ndvilow.append(np.count_nonzero(~np.isnan(results2.isel(time=t).ndvi_low)))\n",
    "#                 ls_ndvimid.append(np.count_nonzero(~np.isnan(results2.isel(time=t).ndvi_mid)))\n",
    "#                 ls_ndvihigh.append(np.count_nonzero(~np.isnan(results2.isel(time=t).ndvi_high)))\n",
    "#                 ls_pxsum.append(np.count_nonzero(~np.isnan(results2.isel(time=t).nbart_red)))\n",
    "#                 ls_tide.append(results2.isel(time=t).tide_height.median().values)\n",
    "\n",
    "#                 index = results2.time.values\n",
    "\n",
    "\n",
    "    ## Return index values to datetime64\n",
    "    for x in range(0, len(ls_index)):\n",
    "        ls_index[x] = np.datetime64(int(ls_index[x]), 'ns')\n",
    "\n",
    "    ##  Generate a dataframe summarising class pixel counts per timestep\n",
    "    classes_df = pd.DataFrame(\n",
    "                {\"pixels\": ls_pixels,\n",
    "                \"water\": ls_ndwi,\n",
    "                \"unveg\": ls_unveg,\n",
    "                \"ndvi_low\": ls_ndvilow,\n",
    "                \"ndvi_mid\": ls_ndvimid,\n",
    "                \"ndvi_high\": ls_ndvihigh,\n",
    "                \"px_sum\": ls_pxsum,\n",
    "                \"tide_height\": ls_tide},\n",
    "                index = ls_index\n",
    "                )\n",
    "\n",
    "    ## Aggregate the datasets to account for identical imagery dates spanning different polygons\n",
    "    ## All pixel values are summed. Tide_height values are averaged\n",
    "    ## Separate tide_height dataset and convert to dataframe\n",
    "    classes_df_th = classes_df.tide_height\n",
    "    classes_df_th = pd.DataFrame(classes_df_th)\n",
    "\n",
    "    ## Drop tide_height from main df then group rows with duplicate indices and then sum them up\n",
    "    classes_df = classes_df.drop(['tide_height'], axis=1)\n",
    "    classes_df = classes_df.groupby(classes_df.index).sum()\n",
    "\n",
    "    ## Take tide-height values and convert from array to int\n",
    "    intlist=[]\n",
    "    for x in range (0,len(classes_df_th.tide_height.values.tolist())):\n",
    "        intlist.append(classes_df_th.tide_height.values.tolist()[x].tolist())\n",
    "\n",
    "    ## Add integer list to tide_height dataframe and drop array list\n",
    "    classes_df_th['th_int'] = intlist\n",
    "    classes_df_th = classes_df_th.drop('tide_height', axis=1)\n",
    "\n",
    "    ## Group by index dates as per classes_df and calculate mean tide_height value\n",
    "    classes_df_th = classes_df_th.groupby(classes_df_th.index).mean()\n",
    "\n",
    "    ## Merge the pixel and tide_height datasets back together\n",
    "    classes_df = classes_df.merge(classes_df_th, left_on = classes_df.index, right_on = classes_df_th.index)\n",
    "\n",
    "    ## Rename tide_height column to something sensible\n",
    "    classes_df = classes_df.rename(columns={'th_int':'tide_height'})\n",
    "\n",
    "    ## Reset the index to observation dates\n",
    "    classes_df.set_index('key_0', inplace=True)\n",
    "\n",
    "    ##  Normalise pixel counts per class per timestep\n",
    "    classes_df['pc_water'] = classes_df['water']/classes_df['pixels']*100\n",
    "    classes_df['pc_unveg'] = classes_df['unveg']/classes_df['pixels']*100\n",
    "    classes_df['pc_ndvi_low'] = classes_df['ndvi_low']/classes_df['pixels']*100\n",
    "    classes_df['pc_ndvi_mid'] = classes_df['ndvi_mid']/classes_df['pixels']*100\n",
    "    classes_df['pc_ndvi_high'] = classes_df['ndvi_high']/classes_df['pixels']*100\n",
    "    classes_df['pc_total'] = (classes_df['pc_water']+\n",
    "                              classes_df['pc_unveg']+\n",
    "                              classes_df['pc_ndvi_low']+\n",
    "                              classes_df['pc_ndvi_mid']+\n",
    "                              classes_df['pc_ndvi_high'])\n",
    "    classes_df['pc_exposedpx'] = (classes_df['unveg']+\n",
    "                                  classes_df['ndvi_low']+\n",
    "                                  classes_df['ndvi_mid']+\n",
    "                                  classes_df['ndvi_high'])/classes_df['px_sum']*100\n",
    "\n",
    "\n",
    "    return classes_df, results2\n",
    "\n",
    "def onclick_timeseries(event):\n",
    "    '''\n",
    "    This widget allows the user to select a time point from a plotted time series. \n",
    "    It then translates the chosen point back into the approriate datetime object so\n",
    "    that it can be used to find the location of this time point within the extracted\n",
    "    datasets. The index location of this time step is also returned. \n",
    "    \n",
    "    '''\n",
    "    global time_slice, TimeIndex, pixelx, pixely\n",
    "    \n",
    "    # Get time from x axis of plot \n",
    "    timeOfInterest = event.xdata\n",
    "    \n",
    "    # Get x and y coordinates from click\n",
    "    pixelx, pixely = int(event.xdata), int(event.ydata)\n",
    "    \n",
    "    # Add point to image\n",
    "    plt.plot(pixelx, pixely, 'ro', markersize=5)\n",
    "    \n",
    "    # Convert clicked int to datetime format\n",
    "    time_slice = matplotlib.dates.num2date(timeOfInterest).date()\n",
    "    \n",
    "    # Convert clicked value to str\n",
    "    time_slice = str(time_slice)\n",
    "    \n",
    "    # Convert clicked value to correct datetime format\n",
    "    time_slice = pd.to_datetime(time_slice, format='%Y-%m-%d')\n",
    "    \n",
    "    # Find the time index of the chosen time slice\n",
    "    TimeIndex = results2[str(cl)][str(pg1)].indexes['time'].get_loc(time_slice, method='nearest')\n",
    "    \n",
    "    # Print the date of the image closest to clicked pixel\n",
    "    ClosestImage = results2[str(cl)][str(pg1)].time[TimeIndex].values\n",
    "    \n",
    "    # Update text below plot\n",
    "    w2.value = 'Closest imagery date : {}'.format(ClosestImage)\n",
    "    \n",
    "        \n",
    "def temporal_stats (gdf, \n",
    "                    results2,\n",
    "                    zonal=True,\n",
    "                    pixel=True,\n",
    "                    mask= 'lowest_20_mask'):\n",
    "\n",
    "    '''\n",
    "    This function calculates and returns the temporal mean and standard deviation\n",
    "    for a range of indices for every polygon and every pixel within\n",
    "    every polygon in the form of a geodataframe.  \n",
    "    For now, leave zonal and pixel set to True to calculate all results. Func may\n",
    "    not work if either of these vars are set to False.\n",
    "    ITEM masking is available using the `mask` variable. If no masking is required, set\n",
    "    this variable to one of the bands such as 'nbart_nir'. If masking, two ITEM\n",
    "    layers are generated by default to choose from. Either 'lowest_20_mask' for\n",
    "    all images except those associated with the lowest 20% of observed tides, or\n",
    "    'lowest_10_mask' to mask by the equivalent in the 10% range.\n",
    "    '''\n",
    "    ##  Spectral indices available in the `calculate_indices` function (dea_bandindices.py)\n",
    "    index_ls = [\n",
    "        \"NDVI\",\n",
    "        \"EVI\",\n",
    "        \"NDAVI\", \n",
    "        \"WAVI\",\n",
    "        \"LAI\",\n",
    "        \"SAVI\",\n",
    "        \"MSAVI\",\n",
    "        \"NDMI\",\n",
    "        \"NBR\",\n",
    "        \"BAI\",\n",
    "        \"NDCI\",\n",
    "        \"NDSI\",\n",
    "        \"NDTI\",\n",
    "        \"NDWI\",\n",
    "        \"MNDWI\",\n",
    "        \"NDBI\",\n",
    "        \"BUI\",\n",
    "        \"BAEI\",\n",
    "        \"NBI\",\n",
    "        \"BSI\",\n",
    "        \"AWEI_ns\",\n",
    "        \"AWEI_sh\",\n",
    "        \"WI\",\n",
    "        \"TCW\",\n",
    "        \"TCG\",\n",
    "        \"TCB\",\n",
    "        \"CMR\",\n",
    "        \"FMR\",\n",
    "        \"IOR\",\n",
    "    ]\n",
    "\n",
    "       \n",
    "    \n",
    "    ## Calculate zonal polygon results\n",
    "    if zonal:\n",
    "        \n",
    "        gdf_zonal = gdf \n",
    "        \n",
    "        ##  Generate a list of keys for polygons in class '0' of results2\n",
    "        keylist = list(results2['0'].keys())\n",
    "\n",
    "        ##  For each nominated indice:\n",
    "        for var in index_ls:\n",
    "            if var in results2[\"0\"][keylist[0]].var():\n",
    "\n",
    "                lsmean = []\n",
    "                lsstd = []\n",
    "\n",
    "                ##  Generate zonal indice stats for polygon followed by temporal statistic\n",
    "                ##  Append polygon id and temporal statistic to gdf\n",
    "                for k in results2:\n",
    "\n",
    "                    for kk in results2[k]:\n",
    "                        temporalmean = ((results2[k][kk][var]\n",
    "                                         .where(results2[k][kk][mask])\n",
    "                                         .mean('y')\n",
    "                                         .mean('x'))\n",
    "                                         .mean())\n",
    "                        lsmean.append([int(kk), temporalmean.values])\n",
    "                        name1 = str(var) + ' zonal mean'\n",
    "                        results2[str(k)][str(kk)][name1] = (temporalmean.values)\n",
    "                        \n",
    "                        temporalstd = ((results2[k][kk][var]\n",
    "                                        .where(results2[k][kk][mask])\n",
    "                                        .std('y')\n",
    "                                        .std('x'))\n",
    "                                        .std())\n",
    "                        lsstd.append([int(kk), temporalstd.values])  \n",
    "                        name2 = str(var) + ' zonal std'\n",
    "                        results2[str(k)][str(kk)][name2] = (temporalstd.values)                        \n",
    "\n",
    "                ##  Sort the list by polygon id to match up to the original polygon gdf\n",
    "                lsmean = sorted(lsmean)\n",
    "                lsstd = sorted(lsstd)\n",
    "\n",
    "                ##  Separate the sorted polygon ids from the indice statistic to build into a pd.DataFrame\n",
    "                indicemean = []\n",
    "                indicestd = []\n",
    "                polyid = []\n",
    "\n",
    "                for x in lsmean:\n",
    "                    polyid.append(x[0])\n",
    "                    indicemean.append(x[1])\n",
    "\n",
    "                for x in lsstd:\n",
    "                    indicestd.append(x[1])\n",
    "\n",
    "                # Build a pd.DataFrame from the sorted polygon id and indice statistics. \n",
    "                # Nominate a name for the new column.\n",
    "                indexstats = pd.DataFrame(\n",
    "                    indicemean, index=polyid, columns=[str(var) + \" zonal mean\"]\n",
    "                )\n",
    "\n",
    "#                 indexstats[str(var) + ' zonal mean'] = indicemean\n",
    "#                 indexstats['polyid'] = polyid \n",
    "    \n",
    "                indexstats[str(var) + \" zonal std\"] = None\n",
    "                indexstats.loc[polyid, (str(var) + \" zonal std\")] = indicestd\n",
    "\n",
    "                # Workaround to handle automatic addition of key_0 column at merge step\n",
    "                if \"key_0\" in gdf_zonal.columns:\n",
    "                    gdf_zonal.drop(columns=[\"key_0\"], inplace=True)\n",
    "\n",
    "                # # Merge the indice statistic for each polygon into the original polygon gdf\n",
    "                gdf_zonal = gdf_zonal.merge(indexstats, on=indexstats.index)\n",
    "\n",
    "        ## Rename the 'index' column to avoid confusion with the gdf.index\n",
    "        gdf_zonal.rename(columns={'OBJECTID' : 'pgid'}, inplace=True)\n",
    "        gdf_zonal.rename(columns={'geometry' : 'pg_geometry'}, inplace=True)\n",
    "\n",
    "#                         return gdf\n",
    "\n",
    "    ## Calculate pixel results\n",
    "    if pixel:\n",
    "\n",
    "        ## New dict to store arrays\n",
    "#         pxsummary = {}\n",
    "\n",
    "        ## Master gdf\n",
    "        gdf_px = gpd.GeoDataFrame()\n",
    "        gdf_px['geometry'] = None\n",
    "\n",
    "        ## List to store geom, unique pixel id \n",
    "        # pxid = []\n",
    "        uniquepx = []\n",
    "        pxgeom = []\n",
    "\n",
    "        ##  Generate a list of keys for polygons in class '0' of results2\n",
    "        keylist = list(results2['0'].keys())\n",
    "\n",
    "\n",
    "        ##  Generate zonal indice stats for polygon followed by temporal statistic\n",
    "        ##  Append polygon id and temporal statistic to gdf\n",
    "        for k in results2:\n",
    "\n",
    "#             if not (str(k) in pxsummary.keys()):\n",
    "#                 pxsummary[str(k)] = {}\n",
    "\n",
    "            for kk in results2[k]:\n",
    "\n",
    "                lon = []\n",
    "                for value in results2[k][kk].x.values:\n",
    "                    lon.append(value)\n",
    "\n",
    "                lat = []\n",
    "                for value in results2[k][kk].y.values:\n",
    "                    lat.append(value)\n",
    "\n",
    "                ds = xr.Dataset()\n",
    "\n",
    "                ##  For each nominated indice:\n",
    "                for var in index_ls:\n",
    "                    if var in results2[\"0\"][keylist[0]].var():\n",
    "\n",
    "                        temporalmean = (results2[str(k)][str(kk)][var]\n",
    "                                        .where(results2[k][kk][mask])\n",
    "                                        .mean(dim='time'))\n",
    "                        name1 = str(var) + ' px mean'\n",
    "                        ds[name1] = (('y', 'x'), temporalmean)\n",
    "                        results2[str(k)][str(kk)][name1] = (('y', 'x'), temporalmean)\n",
    "\n",
    "                        temporalstd = (results2[k][kk][var]\n",
    "                                       .where(results2[k][kk][mask])\n",
    "                                       .std(dim='time'))\n",
    "                        name2 = str(var) + ' px std'\n",
    "                        ds[name2] = (('y', 'x'), temporalstd)\n",
    "                        results2[str(k)][str(kk)][name2] = (('y', 'x'), temporalstd)\n",
    "\n",
    "                ds.coords['lon'] = ('x'), lon\n",
    "                ds.coords['lat'] = ('y'), lat\n",
    "\n",
    "\n",
    "                ## Extract pixel geometry/shape for input into gdf for choropleth plotting\n",
    "                # Extract dataset matching polygon\n",
    "                closest_ds = results2[k][kk]\n",
    "\n",
    "                ## Extract pgid attributes to attach later\n",
    "                attrs = closest_ds.attrs\n",
    "                ds.attrs = attrs\n",
    "\n",
    "                ## Skip empty arrays\n",
    "                if closest_ds.x.size == 0:\n",
    "                    print('Empty arrays: k: ', k, 'kk: ', kk)\n",
    "                    continue\n",
    "                else:       \n",
    "                    # Input array (based on red band) to segment and vectorise\n",
    "                    input_array = closest_ds.nbart_red\n",
    "                    input_transform = closest_ds.affine  \n",
    "                    input_crs = input_array.crs\n",
    "\n",
    "                    # Create array with a unique value per cell\n",
    "                    unique_pixels = np.arange(input_array.size).reshape(input_array.shape)\n",
    "\n",
    "                    # Vectorise each unique feature in array\n",
    "                    vectors = rasterio.features.shapes(\n",
    "                        source=unique_pixels.astype(np.int16), transform=input_transform\n",
    "                    )\n",
    "\n",
    "                    # Extract polygons and values from generator\n",
    "                    vectors = list(vectors)\n",
    "                    values = [value for polygon, value in vectors]\n",
    "                    polygons = [shape(polygon) for polygon, value in vectors]\n",
    "                    pp = np.array(polygons)\n",
    "                    pp = pp.reshape(len(input_array.y), len(input_array.x))\n",
    "\n",
    "#              # Create a geopandas dataframe populated with the polygon shapes\n",
    "#              closestdate_poly_gdf = gpd.GeoDataFrame(data={\"id\": values}, geometry=polygons, crs=input_crs)\n",
    "\n",
    "                    ds['geometry'] = (('y', 'x'), pp)\n",
    "\n",
    "                results2[k][kk]['geometry'] = (('y', 'x'), pp)\n",
    "                results2[k][kk].set_coords('geometry')\n",
    "\n",
    "\n",
    "                ## Append [geom, unique pixel id] to list for later addition to gdf, merging on geom\n",
    "                pxid2 = []\n",
    "                pgid2 = []\n",
    "\n",
    "                for x in ds['x']:\n",
    "                    for y in ds['y']:\n",
    "                        pxid1 = str(attrs['pgid'])+'_'+str(ds['y'][y].item())+'_'+str(ds['x'][x].item())\n",
    "                        gm = pp[ds['y'][y].item()][ds['x'][x].item()]\n",
    "\n",
    "                        uniquepx.append(pxid1)\n",
    "                        pxgeom.append(gm)\n",
    "                        pxid2.append(pxid1)\n",
    "                        pgid2.append(attrs['pgid'])\n",
    "\n",
    "                pxid2 = np.array(pxid2).reshape(ds.y.shape[0], ds.x.shape[0])\n",
    "                pgid2 = np.array(pgid2).reshape(ds.y.shape[0], ds.x.shape[0])\n",
    "                results2[k][kk]['pxid'] = (('y', 'x'), pxid2)\n",
    "\n",
    "                ds['pgid'] = (('y', 'x'), pgid2)\n",
    "\n",
    "                ## Reattach attrs\n",
    "                results2[k][kk].attrs = attrs\n",
    "\n",
    "#                 pxsummary[k][kk] = ds\n",
    "\n",
    "                ## Append ds to gdf_px\n",
    "                ds = ds.to_dataframe()\n",
    "                gdf_px = gdf_px.append(ds)\n",
    "                gdf_px.crs = gdf.crs\n",
    "\n",
    "        pxid = gpd.GeoDataFrame(uniquepx, geometry=pxgeom, columns=['pxid'], crs=input_crs)\n",
    "\n",
    "        gdf_px.reset_index(inplace=True)\n",
    "\n",
    "        gdf_px = gdf_px.merge(pxid)\n",
    "        gdf_px.set_index('pxid', inplace=True, drop=False)\n",
    "        gdf_px.dropna(axis=0, inplace=True)\n",
    "        gdf_px.sort_index(level='pxid', inplace=True)\n",
    "\n",
    "    if zonal == True & pixel == True:\n",
    "        ## Merge the (zonal) gdf and gdf_px\n",
    "        gdf_merged = gdf_px.merge(gdf_zonal, on = 'pgid')\n",
    "\n",
    "        ## Drop the pg_geometry to use the pixel geometry default\n",
    "        gdf_merged.drop(columns='pg_geometry', inplace=True)\n",
    "\n",
    "        ##  Create new gdf's for each class to plot\n",
    "#         grasses = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal grass-herb-sedge-other succulent\"].index\n",
    "#         )\n",
    "#         mangroves = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal mangroves and other trees & shrubs\"].index\n",
    "#         )\n",
    "        seagrass = gdf_merged.drop(gdf_merged[gdf_merged.BRD_HAB != \"Intertidal seagrass\"].index)\n",
    "\n",
    "        ##  Drop polygons containing NaN values\n",
    "        ##  ASSUMPTION: if NDVI contains NaNs, all indices will contain NaNs. \n",
    "        ##  ToDo: write a loop or func that looks for NaNs in any of the supplied indices\n",
    "#         grasses = grasses.dropna(axis=0, how='any', subset=[\n",
    "#                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "#                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "#         mangroves = mangroves.dropna(axis=0, how='any', subset=[\n",
    "#                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "#                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "        seagrass = seagrass.dropna(axis=0, how='any', subset=[\n",
    "                                                   'NDVI zonal mean', \n",
    "                                                   'NDVI px mean', \n",
    "                                                   'NDVI zonal std', \n",
    "                                                   'NDVI px std']) \n",
    "    if zonal == False:\n",
    "        \n",
    "         ## Merge the (zonal) gdf and gdf_px\n",
    "        gdf_merged = gdf_px.merge(gdf, on = 'pgid')\n",
    "\n",
    "        ## Drop the pg_geometry to use the pixel geometry default\n",
    "        gdf_merged.drop(columns='pg_geometry', inplace=True)        \n",
    "\n",
    "        ##  Create new gdf's for each class to plot\n",
    "#         grasses = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal grass-herb-sedge-other succulent\"].index\n",
    "#         )\n",
    "#         mangroves = gdf_merged.drop(\n",
    "#             gdf_merged[gdf_merged.BRD_HAB != \"Intertidal mangroves and other trees & shrubs\"].index\n",
    "#         )\n",
    "        seagrass = gdf_merged.drop(gdf_merged[gdf_merged.BRD_HAB != \"Intertidal seagrass\"].index)\n",
    "\n",
    "        ##  Drop polygons containing NaN values\n",
    "        ##  ASSUMPTION: if NDVI contains NaNs, all indices will contain NaNs. \n",
    "        ##  ToDo: write a loop or func that looks for NaNs in any of the supplied indices\n",
    "#         grasses = grasses.dropna(axis=0, how='any', subset=[\n",
    "# #                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "# #                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "#         mangroves = mangroves.dropna(axis=0, how='any', subset=[\n",
    "# #                                                    'NDVI zonal mean', \n",
    "#                                                    'NDVI px mean', \n",
    "# #                                                    'NDVI zonal std', \n",
    "#                                                    'NDVI px std'])\n",
    "        seagrass = seagrass.dropna(axis=0, how='any', subset=[\n",
    "#                                                    'NDVI zonal mean', \n",
    "                                                   'NDVI px mean', \n",
    "#                                                    'NDVI zonal std', \n",
    "                                                   'NDVI px std']) \n",
    "\n",
    "    return gdf_merged, seagrass#, results2, grasses, mangroves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Temp - data loading cell\n",
    "\n",
    "# # # ## Delete all variables, leaving imported modules # https://stackoverflow.com/questions/26545051/is-there-a-way-to-delete-created-variables-functions-etc-from-the-memory-of-th\n",
    "# # for name in dir():\n",
    "# #     if not name.startswith('_'):\n",
    "# #         del globals()[name]\n",
    "# # # OR\n",
    "# # # reset # as per https://stackoverflow.com/questions/26545051/is-there-a-way-to-delete-created-variables-functions-etc-from-the-memory-of-th\n",
    "\n",
    "# # # Load saved variables (hashed out by default)\n",
    "\n",
    "# ## Load the name for your roi\n",
    "# name = 'Gladstone_Harbour_upperreach'\n",
    "\n",
    "# ## Re-load the query\n",
    "\n",
    "# # Setup the general query and variables for later\n",
    "# products = [\"ga_ls8c_ard_3\"]\n",
    "# align = (0, 0)\n",
    "\n",
    "# # Query\n",
    "# query = {\n",
    "#     \"time\": (\"2013-01-01\", \"2020-08-01\"),\n",
    "#     \"measurements\": [\"nbart_red\", \"nbart_green\", \"nbart_blue\", \"nbart_nir\", \"nbart_swir_1\"],\n",
    "#     \"output_crs\": \"EPSG:3577\", # Do not change th\n",
    "#     \"resolution\": (-30, 30),\n",
    "#     \"group_by\": \"solar_day\",\n",
    "#     \"dask_chunks\": {\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "# }\n",
    "\n",
    "# ## ensure that you are working from the same directory as the files are stored\n",
    "# %cd '/home/jovyan/dev/dea-notebooks/Claire'\n",
    "\n",
    "# ## Load imagery dict\n",
    "# with open('results2_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     results2 = pickle.load(handle)\n",
    "\n",
    "# ## Load polygon gdf    \n",
    "# with open('gdf_' + query['time'][0]+ name +'.pickle', 'rb') as handle:\n",
    "#     gdf = pickle.load(handle)\n",
    "\n",
    "# # gdf.drop(labels=8, axis=0, inplace=True)\n",
    "# len(results2['0']) + len(results2['1']) + len(results2['3'])\n",
    "# # len(gdf)\n",
    "# len(results['1']) + len(results['2'])+ len(results['0'])\n",
    "# # results.keys()\n",
    "# print(len(results['0']))\n",
    "# gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate zonal and temporal stats for each polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate zonal and pixel stats and attach to class polygons\n",
    "# gdf_merged, results2, grasses, mangroves, seagrass = temporal_stats(gdf, \n",
    "#                                                                     results2, \n",
    "#                                                                     mask='lowest_20_mask')\n",
    "\n",
    "gdf_merged, seagrass = temporal_stats(gdf, \n",
    "                                    results2, \n",
    "#                                     zonal = False,\n",
    "#                                     pixel = True,\n",
    "                                    mask='lowest_20_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate zonal and pixel stats and attach to class polygons\n",
    "gdf_merged, results2 = temporal_stats(gdf, \n",
    "                                        results2, \n",
    "                                        mask='lowest_20_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the zonal statistics temporal summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Plot grasses\n",
    "# print('Select attribute from: ', gdf_merged.columns)\n",
    "\n",
    "roi = map_shapefile(grasses, attribute=\"NDVI px std\", continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Plot mangroves\n",
    "roi = map_shapefile(mangroves, attribute=\"NDVI px std\", continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aac2735c83c49c18f933809864d50fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-23.791538455630096, 151.2392031237486], controls=(ZoomControl(options=['position', 'zoom_in_text'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  Plot seagrass\n",
    "roi = map_shapefile(seagrass, attribute=\"NDVI px std\", continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index_x', 'geometry', 'NDVI px mean', 'NDVI px std', 'EVI px mean',\n",
       "       'EVI px std', 'NDAVI px mean', 'NDAVI px std', 'WAVI px mean',\n",
       "       'WAVI px std', 'LAI px mean', 'LAI px std', 'SAVI px mean',\n",
       "       'SAVI px std', 'NDWI px mean', 'NDWI px std', 'MNDWI px mean',\n",
       "       'MNDWI px std', 'lon', 'lat', 'pgid', 'pxid', 'key_0', 'index_y',\n",
       "       'CONSOL', 'DOM_TYPE', 'DOM_LABEL', 'CO_TYPES', 'TIDE_ZONE', 'BRD_HAB',\n",
       "       'Shape_Leng', 'Shape_Area', 'id', 'NDVI zonal mean', 'NDVI zonal std',\n",
       "       'EVI zonal mean', 'EVI zonal std', 'NDAVI zonal mean',\n",
       "       'NDAVI zonal std', 'WAVI zonal mean', 'WAVI zonal std',\n",
       "       'LAI zonal mean', 'LAI zonal std', 'SAVI zonal mean', 'SAVI zonal std',\n",
       "       'NDWI zonal mean', 'NDWI zonal std', 'MNDWI zonal mean',\n",
       "       'MNDWI zonal std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Plot seagrass\n",
    "# roi = map_shapefile(gdf_merged, attribute=\"NDVI px std\", continuous=True)\n",
    "gdf_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIT Preparation - single habitat polygon \n",
    "For single polygon interrogation, manually identify the polygon ID from the popup window above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ******From the interactive zonal summary plots above, IDENTIFY A POLYGON to interrogate*******\n",
    "pg = [3573]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIT preparation\n",
    "To select any region for interrogation, use the 'draw a polygon' option on any of the above 3 plots.\n",
    "Upon completion of the polygon, the geometry will automatically be saved to memory and the following cell\n",
    "will prepare the data for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pg:\n",
    "    ## For single polygon interrogation\n",
    "    classes_df, results2 = coastal_wit(results2, pg)\n",
    "else:\n",
    "\n",
    "    ## WIT preparation from a roi\n",
    "\n",
    "    ##  Form a shapely polygon from the coordinates defined by the user on the map\n",
    "    miniwit_roi = Polygon(roi[-1]['geometry']['coordinates'][0])\n",
    "\n",
    "    ##  Generate a new geodataframe containing the user defined polygon geometry\n",
    "    miniwit_df = gpd.GeoDataFrame(gpd.GeoSeries(miniwit_roi), columns=['geometry'], crs='EPSG:4326')\n",
    "    miniwit_df = miniwit_df.to_crs(gdf.crs)\n",
    "\n",
    "    ##  Intersect the user-defined region of interest with the master\n",
    "    ##  to create the working gdf from which imagery will be extracted\n",
    "    miniwit_gdf = gpd.overlay(roi[0], miniwit_df, how='intersection')  \n",
    "\n",
    "    # miniwit_gdf.plot()\n",
    "\n",
    "    ## Isolate the pgid's in the roi and convert to ints\n",
    "    roi_pg = miniwit_gdf.pgid.unique()\n",
    "    roi_pg = [int(x) for x in roi_pg]\n",
    "\n",
    "    ## Isolate the pxid's in the roi\n",
    "    roi_px = miniwit_gdf.pxid.to_list()\n",
    "    roi_px = [str(x) for x in roi_px]\n",
    "\n",
    "    print('This selection includes ', len(roi_px), ' individual pixel polygons from ', len(roi_pg), ' individual habitat class polygons')\n",
    "\n",
    "    ## Find the associated class and polygon keys in results2\n",
    "    ## Save results for an roi search to this new xarray dict (`roi_results2`)\n",
    "    roi_results2 = {}\n",
    "\n",
    "    for k in results2:\n",
    "\n",
    "        if not (str(k) in roi_results2.keys()):\n",
    "            roi_results2[str(k)] = {}\n",
    "\n",
    "        for kk in results2[k]:\n",
    "            for x in roi_pg:\n",
    "                if x == results2[str(k)][str(kk)].attrs['pgid']:\n",
    "    #                 print('True')\n",
    "    #                 print ('[k][kk]: ', k, ',', kk)\n",
    "\n",
    "                    ## Mask results2 by pixels in roi\n",
    "                    mask = (np.isin(results2[str(k)][str(kk)].pxid, roi_px))\n",
    "                    mask = mask.reshape(mask.shape[-1], mask.shape[0])\n",
    "\n",
    "                    results2[str(k)][str(kk)]['roi_mask'] = (('x', 'y'), mask)\n",
    "\n",
    "                    roi_results2[str(k)][str(kk)] = (results2[str(k)][str(kk)]\n",
    "                                                     .where((results2[str(k)][str(kk)]\n",
    "                                                             .roi_mask == True)))\n",
    "\n",
    "    miniwit_gdf.plot()\n",
    "\n",
    "    ## For region of interest interrogation\n",
    "    classes_df, results2 = coastal_wit(roi_results2, roi_pg)\n",
    "    pg = roi_pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIT plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b8dc36f0ac4ef78952f18a6de696d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d68f976c66448a7b292299f5741b19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbbca46a56e4d71b97f3900bf43910c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='Click on the pixel you would like to interrogate')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## This cell prepares the nominated WIT data for plotting\n",
    "%matplotlib widget\n",
    "pal = [\n",
    "       sns.xkcd_rgb[\"cobalt blue\"],\n",
    "       sns.xkcd_rgb[\"beige\"],\n",
    "       sns.xkcd_rgb[\"light green\"],\n",
    "       sns.xkcd_rgb[\"green\"],\n",
    "       sns.xkcd_rgb[\"dark green\"]]\n",
    "\n",
    "plt.clf()\n",
    "plt.close(fig=None)\n",
    "\n",
    "## `cl` and `pg1` are required for the interactive date selection from the plot\n",
    "cl = gdf.loc[gdf['OBJECTID'] == pg[0]].id.values.item()\n",
    "pg1 = gdf.loc[gdf['OBJECTID'] == pg[0]].index.values.item()\n",
    "\n",
    "fig = plt.figure(figsize=(12,8), constrained_layout=False)\n",
    "gs = fig.add_gridspec(8,1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0:2, :])\n",
    "ax1.set_title('% of polygon exposed')\n",
    "ax2 = fig.add_subplot(gs[4:, :])\n",
    "ax2.set_title('% cover in exposed polygon')\n",
    "ax3 = fig.add_subplot(gs[2:4, :])\n",
    "ax3.set_title('modelled tide height')\n",
    "\n",
    "ax2.stackplot(classes_df.index, \n",
    "              classes_df['pc_water'], \n",
    "              classes_df['pc_unveg'],\n",
    "              classes_df['pc_ndvi_low'], \n",
    "              classes_df['pc_ndvi_mid'], \n",
    "              classes_df['pc_ndvi_high'],\n",
    "              labels=[\n",
    "                  'water',\n",
    "                  'unveg',\n",
    "                  'low veg',\n",
    "                  'medium veg',\n",
    "                  'dense veg',\n",
    "                 ], \n",
    "              baseline='zero',\n",
    "              colors=pal, \n",
    "              alpha = 0.6\n",
    "             )\n",
    "\n",
    "ax1.plot(classes_df.index, \n",
    "        classes_df['pc_exposedpx'], \n",
    "        color='black', \n",
    "        linewidth=0.2, \n",
    "        marker='o',\n",
    "        markersize=3\n",
    "       )\n",
    "\n",
    "ax3.plot(classes_df.index, \n",
    "        classes_df['tide_height'], \n",
    "        color='black', \n",
    "        linewidth=0.2, \n",
    "        marker='o',\n",
    "        markersize=3\n",
    "       )\n",
    "\n",
    "\n",
    "# plt.ylim((0,100))\n",
    "ax1.set_ylim([0,100])\n",
    "ax3.set_ylim([-1,0])\n",
    "\n",
    "#add a legend and a tight plot box\n",
    "ax2.legend(loc='best', framealpha=0.0)#, bbox_to_anchor=(1.00,1.00))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Run on click event\n",
    "w2 = widgets.HTML(\"Click on the pixel you would like to interrogate\")\n",
    "ka = fig.canvas.mpl_connect('button_press_event', onclick_timeseries)\n",
    "display(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial WIT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3861d41500ac439aadf6444af2f9a707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Still buggy with roi areas. TimeIndex recalls wrong dates - needs debugging\n",
    "\n",
    "pglen=0\n",
    "# pg=roi_pg\n",
    "\n",
    "# Plot raster data\n",
    "plt.clf()\n",
    "plt.close()#'all')\n",
    "\n",
    "\n",
    "# ## Colour palette as per WIT\n",
    "# ndvi_pal = [\n",
    "# #        sns.xkcd_rgb[\"cobalt blue\"],\n",
    "#        sns.xkcd_rgb[\"beige\"],\n",
    "#        sns.xkcd_rgb[\"light green\"],\n",
    "#        sns.xkcd_rgb[\"green\"],\n",
    "#        sns.xkcd_rgb[\"dark green\"]]\n",
    "\n",
    "ndvi_pal = [\n",
    "#        sns.xkcd_rgb[\"cobalt blue\"],\n",
    "       sns.xkcd_rgb[\"dark green\"],\n",
    "       sns.xkcd_rgb[\"beige\"],\n",
    "       sns.xkcd_rgb[\"light green\"],\n",
    "       sns.xkcd_rgb[\"green\"]\n",
    "]\n",
    "\n",
    "# ndvi_pal = [\n",
    "# #        sns.xkcd_rgb[\"cobalt blue\"],\n",
    "\n",
    "#        sns.xkcd_rgb[\"light green\"],\n",
    "#        sns.xkcd_rgb[\"green\"],\n",
    "#        sns.xkcd_rgb[\"dark green\"],\n",
    "#        sns.xkcd_rgb[\"beige\"]]\n",
    "\n",
    "ndwi_pal = [\n",
    "    sns.xkcd_rgb[\"white\"],\n",
    "    sns.xkcd_rgb[\"cobalt blue\"]]\n",
    "\n",
    "# for x in range(0,len(pg)):\n",
    "    \n",
    "## Data preparation - pg must be a single value\n",
    "cl = gdf.loc[gdf['OBJECTID'] == pg[pglen]].id.values.item()\n",
    "#     print(cl)\n",
    "## class polygon\n",
    "pg1 = gdf.loc[gdf['OBJECTID'] == pg[pglen]].index.values.item()\n",
    "#     print(pg1)\n",
    "\n",
    "## Extract dataset matching polygon and date selected from WIT plot\n",
    "sWIT = results2[str(cl)][str(pg1)].isel(time=TimeIndex)\n",
    "# sWIT = results2[str(cl)][str(pg1)].isel(time=8)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=[8,8])#nrows = len(pg),\n",
    "#                         ncols = 1)#figsize=[8, 8])\n",
    "sWIT.NDWI.where(sWIT.lowest_20_mask).where(sWIT.NDWI > 0).plot(ax=ax1, levels=[-1, 0, 1], colors=ndwi_pal)\n",
    "sWIT.NDVI.where(sWIT.lowest_20_mask).where(sWIT.mask).plot(ax=ax1, levels=[0, 0.1, 0.33, 0.66, 1], colors = ndvi_pal)\n",
    "\n",
    "mpl.axes.Axes.set_aspect(ax1, aspect=1)#, anchor='C')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c2ed9a1bb04b56b9ab6ea80b66f0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (73,) and (25, 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-8ee0ac503e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m ax1.plot(results2['0']['4'].time, \n\u001b[1;32m      8\u001b[0m         \u001b[0mresults2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NDVI px mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#         linewidth=0.2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         marker='o',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (73,) and (25, 35)"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()#figsize=(12,8), constrained_layout=False)\n",
    "gs = fig.add_gridspec(8,4)#8,1)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "# ax1.set_title('% of polygon exposed')\n",
    "\n",
    "ax1.plot(results2['0']['4'].time, \n",
    "        results2['0']['4']['NDVI px mean'], \n",
    "        color='black'#, \n",
    "#         linewidth=0.2, \n",
    "#         marker='o',\n",
    "#         markersize=3\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['4'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sWIT\n",
    "# sWIT['NDVI px mean']\n",
    "# classes_df\n",
    "results2['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6f9374331429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msWITtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msWIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NDVI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ga_ls_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# type(sWIT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/dea-notebooks/Scripts/dea_bandindices.py\u001b[0m in \u001b[0;36mcalculate_indices\u001b[0;34m(ds, index, collection, custom_varname, normalise, drop, inplace)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;31m# If normalised=True, divide data by 10,000 before applying func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mmult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalise\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands_to_rename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             raise ValueError(f'Please verify that all bands required to '\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4957\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4958\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4959\u001b[0;31m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_binary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4960\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_calculate_binary_op\u001b[0;34m(self, f, other, join, inplace)\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5029\u001b[0m             \u001b[0mother_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"variable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5030\u001b[0;31m             \u001b[0mnew_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_variable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5031\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5032\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5029\u001b[0m             \u001b[0mother_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"variable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5030\u001b[0;31m             \u001b[0mnew_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_variable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5031\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5032\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/env/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 new_data = (\n\u001b[1;32m   2130\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreflexive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m                 )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "# sWITtest = calculate_indices(sWIT, 'NDVI', 'ga_ls_3', inplace=True)\n",
    "# type(sWIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "045ab485daf24868b7c2382f424cbcb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_b0ea6054510a498e8a7c56ce35cc5c4c",
       "style": "IPY_MODEL_f660eac494c147198a27997ad8b22470"
      }
     },
     "0746427347e2416f920f9ce96228b721": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletGeoJSONModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "data": {
        "bbox": [
         142.4524578701443,
         -32.36320549945,
         142.54736615559136,
         -32.29586369982442
        ],
        "features": [
         {
          "bbox": [
           142.51524944800926,
           -32.31838789697648,
           142.54736615559136,
           -32.29586369982442
          ],
          "geometry": {
           "coordinates": [
            [
             [
              142.51524944800926,
              -32.296091685646715
             ],
             [
              142.546601533663,
              -32.29586369982442
             ],
             [
              142.54736615559136,
              -32.3183698586848
             ],
             [
              142.51526741493365,
              -32.31838789697648
             ],
             [
              142.51524944800926,
              -32.296091685646715
             ]
            ]
           ],
           "type": "Polygon"
          },
          "id": "0",
          "properties": {
           "id": 2,
           "style": {
            "color": "black",
            "fillColor": "#ffffcc",
            "fillOpacity": 0.8,
            "weight": 0.9
           }
          },
          "type": "Feature"
         },
         {
          "bbox": [
           142.4524578701443,
           -32.36320549945,
           142.4845749551165,
           -32.34069269280065
          ],
          "geometry": {
           "coordinates": [
            [
             [
              142.4524578701443,
              -32.340907825281136
             ],
             [
              142.483823262827,
              -32.34069269280065
             ],
             [
              142.4845749551165,
              -32.36320063502121
             ],
             [
              142.45246271443352,
              -32.36320549945
             ],
             [
              142.4524578701443,
              -32.340907825281136
             ]
            ]
           ],
           "type": "Polygon"
          },
          "id": "1",
          "properties": {
           "id": 1,
           "style": {
            "color": "black",
            "fillColor": "#800026",
            "fillOpacity": 0.8,
            "weight": 0.9
           }
          },
          "type": "Feature"
         }
        ],
        "type": "FeatureCollection"
       },
       "style": {
        "fillOpacity": 0.8
       }
      }
     },
     "140008a05899493688edb1cfd07bb91d": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_8563b85ab05a465b900584182485dc98"
      }
     },
     "215e008ea30446418c9489a3fc2a3509": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     },
     "2f3cbd62daf645a4a47a3132fde027d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "height": "600px",
       "width": "800px"
      }
     },
     "331f5be31bf049e4a4c2ab49668abcdd": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "472e3957cd724d3fb57312a3fa86dae1": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     },
     "8563b85ab05a465b900584182485dc98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8912f038ad0947a7ae08ed0ccdb15644": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapModel",
      "state": {
       "_dom_classes": [],
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "basemap": {
        "attribution": "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community",
        "max_zoom": 20,
        "name": "Esri.WorldImagery",
        "url": "http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}"
       },
       "center": [
        -32.32953459963721,
        142.4999120128678
       ],
       "controls": [
        "IPY_MODEL_331f5be31bf049e4a4c2ab49668abcdd",
        "IPY_MODEL_472e3957cd724d3fb57312a3fa86dae1"
       ],
       "default_style": "IPY_MODEL_d14c0de5ce3b48bd9eb7729afbe8d701",
       "dragging_style": "IPY_MODEL_a6bbab8038c3446a93e3a549b8f8dd79",
       "east": 142.5685501098633,
       "fullscreen": false,
       "interpolation": "bilinear",
       "layers": [
        "IPY_MODEL_99119a1935514365b929a6d6c4b31a95",
        "IPY_MODEL_0746427347e2416f920f9ce96228b721"
       ],
       "layout": "IPY_MODEL_2f3cbd62daf645a4a47a3132fde027d0",
       "modisdate": "yesterday",
       "north": -32.28597166993233,
       "options": [
        "basemap",
        "bounce_at_zoom_limits",
        "box_zoom",
        "center",
        "close_popup_on_click",
        "double_click_zoom",
        "dragging",
        "fullscreen",
        "inertia",
        "inertia_deceleration",
        "inertia_max_speed",
        "interpolation",
        "keyboard",
        "keyboard_pan_offset",
        "keyboard_zoom_offset",
        "max_zoom",
        "min_zoom",
        "scroll_wheel_zoom",
        "tap",
        "tap_tolerance",
        "touch_zoom",
        "world_copy_jump",
        "zoom",
        "zoom_animation_threshold",
        "zoom_start"
       ],
       "south": -32.373002604986546,
       "style": "IPY_MODEL_215e008ea30446418c9489a3fc2a3509",
       "west": 142.4312210083008,
       "zoom": 13
      }
     },
     "99119a1935514365b929a6d6c4b31a95": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletTileLayerModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "attribution": "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community",
       "base": true,
       "max_native_zoom": 18,
       "max_zoom": 20,
       "min_native_zoom": 0,
       "min_zoom": 1,
       "name": "Esri.WorldImagery",
       "no_wrap": false,
       "options": [
        "attribution",
        "detect_retina",
        "max_native_zoom",
        "max_zoom",
        "min_native_zoom",
        "min_zoom",
        "no_wrap",
        "tile_size"
       ],
       "url": "http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}"
      }
     },
     "a6bbab8038c3446a93e3a549b8f8dd79": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "move"
      }
     },
     "b0ea6054510a498e8a7c56ce35cc5c4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d14c0de5ce3b48bd9eb7729afbe8d701": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     },
     "f660eac494c147198a27997ad8b22470": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
