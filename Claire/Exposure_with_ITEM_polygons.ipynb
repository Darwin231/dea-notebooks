{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sunriset\n",
      "  Using cached sunriset-1.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pytz in /env/lib/python3.6/site-packages (from sunriset) (2021.1)\n",
      "Requirement already satisfied: pandas in /env/lib/python3.6/site-packages (from sunriset) (1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /env/lib/python3.6/site-packages (from pandas->sunriset) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /env/lib/python3.6/site-packages (from pandas->sunriset) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /env/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas->sunriset) (1.16.0)\n",
      "Installing collected packages: sunriset\n",
      "Successfully installed sunriset-1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sunriset\n",
    "import sunriset ##(will need to `pip install sunriset` on first loading) ##for use in daily sunrise/set times. Could be moved into exp_ds func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import datacube\n",
    "from datacube.utils import geometry\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# import sunriset ##(will need to `pip install sunriset` on first loading) ##for use in daily sunrise/set times. Could be moved into exp_ds func\n",
    "from otps import TimePoint\n",
    "from otps import predict_tide\n",
    "import pytz\n",
    "import math\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from math import ceil\n",
    "from scipy.signal import argrelmax ##used in calculation of spring/neap tides. Could be moved into exp_ds func\n",
    "from scipy.signal import argrelmin ##used in calculation of spring/neap tides. Could be moved into exp_ds func\n",
    "from scipy.interpolate import interp1d # for interpolation of new data points\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Scripts\")\n",
    "from dea_plotting import map_shapefile\n",
    "from dea_dask import create_local_dask_cluster\n",
    "\n",
    "# solar modelling modules\n",
    "# import matplotlib.pyplot as plt\n",
    "# %config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/drivers/postgres/_connections.py:87: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33635</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/cp/proxy/8787/status' target='_blank'>/user/cp/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>7</li>\n",
       "  <li><b>Memory: </b>63.57 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33635' processes=1 threads=7, memory=63.57 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dc = datacube.Datacube(app=\"intertidal_exposure\")\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dev/dea-notebooks/Claire\n"
     ]
    }
   ],
   "source": [
    "## Set variables \n",
    "\n",
    "# Read in the polygon vector file\n",
    "%cd '/home/jovyan/dev/dea-notebooks/Claire/'\n",
    "vector_file = \"ITEMv2_tidalmodel.shp\"\n",
    "attribute_col = \"ID\"\n",
    "gdf_master = gpd.read_file(vector_file)\n",
    "\n",
    "# ## Index by date. This may break when time_start or time_end do not appear in the filtered dataset\n",
    "## Ideally: 18.61 year window (19 years), the global average astronomically forced lunar nodal cycle (e.g. Haigh et al., 2011)\n",
    "## NOTE: tidal and exposure modelling are set from the `time_start` and `time_end` parameters\n",
    "time_start = '2019-12-01 00:00:00'\n",
    "time_end = '2020-12-01 00:00:00'\n",
    "\n",
    "## Set the frequency to run the tidal modelling\n",
    "modelled_freq='30min'\n",
    "\n",
    "# ## Set the filter to apply for the exposure modelling\n",
    "# time_filter = 'Oct'\n",
    "\n",
    "query = {\n",
    "    'product': ['nidem'],\n",
    "    \"dask_chunks\": {\"time\": 1, \"x\": 1000, \"y\": 1000}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST CELL!\n",
    "### Incorporate solar exposure (sunrise/set) and rebuild the datetime filter to generate \n",
    "### all required values simultaneously\n",
    "\n",
    "# ##### Build a list of DataArrays to concat\n",
    "\n",
    "\n",
    "\n",
    "def exp_model(time_start, time_end, time_filter, modelled_freq, tidepost_lat, tidepost_lon):#, round_stats):\n",
    "    \n",
    "    '''\n",
    "    For each modelled timestep in modelledtides,\n",
    "    mask NIDEM for the associated tideheight.\n",
    "    Save the lists of timesteps and masked arrays\n",
    "    and concatenate to join all arrays on the new\n",
    "    dimension 'datetime'\n",
    "    \n",
    "    Time filtering (`time_filter`) options for exposure mapping routine are:\n",
    "    all_time,\n",
    "    daynight,\n",
    "    wet,\n",
    "    dry,\n",
    "    summer,\n",
    "    autumn,\n",
    "    winter,\n",
    "    spring,\n",
    "    Jan,\n",
    "    Feb,\n",
    "    Mar,\n",
    "    Apr,\n",
    "    May,\n",
    "    Jun,\n",
    "    Jul,\n",
    "    Aug,\n",
    "    Sep,\n",
    "    Oct,\n",
    "    Nov,\n",
    "    Dec\n",
    "    \n",
    "    Use one of the following strings to match your tidepost to set the appropriate `timezone`\n",
    "    UTC       =  pytz.UTC ## Coordinated Universal Time\n",
    "    UTC + 8   = 'Australia/West'\n",
    "\n",
    "    UTC + 9.5 = 'Australia/North'\n",
    "                'Australia/South'\n",
    "\n",
    "    UTC + 10  = 'Australia/Queensland'\n",
    "                'Australia/NSW'\n",
    "                'Australia/Victoria'\n",
    "                'Australia/Tasmania'\n",
    "    '''\n",
    "    '''------------------------------------'''\n",
    "    ## Run tidal modelling\n",
    "\n",
    "    # Generate range of times covering entire period of satellite record\n",
    "    all_timerange = pd.date_range(start=time_start,\n",
    "                                  end=time_end,\n",
    "                                  freq=modelled_freq)\n",
    "    all_datetimes = all_timerange.values.astype('M8[s]').astype('O').tolist()  \n",
    "\n",
    "    # Use the tidal model to compute tide heights for each observation:  \n",
    "    all_timepoints = [TimePoint(tidepost_lon, tidepost_lat, dt) \n",
    "                      for dt in all_datetimes]\n",
    "    all_predictedtides = predict_tide(all_timepoints)   \n",
    "    all_tideheights = [predictedtide.tide_m for predictedtide \n",
    "                        in all_predictedtides]\n",
    "        ## Save modelled tides as dataframe\n",
    "        ## Firstly convert the dates to series\n",
    "    all_timerange = all_timerange.to_series()\n",
    "        ## Save dates and tideheights to pd.DataFrame\n",
    "    modelledtides = pd.DataFrame(data={'timerange': all_timerange,\n",
    "                       'tideheights': all_tideheights})\n",
    "\n",
    "    '''---------------------------------------------------------'''\n",
    "    ## Automate timezone selection based on location of tidepost\n",
    "    ## State boundary coords from https://www.ga.gov.au/scientific-topics/national-location-information/dimensions/border-lengths\n",
    "    if tidepost_lon <= 129.0:\n",
    "        timezone = 'Australia/West'\n",
    "        local_tz = 8\n",
    "    elif (tidepost_lon > 129.0) & (tidepost_lon <= 138.0) & (tidepost_lat < 26.0):\n",
    "        timezone = 'Australia/North'\n",
    "        local_tz = 9.5\n",
    "    elif (tidepost_lon > 129.0) & (tidepost_lon <= 141.0) & (tidepost_lat > 26.0):\n",
    "        timezone = 'Australia/South'\n",
    "        local_tz = 9.5\n",
    "    elif (tidepost_lon > 138.0) & (tidepost_lat < 26.0):\n",
    "        timezone = 'Australia/Queensland'\n",
    "        local_tz = 10\n",
    "    elif (tidepost_lon > 141.0) & (tidepost_lat >= 26.0):\n",
    "        timezone = 'Australia/NSW'\n",
    "        local_tz = 10\n",
    "    else:\n",
    "        print('Unable to assign timezone from supplied tidepost coords (tidepost_lon and tidepost_lat)')\n",
    "    print('Timezone set to', timezone)\n",
    "    \n",
    "    ## Convert time_start and time_end to datetime objects in local timezone\n",
    "    time_start = pd.to_datetime(time_start, utc=True).tz_convert(timezone)\n",
    "    time_end = pd.to_datetime(time_end, utc=True).tz_convert(timezone)\n",
    "    \n",
    "    ## Convert tz-naive to tz-aware (set to UTC to match modelled timestamp input)\n",
    "    localtides = modelledtides.index.tz_localize(tz=pytz.UTC)\n",
    "\n",
    "    ## Convert tz-aware index to local timezone\n",
    "    localtides = localtides.tz_convert(timezone)\n",
    "    \n",
    "    ## Reset the index of modelledtides to reflect local times\n",
    "    modelledtides['local_timerange'] = localtides\n",
    "    modelledtides.set_index('local_timerange', inplace=True)\n",
    "    modelledtides.drop('timerange', axis=1, inplace=True)\n",
    "    \n",
    "    '''---------------------------------'''\n",
    "    ## Prepare data for use in solar modelling function (sunriset)\n",
    "    ## Translate input dates to datetime\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    start = pd.to_datetime(time_start, format=format)\n",
    "    end = pd.to_datetime(time_end, format=format)\n",
    "\n",
    "    ## Calculate number of days between input dates\n",
    "    diff = end-start\n",
    "\n",
    "    ## Return difference in years\n",
    "    yearsdiff = diff.days/365\n",
    "\n",
    "    ## Round up to ensure all modelledtide datetimes are captured in solar model\n",
    "    yearsdiff = int(math.ceil(yearsdiff))\n",
    "\n",
    "    ## Identify variables for solar model input\n",
    "    lat = tidepost_lat ## from tidepost\n",
    "    long = tidepost_lon ## from tidepost\n",
    "#     local_tz = local_tz  ## hardcoded for 3 Austral regions\n",
    "\n",
    "    number_of_years = yearsdiff\n",
    "    start_date = datetime.date(start.year, start.month, start.day) ## from query\n",
    "    \n",
    "    ## Create all required time filters\n",
    "    ## Create dict to store filtered times\n",
    "    filters = {}\n",
    "    \n",
    "    ## Create a filteredtides dataframe for the filters of interest\n",
    "    for x in time_filter:\n",
    "        \n",
    "        if x == 'all_time':\n",
    "            filteredtides = modelledtides\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'daynight':\n",
    "\n",
    "            ## Model sunrise and sunset\n",
    "            sun_df = sunriset.to_pandas(start_date, lat, long, local_tz, number_of_years)\n",
    "\n",
    "            ## Return sunrise/sunset in hh:mm:ss format (str)\n",
    "            sun_df['Sunrise hh:mm:ss'] = sun_df['Sunrise'].apply(\n",
    "                    lambda numpy_td: str(timedelta(seconds=numpy_td.total_seconds())))\n",
    "            sun_df['Sunset hh:mm:ss'] = sun_df['Sunset'].apply(\n",
    "                    lambda numpy_td: str(timedelta(seconds=numpy_td.total_seconds())))\n",
    "\n",
    "            ## Drop accessory columns\n",
    "            sun_df = sun_df[['Sunrise hh:mm:ss','Sunset hh:mm:ss']]\n",
    "\n",
    "            ## Set the index as a datetimeindex to match the modelledtide df\n",
    "            sun_df = sun_df.set_index(pd.DatetimeIndex(sun_df.index))\n",
    "            \n",
    "            ## Create dataframe from localtides (lt_df)\n",
    "            lt_df=pd.DataFrame(localtides, columns=['localtides'])\n",
    "            dates = []\n",
    "            times = []\n",
    "            for element in localtides:\n",
    "                d = element.date()\n",
    "                dates.append(d)\n",
    "                t = element.time()\n",
    "                times.append(t)\n",
    "            lt_df['Date'] = dates\n",
    "            lt_df['Time'] = times\n",
    "\n",
    "            ## Generate empty dateframe to concatenate day and night attributed timesteps into\n",
    "            ltdaynight_df = pd.DataFrame()\n",
    "\n",
    "            for index,row in sun_df.iterrows():\n",
    "\n",
    "                ## Translate the time string from sunriset module into datetime.time\n",
    "                hourday = (int(row['Sunrise hh:mm:ss'].split(':')[0]))\n",
    "                minuteday = (int(row['Sunrise hh:mm:ss'].split(':')[1]))\n",
    "#                 secday = ceil(float(row['Sunrise hh:mm:ss'].split(':')[-1]))\n",
    "                sunrise = datetime.time(hourday, minuteday)#, secday)\n",
    "\n",
    "                hournight = (int(row['Sunset hh:mm:ss'].split(':')[0]))\n",
    "                minutenight = (int(row['Sunset hh:mm:ss'].split(':')[1]))\n",
    "#                 secnight = ceil(float(row['Sunset hh:mm:ss'].split(':')[-1]))\n",
    "                sunset = datetime.time(hournight, minutenight)#, secnight)\n",
    "\n",
    "                ## Assign day or night by comparison against sunrise and sunset for the day\n",
    "                conditions = [(lt_df.loc[lt_df['Date'] == index.date()].Time > sunrise) & (lt_df.loc[lt_df['Date'] == index.date()].Time < sunset)]\n",
    "                choices = ['day']\n",
    "                lt_df.loc[(lt_df['Date'] == index.date()), ['daynight']] = np.select(conditions, choices, default='night')\n",
    "\n",
    "                ## Extract day and night arrays to filter localtides against as per other filtering routines\n",
    "                day_df = lt_df[lt_df.daynight == 'day']\n",
    "                night_df = lt_df[lt_df.daynight == 'night']\n",
    "\n",
    "                ## Return values to DatetimeIndex\n",
    "                day = pd.DatetimeIndex(day_df.localtides)\n",
    "                night = pd.DatetimeIndex(night_df.localtides)\n",
    "    \n",
    "# #                 Try using .loc[row_indexer,col_indexer] = value instead\n",
    "#                 ## Attribute day or night against each localtides modelled timestep for each day\n",
    "#                 daynight = lt_df.loc[lt_df['Date'] == index.date()]\n",
    "\n",
    "#                 conditions = [(daynight.Time > sunrise) & (daynight.Time < sunset)]\n",
    "#                 choices = ['day']\n",
    "\n",
    "#                 ## Assign day or night by comparison against sunrise and sunset for the day\n",
    "#                 daynight.loc[:,('daynight')] = np.select(conditions, choices, default='night')\n",
    "\n",
    "#                 ## Concatenate results into master localtides/daynight dataframe `ltdaynight_df`\n",
    "#                 ltdaynight_df = pd.concat([ltdaynight_df, daynight])\n",
    "\n",
    "#                 ## Next step: extract day and night arrays to filter localtides against as per other filtering routines\n",
    "#                 ## Drop values\n",
    "#                 day_df = ltdaynight_df[ltdaynight_df.daynight != 'night']\n",
    "#                 night_df = ltdaynight_df[ltdaynight_df.daynight != 'day']\n",
    "\n",
    "#                 ## Return values to DatetimeIndex\n",
    "#                 day = pd.DatetimeIndex(day_df.localtides)\n",
    "#                 night = pd.DatetimeIndex(night_df.localtides)\n",
    "                \n",
    "                ## Filtering modelledtides by nominated timerange\n",
    "                filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in day.array)\n",
    "                filteredtides['timerange'] = day\n",
    "                filteredtides.set_index('timerange', inplace=True)\n",
    "                filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "                filters['day'] = filteredtides\n",
    "\n",
    "                ## Filtering modelledtides by nominated timerange\n",
    "                filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in night.array)\n",
    "                filteredtides['timerange'] = night\n",
    "                filteredtides.set_index('timerange', inplace=True)\n",
    "                filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "                filters['night'] = filteredtides\n",
    "\n",
    "        elif x == 'springneap':\n",
    "            ## Find all spring and neap high tides\n",
    "\n",
    "            ## All peaks(maxima) in modelledtides \n",
    "            Max = argrelmax(modelledtides[0:-1].tideheights.values)\n",
    "            Max = np.array(Max[0])\n",
    "\n",
    "            ## Find higher tides in the maxima then the spring high tides \n",
    "            maxhigh = argrelmax(modelledtides.tideheights[Max].values)\n",
    "            maxhigh = np.array(maxhigh[0])\n",
    "            springhigh = argrelmax(modelledtides.tideheights[Max[maxhigh]].values)\n",
    "            springhigh = np.array(springhigh[0]) \n",
    "\n",
    "            ## Find lower tides in the maxima then the neap high tides\n",
    "            maxlow = argrelmin(modelledtides.tideheights[Max].values)\n",
    "            maxlow = np.array(maxlow[0])\n",
    "            neaphigh = argrelmin(modelledtides.tideheights[Max[maxlow]].values)\n",
    "            neaphigh = np.array(neaphigh[0])\n",
    "\n",
    "            ## Repeat to determine spring and neap low tides.\n",
    "\n",
    "            ## All minima in modelledtides \n",
    "            Min = argrelmin(modelledtides[0:-1].tideheights.values)\n",
    "            Min = np.array(Min[0])\n",
    "\n",
    "            ## Find higher tides in the maxima then the spring high tides \n",
    "            minhigh = argrelmin(modelledtides.tideheights[Min].values)\n",
    "            minhigh = np.array(minhigh[0])\n",
    "            springlow = argrelmin(modelledtides.tideheights[Min[minhigh]].values)\n",
    "            springlow = np.array(springlow[0])\n",
    "\n",
    "            ## Find lower tides in the maxima then the neap high tides\n",
    "            minlow = argrelmax(modelledtides.tideheights[Min].values)\n",
    "            minlow = np.array(minlow[0])\n",
    "            neaplow = argrelmax(modelledtides.tideheights[Min[minlow]].values)\n",
    "            neaplow = np.array(neaplow[0])\n",
    "\n",
    "            # Add column to modelledtides to plot without using datetime values\n",
    "            modelledtides['count'] = np.arange(0,len(modelledtides),1)\n",
    "\n",
    "            ## Interpolate the high and low spring and neap curves\n",
    "            neap_high_linear = interp1d(Max[maxlow], modelledtides.tideheights[Max[maxlow]].values, bounds_error=False, kind='linear', fill_value='extrapolate')\n",
    "            modelledtides['neap_high_interp'] = neap_high_linear(modelledtides['count'])\n",
    "\n",
    "            spring_high_linear = interp1d(Max[maxhigh], modelledtides.tideheights[Max[maxhigh]].values, bounds_error=False, kind='linear', fill_value='extrapolate')\n",
    "            modelledtides['spring_high_interp'] = spring_high_linear(modelledtides['count'])\n",
    "\n",
    "            neap_low_linear = interp1d(Min[minlow], modelledtides.tideheights[Min[minlow]].values, bounds_error=False, kind='linear', fill_value='extrapolate')\n",
    "            modelledtides['neap_low_interp'] = neap_low_linear(modelledtides['count'])\n",
    "\n",
    "            spring_low_linear = interp1d(Min[minhigh], modelledtides.tideheights[Min[minhigh]].values, bounds_error=False, kind='linear', fill_value='extrapolate')\n",
    "            modelledtides['spring_low_interp'] = spring_low_linear(modelledtides['count'])\n",
    "\n",
    "            ## Extract datetimeindex for each dataslice\n",
    "            spring_high = modelledtides.tideheights[Max[maxhigh[springhigh]]].index\n",
    "            spring_low = modelledtides.tideheights[Min[minhigh[springlow]]].index\n",
    "            neap_high = modelledtides.tideheights[Max[maxlow[neaphigh]]].index\n",
    "            neap_low = modelledtides.tideheights[Min[minlow[neaplow]]].index\n",
    "            hightide = modelledtides[modelledtides.tideheights > modelledtides.neap_high_interp].index\n",
    "            lowtide = modelledtides[modelledtides.tideheights < modelledtides.neap_low_interp].index\n",
    "\n",
    "#                         ## Filtering modelledtides by nominated timerange\n",
    "#             filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in spring_high.array)\n",
    "#             filteredtides['timerange'] = spring_high\n",
    "#             filteredtides.set_index('timerange', inplace=True)\n",
    "#             filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "#             filters['spring_high'] = filteredtides\n",
    "\n",
    "#                             ## Filtering modelledtides by nominated timerange\n",
    "#             filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in spring_low.array)\n",
    "#             filteredtides['timerange'] = spring_low\n",
    "#             filteredtides.set_index('timerange', inplace=True)\n",
    "#             filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "#             filters['spring_low'] = filteredtides\n",
    "\n",
    "#                             ## Filtering modelledtides by nominated timerange\n",
    "#             filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in neap_high.array)\n",
    "#             filteredtides['timerange'] = neap_high\n",
    "#             filteredtides.set_index('timerange', inplace=True)\n",
    "#             filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "#             filters['neap_high'] = filteredtides\n",
    "\n",
    "#                             ## Filtering modelledtides by nominated timerange\n",
    "#             filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in neap_low.array)\n",
    "#             filteredtides['timerange'] = neap_low\n",
    "#             filteredtides.set_index('timerange', inplace=True)\n",
    "#             filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "#             filters['neap_low'] = filteredtides\n",
    "\n",
    "                            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in hightide.array)\n",
    "            filteredtides['timerange'] = hightide\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters['hightide'] = filteredtides\n",
    "            \n",
    "                            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in lowtide.array)\n",
    "            filteredtides['timerange'] = lowtide\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters['lowtide'] = filteredtides\n",
    "            \n",
    "            # ## Plot\n",
    "\n",
    "            #     # Add column to modelledtides to plot without using datetime values\n",
    "            # modelledtides['count'] = np.arange(0,len(modelledtides),1)\n",
    "            #     # all modelled tides\n",
    "            # plt.plot(modelledtides[0:-1]['count'], modelledtides[0:-1].tideheights) ## all modelled tide heights\n",
    "            #     # spring and neap high tides\n",
    "            # # plt.plot(Max, modelledtides.tideheights[Max], \"X\") ## all local maxima (orange)\n",
    "            # # plt.plot(Max[maxhigh], modelledtides.tideheights[Max[maxhigh]], \"X\", color='red') ## higher tides in the maxima dataset (red)\n",
    "            # plt.plot(Max[maxhigh[springhigh]], modelledtides.tideheights[Max[maxhigh[springhigh]]], \"o\", color='black') ##SPRING HIGH TIDES!! (black)\n",
    "            # plt.plot(Max[maxlow[neaphigh]], modelledtides.tideheights[Max[maxlow[neaphigh]]], \"o\", color='red') ##NEAP HIGH TIDES!! (red)\n",
    "            #     # spring and neap low tides\n",
    "            # # plt.plot(Min, modelledtides.tideheights[Min], \"X\") ## all local maxima (orange)\n",
    "            # # plt.plot(Min[minhigh], modelledtides.tideheights[Min[minhigh]], \"X\", color='red') ## higher tides in the maxima dataset (red)\n",
    "            # plt.plot(Min[minhigh[springlow]], modelledtides.tideheights[Min[minhigh[springlow]]], \"o\", color='black') ##SPRING LOW TIDES!! (black)\n",
    "            # plt.plot(Min[minlow[neaplow]], modelledtides.tideheights[Min[minlow[neaplow]]], \"o\", color='red') ##NEAP LOW TIDES!! (red)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#         elif x == 'night':\n",
    "#             night = localtides.drop(localtides[(localtides.hour == 6) ## Daylight: arbitrarily between 6 am and 5.59 pm\n",
    "#                         |(localtides.hour == 7)\n",
    "#                         |(localtides.hour == 8)\n",
    "#                         |(localtides.hour == 9)\n",
    "#                         |(localtides.hour == 10)\n",
    "#                         |(localtides.hour == 11)\n",
    "#                         |(localtides.hour == 12)\n",
    "#                         |(localtides.hour == 13)\n",
    "#                         |(localtides.hour == 14)\n",
    "#                         |(localtides.hour == 15)\n",
    "#                         |(localtides.hour == 16)\n",
    "#                         |(localtides.hour == 17)\n",
    "#                         ])\n",
    "\n",
    "#             ## Filtering modelledtides by nominated timerange\n",
    "#             filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in night.array)\n",
    "#             filteredtides['timerange'] = night\n",
    "#             filteredtides.set_index('timerange', inplace=True)\n",
    "#             filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "#             filters[str(x)] = filteredtides\n",
    "\n",
    "#         elif x == 'day':\n",
    "#             day = localtides.drop(localtides[(localtides.hour == 0) ## Nighttime: arbitrarily between 6 pm and 5.59 am\n",
    "#                         |(localtides.hour == 1)\n",
    "#                         |(localtides.hour == 2)\n",
    "#                         |(localtides.hour == 3)\n",
    "#                         |(localtides.hour == 4)\n",
    "#                         |(localtides.hour == 5)\n",
    "#                         |(localtides.hour == 18)\n",
    "#                         |(localtides.hour == 19)\n",
    "#                         |(localtides.hour == 20)\n",
    "#                         |(localtides.hour == 21)\n",
    "#                         |(localtides.hour == 22)\n",
    "#                         |(localtides.hour == 23)\n",
    "#                         ])\n",
    "\n",
    "#             ## Filtering modelledtides by nominated timerange\n",
    "#             filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in day.array)\n",
    "#             filteredtides['timerange'] = day\n",
    "#             filteredtides.set_index('timerange', inplace=True)\n",
    "#             filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "#             filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'dry':\n",
    "            dry = localtides.drop(localtides[(localtides.month == 10) ## Wet season: Oct-Mar\n",
    "                        |(localtides.month == 11)\n",
    "                        |(localtides.month == 12)\n",
    "                        |(localtides.month == 1)\n",
    "                        |(localtides.month == 2)\n",
    "                        |(localtides.month == 3)\n",
    "                        ])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in dry.array)\n",
    "            filteredtides['timerange'] = dry\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'wet':\n",
    "            wet = localtides.drop(localtides[(localtides.month == 4) ## Dry season: Apr-Sep\n",
    "                        |(localtides.month == 5)\n",
    "                        |(localtides.month == 6)\n",
    "                        |(localtides.month == 7)\n",
    "                        |(localtides.month == 8)\n",
    "                        |(localtides.month == 9)\n",
    "                        ])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in wet.array)\n",
    "            filteredtides['timerange'] = wet\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'summer':\n",
    "            summer = localtides.drop(localtides[localtides.quarter != 1])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in summer.array)\n",
    "            filteredtides['timerange'] = summer\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'autumn':\n",
    "            autumn = localtides.drop(localtides[localtides.quarter != 2])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in autumn.array)\n",
    "            filteredtides['timerange'] = autumn\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'winter':\n",
    "            autumn = localtides.drop(localtides[localtides.quarter != 3])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in winter.array)\n",
    "            filteredtides['timerange'] = winter\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'spring':\n",
    "            spring = localtides.drop(localtides[localtides.quarter != 4])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in spring.array)\n",
    "            filteredtides['timerange'] = spring\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Jan':\n",
    "            Jan = localtides.drop(localtides[localtides.month != 1])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Jan.array)\n",
    "            filteredtides['timerange'] = Jan\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Feb':\n",
    "            Feb = localtides.drop(localtides[localtides.month != 2])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Feb.array)\n",
    "            filteredtides['timerange'] = Feb\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Mar':\n",
    "            Mar = localtides.drop(localtides[localtides.month != 3])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Mar.array)\n",
    "            filteredtides['timerange'] = Mar\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Apr':\n",
    "            Apr = localtides.drop(localtides[localtides.month != 4])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Apr.array)\n",
    "            filteredtides['timerange'] = Apr\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'May':\n",
    "            May = localtides.drop(localtides[localtides.month != 5])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in May.array)\n",
    "            filteredtides['timerange'] = May\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Jun':\n",
    "            Jun = localtides.drop(localtides[localtides.month != 6])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Jun.array)\n",
    "            filteredtides['timerange'] = Jun\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Jul':\n",
    "            Jul = localtides.drop(localtides[localtides.month != 7])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Jul.array)\n",
    "            filteredtides['timerange'] = Jul\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Aug':\n",
    "            Aug = localtides.drop(localtides[localtides.month != 8])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Aug.array)\n",
    "            filteredtides['timerange'] = Aug\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Sep':\n",
    "            Sep = localtides.drop(localtides[localtides.month != 9])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Sep.array)\n",
    "            filteredtides['timerange'] = Sep\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Oct':\n",
    "            Oct = localtides.drop(localtides[localtides.month != 10])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Oct.array)\n",
    "            filteredtides['timerange'] = Oct\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Nov':\n",
    "            Nov = localtides.drop(localtides[localtides.month != 11])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Nov.array)\n",
    "            filteredtides['timerange'] = Nov\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        elif x == 'Dec':\n",
    "            Dec = localtides.drop(localtides[localtides.month != 12])\n",
    "\n",
    "            ## Filtering modelledtides by nominated timerange\n",
    "            filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Dec.array)\n",
    "            filteredtides['timerange'] = Dec\n",
    "            filteredtides.set_index('timerange', inplace=True)\n",
    "            filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "            filters[str(x)] = filteredtides\n",
    "\n",
    "        else:\n",
    "            print('''\n",
    "            Please select one of the following `time_filter`s: \n",
    "            all_time, day, night, wet, dry, summer, autumn, winter, \n",
    "            spring, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec\n",
    "            ''')\n",
    "    \n",
    "    ## Create wet/dry boolean for each timestep per filter\n",
    "    WetDry = {}\n",
    "    for key in filters:\n",
    "                \n",
    "        ## Boolean mask all modelled timesteps by tideheight relative to NIDEM:\n",
    "        da_list = list(ds.nidem >= filters[str(key)]['tideheights'][timestep] \n",
    "                       for timestep in filters[str(key)].loc[time_start:time_end].index) \n",
    "\n",
    "        index_list = list(timestep for timestep in filters[str(key)][time_start:time_end].index)\n",
    "\n",
    "        ## Store modelled datetimes as a pandas index\n",
    "        index = pd.Index(index_list, name='datetime')\n",
    "\n",
    "        ## Concatenate the arrays on the new dimension 'datetime'\n",
    "        exp_ds = xr.concat(da_list, index)\n",
    "        \n",
    "        WetDry[str(key)] = exp_ds\n",
    "    '''--------------------------------------------'''\n",
    "    ## Calculate the pc exposure per pixel for each filter\n",
    "    ## Build empty xr.ds and append each new da during looping through WetDry\n",
    "    \n",
    "    pxpc2 = ds#.squeeze().reset_coords() ## Copy of NIDEM ds to append exposure results into\n",
    "    \n",
    "    for f in WetDry:\n",
    "    \n",
    "            ## Calculate the mean of the boolean across the datetime axis (equiv. to % True)\n",
    "        pxpc = WetDry[str(f)].mean('datetime')\n",
    "\n",
    "        ## Compute the array from dask\n",
    "#         pxpc = pxpc.compute() #%timeit\n",
    "\n",
    "        ## Name the exposure time array\n",
    "        pxpc = pxpc.rename('Exposure time (%)')\n",
    "\n",
    "        ## Mask out non-intertidal areas\n",
    "        pxpc = pxpc.where(pxpc > 0)\n",
    "        \n",
    "        ## Append filter (f) exposure results into results dataset (pxpc2)\n",
    "        pxpc2[str(f)] = pxpc#.drop('time')\n",
    "\n",
    "#         ## Save exposure results\n",
    "#         pxpc.drop('time').to_netcdf(\"ID\"\n",
    "#                        + str(row.ID)\n",
    "#                        + \"_tidepost_\"\n",
    "#                        + str(tp_y) \n",
    "#                        + '_'\n",
    "#                        + str(tp_x) \n",
    "#                        + \"_pxpc_for_modelledtides20min_\" \n",
    "#                        + str(time_start)\n",
    "#                        + '_to_'\n",
    "#                        + str(time_end)\n",
    "#                        + \"time_filter_\"\n",
    "#                        + str(time_filter)\n",
    "#                        + \".nc\")\n",
    "#         # ## To save the NIDEM dataset to netcdf, need to remove the time dimension\n",
    "#         ds = ds.squeeze()\n",
    "#         ds = ds.reset_coords()\n",
    "#         ds.nidem.to_netcdf(\"ID\" + str(row.ID) +\"_tidepost_\"+str(tp_y) + '_'+ str(tp_x) +'nidem.nc') \n",
    "    pxpc2 = pxpc2.compute()    \n",
    "    \n",
    "    return pxpc2#exp_ds\n",
    "\n",
    "\n",
    "# # # ## TEMP: refresh the modelledtides var\n",
    "# # # modelledtides = pd.read_pickle(\"tidepost_\"+str(tp_y) + '_'+ str(tp_x) + \"_modelledtides_20min.pkl\")\n",
    "\n",
    "# # ## Run function to collect exposure dataset. Set time filter to one of the following:\n",
    "# # '''all_time,\n",
    "# #     day,\n",
    "# #     night,\n",
    "# #     wet, # wet_season\n",
    "# #     dry, # dry_season\n",
    "# #     summer,\n",
    "# #     autumn,\n",
    "# #     winter,\n",
    "# #     spring,\n",
    "# #     Jan,\n",
    "# #     Feb,\n",
    "# #     Mar,\n",
    "# #     Apr,\n",
    "# #     May,\n",
    "# #     Jun,\n",
    "# #     Jul,\n",
    "# #     Aug,\n",
    "# #     Sep,\n",
    "# #     Oct,\n",
    "# #     Nov,\n",
    "# #     Dec'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timezone set to Australia/Queensland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "## Test cell: incoporating solar modelling and reworking time/date filtering\n",
    "\n",
    "## Prototyping the continental workflow\n",
    "time_filter = ['daynight']\n",
    "## Prepare dict to store results\n",
    "ITEMpolygons = {}\n",
    "# Loop through polygons in geodataframe and extract satellite data\n",
    "for index, row in gdf_master.iterrows():\n",
    "    \n",
    "    ## If a desired ITEM polygon is required, set the value here and \n",
    "    ## enable the `break` at the end of this loop\n",
    "    if row.ID == 269: \n",
    "        \n",
    "        \n",
    "        # Extract the feature's geometry as a datacube geometry object\n",
    "        geom = geometry.Geometry(geom=row.geometry, crs=gdf_master.crs)\n",
    "\n",
    "        # Update the query to include our geopolygon\n",
    "        query.update({\"geopolygon\": geom})\n",
    "\n",
    "        ds = dc.load(**query)\n",
    "        ds = ds.where(ds.nidem > ds.nidem.min())\n",
    "\n",
    "        '''-------------------'''\n",
    "        ## Run the exp_model function to generate tide model and exposure dataset\n",
    "        pxpc2 = exp_model(time_start, \n",
    "                           time_end,                        \n",
    "                           time_filter,\n",
    "                           modelled_freq,\n",
    "                           tidepost_lat = row.lat, \n",
    "                           tidepost_lon = row.lon)\n",
    "\n",
    "    #     sun_df, localtides = exp_model(time_start, \n",
    "    #                        time_end,                        \n",
    "    #                        time_filter,\n",
    "    #                        modelled_freq,\n",
    "    #                        tidepost_lat = row.lat, \n",
    "    #                        tidepost_lon = row.lon)\n",
    "\n",
    "        # Save filtered, exposure results (pxpc2) per polyon in results dics\n",
    "        ITEMpolygons[str(row.ID)] = pxpc2\n",
    "        \n",
    "        break\n",
    "        \n",
    "#     ## Stop looping\n",
    "#     if index == 0:\n",
    "#         break\n",
    "        print('Completed polygon: ', row.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'269': <xarray.Dataset>\n",
       " Dimensions:      (time: 1, x: 5354, y: 5577)\n",
       " Coordinates:\n",
       "   * time         (time) datetime64[ns] 2001-07-02\n",
       "   * y            (y) float64 -2.668e+06 -2.668e+06 ... -2.807e+06 -2.807e+06\n",
       "   * x            (x) float64 1.879e+06 1.879e+06 ... 2.013e+06 2.013e+06\n",
       "     spatial_ref  int32 3577\n",
       " Data variables:\n",
       "     nidem        (time, y, x) float32 nan nan nan nan nan ... nan nan nan nan\n",
       "     hightide     (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan\n",
       "     lowtide      (time, y, x) float64 nan nan nan nan nan ... nan nan nan nan\n",
       " Attributes:\n",
       "     crs:           EPSG:3577\n",
       "     grid_mapping:  spatial_ref}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ITEMpolygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITEMpolygons['188'].spring_low.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITEMpolygons['269'].day.plot()\n",
    "\n",
    "#         ## Save exposure results\n",
    "#         pxpc.drop('time').to_netcdf(\"ID\"\n",
    "#                        + str(row.ID)\n",
    "#                        + \"_tidepost_\"\n",
    "#                        + str(tp_y) \n",
    "#                        + '_'\n",
    "#                        + str(tp_x) \n",
    "#                        + \"_pxpc_for_modelledtides20min_\" \n",
    "#                        + str(time_start)\n",
    "#                        + '_to_'\n",
    "#                        + str(time_end)\n",
    "#                        + \"time_filter_\"\n",
    "#                        + str(time_filter)\n",
    "#                        + \".nc\")\n",
    "\n",
    "ITEMpolygons['269'].hightide.drop('time').to_netcdf(\n",
    "                                    'ID'\n",
    "                                   + str(row.ID)\n",
    "                                   + \"_for_modelledtides30min_\" \n",
    "                                   + str(time_start)\n",
    "                                   + '_to_'\n",
    "                                   + str(time_end)\n",
    "                                   + \"time_filter_hightide\"\n",
    "#                                    + str(time_filter)\n",
    "                                   + \".nc\")\n",
    "\n",
    "\n",
    "ITEMpolygons['269'].lowtide.drop('time').to_netcdf(\n",
    "                                    'ID'\n",
    "                                   + str(row.ID)\n",
    "                                   + \"_for_modelledtides30min_\" \n",
    "                                   + str(time_start)\n",
    "                                   + '_to_'\n",
    "                                   + str(time_end)\n",
    "                                   + \"time_filter_lowtide\"\n",
    "#                                    + str(time_filter)\n",
    "                                   + \".nc\")\n",
    "\n",
    "\n",
    "# ITEMpolygons['174'].neap_high.drop('time').to_netcdf(\n",
    "#                                     'ID'\n",
    "#                                    + str(row.ID)\n",
    "#                                    + \"_for_modelledtides30min_\" \n",
    "#                                    + str(time_start)\n",
    "#                                    + '_to_'\n",
    "#                                    + str(time_end)\n",
    "#                                    + \"time_filter_neap_high\"\n",
    "# #                                    + str(time_filter)\n",
    "#                                    + \".nc\")\n",
    "\n",
    "# ITEMpolygons['174'].neap_low.drop('time').to_netcdf(\n",
    "#                                     'ID'\n",
    "#                                    + str(row.ID)\n",
    "#                                    + \"_for_modelledtides30min_\" \n",
    "#                                    + str(time_start)\n",
    "#                                    + '_to_'\n",
    "#                                    + str(time_end)\n",
    "#                                    + \"time_filter_neap_low\"\n",
    "# #                                    + str(time_filter)\n",
    "#                                    + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  269 row:  66\n"
     ]
    }
   ],
   "source": [
    "# gdf_master.set_index('ID', drop=True, inplace=True)\n",
    "# gdf_master.index['269']\n",
    "\n",
    "for index, row in gdf_master[255:275].iterrows():\n",
    "#     if row.ID != 66:\n",
    "#         next\n",
    "    if row.ID == 66: ## If a desired ITEM polygon is required, set the value here and enable the `break` at the end of this loop\n",
    "        \n",
    "        break\n",
    "#         continue\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ITEMpolygons['269'].night.plot()\n",
    "row.ID\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f523f5830f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ITEMpolygons['269'].nidem.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Working day/night code loop\n",
    "\n",
    "lt_df=pd.DataFrame(localtides, columns=['localtides'])\n",
    "\n",
    "dates = []\n",
    "times = []\n",
    "for element in localtides:\n",
    "    d = element.date()\n",
    "    dates.append(d)\n",
    "    \n",
    "    t = element.time()\n",
    "    times.append(t)\n",
    "\n",
    "lt_df['Date'] = dates\n",
    "lt_df['Time'] = times\n",
    "\n",
    "for index,row in sun_df[0:4].iterrows():\n",
    "    \n",
    "    ## Translate the time string from sunriset module into datetime.time\n",
    "    hourday = (int(row['Sunrise hh:mm:ss'].split(':')[0]))\n",
    "    minuteday = (int(row['Sunrise hh:mm:ss'].split(':')[1]))\n",
    "    secday = ceil(float(row['Sunrise hh:mm:ss'].split(':')[-1]))\n",
    "    sunrise = datetime.time(hourday, minuteday, secday)\n",
    "    \n",
    "    hournight = (int(row['Sunset hh:mm:ss'].split(':')[0]))\n",
    "    minutenight = (int(row['Sunset hh:mm:ss'].split(':')[1]))\n",
    "    secnight = ceil(float(row['Sunset hh:mm:ss'].split(':')[-1]))\n",
    "    sunset = datetime.time(hournight, minutenight, secnight)\n",
    "    \n",
    "    ## Assign day or night by comparison against sunrise and sunset for the day\n",
    "    conditions = [(lt_df.loc[lt_df['Date'] == index.date()].Time > sunrise) & (lt_df.loc[lt_df['Date'] == index.date()].Time < sunset)]\n",
    "    choices = ['day']\n",
    "    lt_df.loc[(lt_df['Date'] == index.date()), ['daynight']] = np.select(conditions, choices, default='night')\n",
    "\n",
    "    ## Extract day and night arrays to filter localtides against as per other filtering routines\n",
    "    day_df = lt_df[lt_df.daynight == 'day']\n",
    "    night_df = lt_df[lt_df.daynight == 'night']\n",
    "    \n",
    "    ## Return values to DatetimeIndex\n",
    "    day = pd.DatetimeIndex(day_df.localtides)\n",
    "    night = pd.DatetimeIndex(night_df.localtides)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = lt_df[lt_df.daynight == 'day']\n",
    "night_df = lt_df[lt_df.daynight == 'night']\n",
    "\n",
    "## Return values to DatetimeIndex\n",
    "day = pd.DatetimeIndex(day_df.localtides)\n",
    "night = pd.DatetimeIndex(night_df.localtides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-12-01 18:40:00+10:00', '2019-12-01 18:50:00+10:00',\n",
       "               '2019-12-01 19:00:00+10:00', '2019-12-01 19:10:00+10:00',\n",
       "               '2019-12-01 19:20:00+10:00', '2019-12-01 19:30:00+10:00',\n",
       "               '2019-12-01 19:40:00+10:00', '2019-12-01 19:50:00+10:00',\n",
       "               '2019-12-01 20:00:00+10:00', '2019-12-01 20:10:00+10:00',\n",
       "               ...\n",
       "               '2020-12-01 08:30:00+10:00', '2020-12-01 08:40:00+10:00',\n",
       "               '2020-12-01 08:50:00+10:00', '2020-12-01 09:00:00+10:00',\n",
       "               '2020-12-01 09:10:00+10:00', '2020-12-01 09:20:00+10:00',\n",
       "               '2020-12-01 09:30:00+10:00', '2020-12-01 09:40:00+10:00',\n",
       "               '2020-12-01 09:50:00+10:00', '2020-12-01 10:00:00+10:00'],\n",
       "              dtype='datetime64[ns, Australia/Queensland]', name='localtides', length=52413, freq=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_df.index\n",
    "# day\n",
    "night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(night)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localtides</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>daynight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2019-12-03 15:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>15:20:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2019-12-03 15:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2019-12-03 15:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>15:40:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2019-12-03 15:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>15:50:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2019-12-03 16:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2019-12-03 16:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>16:10:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2019-12-03 16:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>16:20:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2019-12-03 16:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2019-12-03 16:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>16:40:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2019-12-03 16:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>16:50:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2019-12-03 17:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2019-12-03 17:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>17:10:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2019-12-03 17:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>17:20:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2019-12-03 17:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2019-12-03 17:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>17:40:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2019-12-03 17:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>17:50:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2019-12-03 18:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2019-12-03 18:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>18:10:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2019-12-03 18:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>18:20:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2019-12-03 18:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2019-12-03 18:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>18:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2019-12-03 18:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>18:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2019-12-03 19:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2019-12-03 19:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>19:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2019-12-03 19:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>19:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2019-12-03 19:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2019-12-03 19:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>19:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2019-12-03 19:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>19:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2019-12-03 20:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2019-12-03 20:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>20:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2019-12-03 20:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>2019-12-03 20:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>20:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2019-12-03 20:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>20:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2019-12-03 20:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>20:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2019-12-03 21:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2019-12-03 21:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>21:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2019-12-03 21:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>21:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2019-12-03 21:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2019-12-03 21:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>21:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2019-12-03 21:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>21:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2019-12-03 22:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2019-12-03 22:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>22:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2019-12-03 22:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2019-12-03 22:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2019-12-03 22:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>22:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2019-12-03 22:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>22:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2019-12-03 23:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2019-12-03 23:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2019-12-03 23:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2019-12-03 23:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2019-12-03 23:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2019-12-03 23:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2019-12-04 00:00:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2019-12-04 00:10:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2019-12-04 00:20:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2019-12-04 00:30:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2019-12-04 00:40:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>00:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2019-12-04 00:50:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>00:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2019-12-04 01:00:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2019-12-04 01:10:00+10:00</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>01:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   localtides        Date      Time daynight\n",
       "320 2019-12-03 15:20:00+10:00  2019-12-03  15:20:00      day\n",
       "321 2019-12-03 15:30:00+10:00  2019-12-03  15:30:00      day\n",
       "322 2019-12-03 15:40:00+10:00  2019-12-03  15:40:00      day\n",
       "323 2019-12-03 15:50:00+10:00  2019-12-03  15:50:00      day\n",
       "324 2019-12-03 16:00:00+10:00  2019-12-03  16:00:00      day\n",
       "325 2019-12-03 16:10:00+10:00  2019-12-03  16:10:00      day\n",
       "326 2019-12-03 16:20:00+10:00  2019-12-03  16:20:00      day\n",
       "327 2019-12-03 16:30:00+10:00  2019-12-03  16:30:00      day\n",
       "328 2019-12-03 16:40:00+10:00  2019-12-03  16:40:00      day\n",
       "329 2019-12-03 16:50:00+10:00  2019-12-03  16:50:00      day\n",
       "330 2019-12-03 17:00:00+10:00  2019-12-03  17:00:00      day\n",
       "331 2019-12-03 17:10:00+10:00  2019-12-03  17:10:00      day\n",
       "332 2019-12-03 17:20:00+10:00  2019-12-03  17:20:00      day\n",
       "333 2019-12-03 17:30:00+10:00  2019-12-03  17:30:00      day\n",
       "334 2019-12-03 17:40:00+10:00  2019-12-03  17:40:00      day\n",
       "335 2019-12-03 17:50:00+10:00  2019-12-03  17:50:00      day\n",
       "336 2019-12-03 18:00:00+10:00  2019-12-03  18:00:00      day\n",
       "337 2019-12-03 18:10:00+10:00  2019-12-03  18:10:00      day\n",
       "338 2019-12-03 18:20:00+10:00  2019-12-03  18:20:00      day\n",
       "339 2019-12-03 18:30:00+10:00  2019-12-03  18:30:00      day\n",
       "340 2019-12-03 18:40:00+10:00  2019-12-03  18:40:00    night\n",
       "341 2019-12-03 18:50:00+10:00  2019-12-03  18:50:00    night\n",
       "342 2019-12-03 19:00:00+10:00  2019-12-03  19:00:00    night\n",
       "343 2019-12-03 19:10:00+10:00  2019-12-03  19:10:00    night\n",
       "344 2019-12-03 19:20:00+10:00  2019-12-03  19:20:00    night\n",
       "345 2019-12-03 19:30:00+10:00  2019-12-03  19:30:00    night\n",
       "346 2019-12-03 19:40:00+10:00  2019-12-03  19:40:00    night\n",
       "347 2019-12-03 19:50:00+10:00  2019-12-03  19:50:00    night\n",
       "348 2019-12-03 20:00:00+10:00  2019-12-03  20:00:00    night\n",
       "349 2019-12-03 20:10:00+10:00  2019-12-03  20:10:00    night\n",
       "350 2019-12-03 20:20:00+10:00  2019-12-03  20:20:00    night\n",
       "351 2019-12-03 20:30:00+10:00  2019-12-03  20:30:00    night\n",
       "352 2019-12-03 20:40:00+10:00  2019-12-03  20:40:00    night\n",
       "353 2019-12-03 20:50:00+10:00  2019-12-03  20:50:00    night\n",
       "354 2019-12-03 21:00:00+10:00  2019-12-03  21:00:00    night\n",
       "355 2019-12-03 21:10:00+10:00  2019-12-03  21:10:00    night\n",
       "356 2019-12-03 21:20:00+10:00  2019-12-03  21:20:00    night\n",
       "357 2019-12-03 21:30:00+10:00  2019-12-03  21:30:00    night\n",
       "358 2019-12-03 21:40:00+10:00  2019-12-03  21:40:00    night\n",
       "359 2019-12-03 21:50:00+10:00  2019-12-03  21:50:00    night\n",
       "360 2019-12-03 22:00:00+10:00  2019-12-03  22:00:00    night\n",
       "361 2019-12-03 22:10:00+10:00  2019-12-03  22:10:00    night\n",
       "362 2019-12-03 22:20:00+10:00  2019-12-03  22:20:00    night\n",
       "363 2019-12-03 22:30:00+10:00  2019-12-03  22:30:00    night\n",
       "364 2019-12-03 22:40:00+10:00  2019-12-03  22:40:00    night\n",
       "365 2019-12-03 22:50:00+10:00  2019-12-03  22:50:00    night\n",
       "366 2019-12-03 23:00:00+10:00  2019-12-03  23:00:00    night\n",
       "367 2019-12-03 23:10:00+10:00  2019-12-03  23:10:00    night\n",
       "368 2019-12-03 23:20:00+10:00  2019-12-03  23:20:00    night\n",
       "369 2019-12-03 23:30:00+10:00  2019-12-03  23:30:00    night\n",
       "370 2019-12-03 23:40:00+10:00  2019-12-03  23:40:00    night\n",
       "371 2019-12-03 23:50:00+10:00  2019-12-03  23:50:00    night\n",
       "372 2019-12-04 00:00:00+10:00  2019-12-04  00:00:00    night\n",
       "373 2019-12-04 00:10:00+10:00  2019-12-04  00:10:00    night\n",
       "374 2019-12-04 00:20:00+10:00  2019-12-04  00:20:00    night\n",
       "375 2019-12-04 00:30:00+10:00  2019-12-04  00:30:00    night\n",
       "376 2019-12-04 00:40:00+10:00  2019-12-04  00:40:00    night\n",
       "377 2019-12-04 00:50:00+10:00  2019-12-04  00:50:00    night\n",
       "378 2019-12-04 01:00:00+10:00  2019-12-04  01:00:00    night\n",
       "379 2019-12-04 01:10:00+10:00  2019-12-04  01:10:00    night"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_df[320:380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "for index,row in sun_df[0:1].iterrows():\n",
    "\n",
    "    hourday = (int(row['Sunrise hh:mm:ss'].split(':')[0]))\n",
    "    minuteday = (int(row['Sunrise hh:mm:ss'].split(':')[1]))\n",
    "#     secday = ceil(float(row['Sunrise hh:mm:ss'].split(':')[-1]))\n",
    "    sunrise = datetime.time(hourday, minuteday)\n",
    "    \n",
    "    hournight = (int(row['Sunset hh:mm:ss'].split(':')[0]))\n",
    "    minutenight = (int(row['Sunset hh:mm:ss'].split(':')[1]))\n",
    "#     secnight = ceil(float(row['Sunset hh:mm:ss'].split(':')[-1]))\n",
    "    sunset = datetime.time(hournight, minutenight)\n",
    "    \n",
    "    print ('Sunrise: ', sunrise)\n",
    "    print ('Sunset: ', sunset)\n",
    "\n",
    "# print(datetime.time(hour,minute,sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lt_df.where(lt_df.Date == index.date()) #& lt_df.where(lt_df.Date == index.date()).Time\n",
    "# test.where(test.Time >= sunrise & test.Time < sunset\n",
    "# a = test.Time >= sunrise\n",
    "# b = test.Time < sunset\n",
    "lt_df.drop(['daynight'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lt_df.where(lt_df.Date == index.date()).Time\n",
    "lt_df['daynight'] = np.where((lt_df.where(lt_df.Date == index.date()).any().Time > sunrise and lt_df.where(lt_df.Date == index.date()).any().Time < sunset), 'day', 'night')\n",
    "# lt_df['daynight'] = np.where(sunrise < lt_df.loc[lt_df['Date'] == index.date()].Time.all() < sunset, 'day', 'night')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lt_df.daynight\n",
    "# print( lt_df.Date.values() == index.date())\n",
    "for r, i in lt_df.loc[lt_df['Date'] == index.date()]:\n",
    "#     print(r)\n",
    "# #     lt_df['daynight'] = np.where(sunrise < lt_df.loc[lt_df['Date'] == index.date()].Time.all() < sunset, 'day', 'night')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daynight.drop(['daynight'], axis=1)\n",
    "test = lt_df.loc[lt_df['Date'] == index.date()]\n",
    "print(type(lt_df))\n",
    "# lt_df['daynight'] = np.where((test.Time.any() < sunset) and (test.Time.any() > sunrise), 'day', 'night')\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/env/lib/python3.6/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localtides</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>daynight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2019-12-03 00:00:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2019-12-03 00:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2019-12-03 00:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2019-12-03 00:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2019-12-03 00:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>00:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2019-12-03 23:10:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:10:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2019-12-03 23:20:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:20:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2019-12-03 23:30:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2019-12-03 23:40:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:40:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2019-12-03 23:50:00+10:00</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>23:50:00</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   localtides        Date      Time daynight\n",
       "228 2019-12-03 00:00:00+10:00  2019-12-03  00:00:00    night\n",
       "229 2019-12-03 00:10:00+10:00  2019-12-03  00:10:00    night\n",
       "230 2019-12-03 00:20:00+10:00  2019-12-03  00:20:00    night\n",
       "231 2019-12-03 00:30:00+10:00  2019-12-03  00:30:00    night\n",
       "232 2019-12-03 00:40:00+10:00  2019-12-03  00:40:00    night\n",
       "..                        ...         ...       ...      ...\n",
       "367 2019-12-03 23:10:00+10:00  2019-12-03  23:10:00    night\n",
       "368 2019-12-03 23:20:00+10:00  2019-12-03  23:20:00    night\n",
       "369 2019-12-03 23:30:00+10:00  2019-12-03  23:30:00    night\n",
       "370 2019-12-03 23:40:00+10:00  2019-12-03  23:40:00    night\n",
       "371 2019-12-03 23:50:00+10:00  2019-12-03  23:50:00    night\n",
       "\n",
       "[144 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltdaynight_df = pd.DataFrame()\n",
    "# daynight.drop(['daynight'], axis=1)\n",
    "daynight = lt_df.loc[lt_df['Date'] == index.date()]\n",
    "\n",
    "conditions = [(daynight['Date'] == index.date()) & (daynight.Time > sunrise) & (daynight.Time < sunset),\n",
    "              (daynight['Date'] == index.date()) ]\n",
    "choices = ['day', 'night']\n",
    "\n",
    "# daynight.loc[:,('daynight')] = np.select(conditions, choices)\n",
    "lt_df= np.select(conditions, choices)\n",
    "\n",
    "ltdaynight_df = pd.concat([ltdaynight_df, daynight])\n",
    "# daynight\n",
    "ltdaynight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sunrise)\n",
    "print(sunset)\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df = pd.concat([test_df, test])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type(localtides)#.date()\n",
    "# for date in localtides:\n",
    "#     print(type(date.date()))\n",
    "# sun_df[0:1]\n",
    "# localtides[0:10]\n",
    "\n",
    "test = []\n",
    "for val in localtides[0:1000]:\n",
    "    if val.date() == pd.to_datetime('2019-12-01').date():\n",
    "        test.append(val)\n",
    "#     print(val.date())\n",
    "print(test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = localtides.where(localtides.date() == pd.to_datetime('2019-12-01').date())\n",
    "localtides.isin([pd.to_datetime('2019-12-01').date()])#==localtides.isin([pd.to_datetime('2019-12-01')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.date('2019-12-01')\n",
    "pd.to_datetime('2019-12-01')#.date()\n",
    "localtides[0:2].isin([pd.to_datetime('2019-12-01')])\n",
    "# test = localtides.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test cell\n",
    "# import datetime\n",
    "# start_date = datetime.date(2019,1,1)\n",
    "# start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test cell\n",
    "# datetime.date(s.year, s.month, s.day)\n",
    "# # s.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test cell: solar modelling\n",
    "\n",
    "# ## Prepare data for use in solar modelling function (sunriset)\n",
    "\n",
    "# ## Translate input dates to datetime\n",
    "# format = '%Y-%m-%d %H:%M:%S'\n",
    "# start = pd.to_datetime(time_start, format=format)\n",
    "# end = pd.to_datetime(time_end, format=format)\n",
    "\n",
    "# ## Calculate number of days between input dates\n",
    "# diff = end-start\n",
    "\n",
    "# ## Return difference in years\n",
    "# yearsdiff = diff.days/365\n",
    "\n",
    "# ## Round up to ensure all modelledtide datetimes are captured in solar model\n",
    "# yearsdiff = int(math.ceil(yearsdiff))\n",
    "\n",
    "# ## Identify variables for solar model input\n",
    "# lat = 34.0522 ## from tidepost\n",
    "# long = -118.2437 ## from tidepost\n",
    "# local_tz = -8  ## hardcoded for 3 Austral regions\n",
    "\n",
    "# number_of_years = yearsdiff\n",
    "# start_date = datetime.date(start.year, start.month, start.day) ## from query\n",
    "\n",
    "# ## Model sunrise and sunset\n",
    "# sun_df = sunriset.to_pandas(start_date, lat, long, local_tz, number_of_years)\n",
    "\n",
    "# ## Return sunrise/sunset in hh:mm:ss format (str)\n",
    "# sun_df['Sunrise hh:mm:ss'] = sun_df['Sunrise'].apply(\n",
    "#         lambda numpy_td: str(timedelta(seconds=numpy_td.total_seconds())))\n",
    "# sun_df['Sunset hh:mm:ss'] = sun_df['Sunset'].apply(\n",
    "#         lambda numpy_td: str(timedelta(seconds=numpy_td.total_seconds())))\n",
    "\n",
    "# ## Drop accessory columns\n",
    "# sun_df = sun_df[['Sunrise hh:mm:ss','Sunset hh:mm:ss']]\n",
    "\n",
    "# ## Set the index as a datetimeindex to match the modelledtide df\n",
    "# sun_df = sun_df.set_index(pd.DatetimeIndex(sun_df.index))\n",
    " \n",
    "# # sun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tidal_stats(\n",
    "#                 start=time_start,\n",
    "#                 end=time_end,\n",
    "#                 tidepost_lat=None,\n",
    "#                 tidepost_lon=None,\n",
    "#                 modelled_freq=modelled_freq,\n",
    "#                 round_stats=3): \n",
    "#     \"\"\"\n",
    "#     Takes an xarray.Dataset and statistically compares the tides \n",
    "#     modelled for each satellite observation against the full modelled \n",
    "#     tidal range. This comparison can be used to evaluate whether the \n",
    "#     tides observed by satellites (e.g. Landsat) are biased compared to \n",
    "#     the natural tidal range (e.g. fail to observe either the highest or \n",
    "#     lowest tides etc).    \n",
    "       \n",
    "#     By default, the function models tides for the centroid of the \n",
    "#     dataset, but a custom tidal modelling location can be specified \n",
    "#     using `tidepost_lat` and `tidepost_lon`.\n",
    "    \n",
    "#     Tides are modelled using the OTPS tidal modelling software based on\n",
    "#     the TPXO8 tidal model: http://volkov.oce.orst.edu/tides/tpxo8_atlas.html\n",
    "    \n",
    "#     For more information about the tidal statistics computed by this \n",
    "#     function, refer to Figure 8 in Bishop-Taylor et al. 2018:\n",
    "#     https://www.sciencedirect.com/science/article/pii/S0272771418308783#fig8\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------     \n",
    "#     ds : xarray.Dataset\n",
    "#         An xarray.Dataset object with x, y and time dimensions  \n",
    "#     tidepost_lat, tidepost_lon : float or int, optional\n",
    "#         Optional coordinates used to model tides. The default is None,\n",
    "#         which uses the centroid of the dataset as the tide modelling \n",
    "#         location.\n",
    "#     plot : bool, optional\n",
    "#         An optional boolean indicating whether to plot how satellite-\n",
    "#         observed tide heights compare against the full tidal range. \n",
    "#         Defaults to True.\n",
    "#     modelled_freq : str, optional\n",
    "#         An optional string giving the frequency at which to model tides \n",
    "#         when computing the full modelled tidal range. Defaults to '2h', \n",
    "#         which computes a tide height for every two hours across the\n",
    "#         temporal extent of `ds`.        \n",
    "#     round_stats : int, optional\n",
    "#         The number of decimal places used to round the output statistics.\n",
    "#         Defaults to 3.\n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#     TODO\n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "#     # Generate range of times covering entire period of satellite record\n",
    "#     all_timerange = pd.date_range(start=start,\n",
    "#                                   end=end,\n",
    "#                                   freq=modelled_freq)\n",
    "#     all_datetimes = all_timerange.values.astype('M8[s]').astype('O').tolist()  \n",
    "\n",
    "#     # Use the tidal model to compute tide heights for each observation:  \n",
    "#     all_timepoints = [TimePoint(tidepost_lon, tidepost_lat, dt) \n",
    "#                       for dt in all_datetimes]\n",
    "#     all_predictedtides = predict_tide(all_timepoints)   \n",
    "#     all_tideheights = [predictedtide.tide_m for predictedtide \n",
    "#                         in all_predictedtides]\n",
    "\n",
    "#     return all_timerange, all_tideheights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ##### Build a list of DataArrays to concat\n",
    "\n",
    "# def exp_model(time_start, time_end, modelledtides, time_filter, tidepost_lat, tidepost_lon):\n",
    "    \n",
    "#     '''\n",
    "#     For each modelled timestep in modelledtides,\n",
    "#     mask NIDEM for the associated tideheight.\n",
    "#     Save the lists of timesteps and masked arrays\n",
    "#     and concatenate to join all arrays on the new\n",
    "#     dimension 'datetime'\n",
    "    \n",
    "#     Time filtering (`time_filter`) options for exposure mapping routine are:\n",
    "#     all_time,\n",
    "#     day,\n",
    "#     night,\n",
    "#     wet,\n",
    "#     dry,\n",
    "#     summer,\n",
    "#     autumn,\n",
    "#     winter,\n",
    "#     spring,\n",
    "#     Jan,\n",
    "#     Feb,\n",
    "#     Mar,\n",
    "#     Apr,\n",
    "#     May,\n",
    "#     Jun,\n",
    "#     Jul,\n",
    "#     Aug,\n",
    "#     Sep,\n",
    "#     Oct,\n",
    "#     Nov,\n",
    "#     Dec\n",
    "    \n",
    "#     Use one of the following strings to match your tidepost to set the appropriate `timezone`\n",
    "#     UTC       =  pytz.UTC ## Coordinated Universal Time\n",
    "#     UTC + 8   = 'Australia/West'\n",
    "\n",
    "#     UTC + 9.5 = 'Australia/North'\n",
    "#                 'Australia/South'\n",
    "\n",
    "#     UTC + 10  = 'Australia/Queensland'\n",
    "#                 'Australia/NSW'\n",
    "#                 'Australia/Victoria'\n",
    "#                 'Australia/Tasmania'\n",
    "#     '''\n",
    "#     ## Automate timezone selection based on location of tidepost\n",
    "#     ## State boundary coords from https://www.ga.gov.au/scientific-topics/national-location-information/dimensions/border-lengths\n",
    "#     if tidepost_lon <= 129.0:\n",
    "#         timezone = 'Australia/West'\n",
    "#     elif (tidepost_lon > 129.0) & (tidepost_lon <= 138.0) & (tidepost_lat < 26.0):\n",
    "#         timezone = 'Australia/North'\n",
    "#     elif (tidepost_lon > 129.0) & (tidepost_lon <= 141.0) & (tidepost_lat > 26.0):\n",
    "#         timezone = 'Australia/South'\n",
    "#     elif (tidepost_lon > 138.0) & (tidepost_lat < 26.0):\n",
    "#         timezone = 'Australia/Queensland'\n",
    "#     elif (tidepost_lon > 141.0) & (tidepost_lat >= 26.0):\n",
    "#         timezone = 'Australia/NSW'\n",
    "#     else:\n",
    "#         print('Unable to assign timezone from supplied tidepost coords (tidepost_lon and tidepost_lat)')\n",
    "#     print('Timezone set to', timezone)\n",
    "    \n",
    "#     ## Convert time_start and time_end to datetime objects in local timezone\n",
    "#     time_start = pd.to_datetime(time_start, utc=True).tz_convert(timezone)\n",
    "#     time_end = pd.to_datetime(time_end, utc=True).tz_convert(timezone)\n",
    "    \n",
    "#     ## Convert tz-naive to tz-aware (set to UTC to match modelled timestamp input)\n",
    "#     localtides = modelledtides.index.tz_localize(tz=pytz.UTC)\n",
    "\n",
    "#     ## Convert tz-aware index to local timezone\n",
    "#     localtides = localtides.tz_convert(timezone)\n",
    "    \n",
    "#     ## Reset the index of modelledtides to reflect local times\n",
    "#     modelledtides['local_timerange'] = localtides\n",
    "#     modelledtides.set_index('local_timerange', inplace=True)\n",
    "#     modelledtides.drop('timerange', axis=1, inplace=True)\n",
    "    \n",
    "#     ## Create a filteredtides dataframe for the filter of interest\n",
    "#     if time_filter == 'all_time':\n",
    "#         filteredtides = modelledtides\n",
    "        \n",
    "#     elif time_filter == 'night':\n",
    "#         night = localtides.drop(localtides[(localtides.hour == 6) ## Daylight: arbitrarily between 6 am and 5.59 pm\n",
    "#                     |(localtides.hour == 7)\n",
    "#                     |(localtides.hour == 8)\n",
    "#                     |(localtides.hour == 9)\n",
    "#                     |(localtides.hour == 10)\n",
    "#                     |(localtides.hour == 11)\n",
    "#                     |(localtides.hour == 12)\n",
    "#                     |(localtides.hour == 13)\n",
    "#                     |(localtides.hour == 14)\n",
    "#                     |(localtides.hour == 15)\n",
    "#                     |(localtides.hour == 16)\n",
    "#                     |(localtides.hour == 17)\n",
    "#                     ])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in night.array)\n",
    "#         filteredtides['timerange'] = night\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'day':\n",
    "#         day = localtides.drop(localtides[(localtides.hour == 0) ## Nighttime: arbitrarily between 6 pm and 5.59 am\n",
    "#                     |(localtides.hour == 1)\n",
    "#                     |(localtides.hour == 2)\n",
    "#                     |(localtides.hour == 3)\n",
    "#                     |(localtides.hour == 4)\n",
    "#                     |(localtides.hour == 5)\n",
    "#                     |(localtides.hour == 18)\n",
    "#                     |(localtides.hour == 19)\n",
    "#                     |(localtides.hour == 20)\n",
    "#                     |(localtides.hour == 21)\n",
    "#                     |(localtides.hour == 22)\n",
    "#                     |(localtides.hour == 23)\n",
    "#                     ])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in day.array)\n",
    "#         filteredtides['timerange'] = day\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'dry':\n",
    "#         dry = localtides.drop(localtides[(localtides.month == 10) ## Wet season: Oct-Mar\n",
    "#                     |(localtides.month == 11)\n",
    "#                     |(localtides.month == 12)\n",
    "#                     |(localtides.month == 1)\n",
    "#                     |(localtides.month == 2)\n",
    "#                     |(localtides.month == 3)\n",
    "#                     ])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in dry.array)\n",
    "#         filteredtides['timerange'] = dry\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'wet':\n",
    "#         wet = localtides.drop(localtides[(localtides.month == 4) ## Dry season: Apr-Sep\n",
    "#                     |(localtides.month == 5)\n",
    "#                     |(localtides.month == 6)\n",
    "#                     |(localtides.month == 7)\n",
    "#                     |(localtides.month == 8)\n",
    "#                     |(localtides.month == 9)\n",
    "#                     ])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in wet.array)\n",
    "#         filteredtides['timerange'] = wet\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "\n",
    "#     elif time_filter == 'summer':\n",
    "#         summer = localtides.drop(localtides[localtides.quarter != 1])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in summer.array)\n",
    "#         filteredtides['timerange'] = summer\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'autumn':\n",
    "#         autumn = localtides.drop(localtides[localtides.quarter != 2])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in autumn.array)\n",
    "#         filteredtides['timerange'] = autumn\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'winter':\n",
    "#         autumn = localtides.drop(localtides[localtides.quarter != 3])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in winter.array)\n",
    "#         filteredtides['timerange'] = winter\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'spring':\n",
    "#         spring = localtides.drop(localtides[localtides.quarter != 4])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in spring.array)\n",
    "#         filteredtides['timerange'] = spring\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Jan':\n",
    "#         Jan = localtides.drop(localtides[localtides.month != 1])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Jan.array)\n",
    "#         filteredtides['timerange'] = Jan\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "    \n",
    "#     elif time_filter == 'Feb':\n",
    "#         Feb = localtides.drop(localtides[localtides.month != 2])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Feb.array)\n",
    "#         filteredtides['timerange'] = Feb\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Mar':\n",
    "#         Mar = localtides.drop(localtides[localtides.month != 3])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Mar.array)\n",
    "#         filteredtides['timerange'] = Mar\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Apr':\n",
    "#         Apr = localtides.drop(localtides[localtides.month != 4])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Apr.array)\n",
    "#         filteredtides['timerange'] = Apr\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'May':\n",
    "#         May = localtides.drop(localtides[localtides.month != 5])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in May.array)\n",
    "#         filteredtides['timerange'] = May\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Jun':\n",
    "#         Jun = localtides.drop(localtides[localtides.month != 6])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Jun.array)\n",
    "#         filteredtides['timerange'] = Jun\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Jul':\n",
    "#         Jul = localtides.drop(localtides[localtides.month != 7])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Jul.array)\n",
    "#         filteredtides['timerange'] = Jul\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Aug':\n",
    "#         Aug = localtides.drop(localtides[localtides.month != 8])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Aug.array)\n",
    "#         filteredtides['timerange'] = Aug\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Sep':\n",
    "#         Sep = localtides.drop(localtides[localtides.month != 9])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Sep.array)\n",
    "#         filteredtides['timerange'] = Sep\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Oct':\n",
    "#         Oct = localtides.drop(localtides[localtides.month != 10])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Oct.array)\n",
    "#         filteredtides['timerange'] = Oct\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Nov':\n",
    "#         Nov = localtides.drop(localtides[localtides.month != 11])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Nov.array)\n",
    "#         filteredtides['timerange'] = Nov\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "        \n",
    "#     elif time_filter == 'Dec':\n",
    "#         Dec = localtides.drop(localtides[localtides.month != 12])\n",
    "        \n",
    "#         ## Filtering modelledtides by nominated timerange\n",
    "#         filteredtides = pd.DataFrame(modelledtides['tideheights'][timestep] for timestep in Dec.array)\n",
    "#         filteredtides['timerange'] = Dec\n",
    "#         filteredtides.set_index('timerange', inplace=True)\n",
    "#         filteredtides.rename(columns={0:\"tideheights\"}, inplace=True)\n",
    "\n",
    "#     else:\n",
    "#         print('''\n",
    "#         Please select one of the following `time_filter`s: \n",
    "#         all_time, day, night, wet, dry, summer, autumn, winter, \n",
    "#         spring, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec\n",
    "#         ''')\n",
    "        \n",
    "        \n",
    "        \n",
    "#     ## Boolean mask all modelled timesteps by tideheight relative to NIDEM:\n",
    "#     da_list = list(ds.nidem >= filteredtides['tideheights'][timestep] \n",
    "#                    for timestep in filteredtides.loc[time_start:time_end].index) \n",
    "     \n",
    "#     index_list = list(timestep for timestep in filteredtides[time_start:time_end].index)\n",
    "    \n",
    "#     ## Store modelled datetimes as a pandas index\n",
    "#     index = pd.Index(index_list, name='datetime')\n",
    "\n",
    "#     ## Concatenate the arrays on the new dimension 'datetime'\n",
    "#     exp_ds = xr.concat(da_list, index)\n",
    "    \n",
    "#     return exp_ds\n",
    "\n",
    "\n",
    "# # ## TEMP: refresh the modelledtides var\n",
    "# # modelledtides = pd.read_pickle(\"tidepost_\"+str(tp_y) + '_'+ str(tp_x) + \"_modelledtides_20min.pkl\")\n",
    "\n",
    "# ## Run function to collect exposure dataset. Set time filter to one of the following:\n",
    "# '''all_time,\n",
    "#     day,\n",
    "#     night,\n",
    "#     wet,\n",
    "#     dry,\n",
    "#     summer,\n",
    "#     autumn,\n",
    "#     winter,\n",
    "#     spring,\n",
    "#     Jan,\n",
    "#     Feb,\n",
    "#     Mar,\n",
    "#     Apr,\n",
    "#     May,\n",
    "#     Jun,\n",
    "#     Jul,\n",
    "#     Aug,\n",
    "#     Sep,\n",
    "#     Oct,\n",
    "#     Nov,\n",
    "#     Dec'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Prototyping the continental workflow\n",
    "\n",
    "# # Loop through polygons in geodataframe and extract satellite data\n",
    "# for index, row in gdf_master.iterrows():\n",
    "\n",
    "#     # Extract the feature's geometry as a datacube geometry object\n",
    "#     geom = geometry.Geometry(geom=row.geometry, crs=gdf_master.crs)\n",
    "\n",
    "#     # Update the query to include our geopolygon\n",
    "#     query.update({\"geopolygon\": geom})\n",
    "\n",
    "#     ds = dc.load(**query)\n",
    "#     ds = ds.where(ds.nidem > ds.nidem.min())\n",
    "    \n",
    "#     '''-------------------'''\n",
    "#     ## run tidal model for polygon\n",
    "#         ## tidepost coords for polygon\n",
    "#     tp_x = row.lon\n",
    "#     tp_y = row.lat\n",
    "    \n",
    "#     ## Run tidal model function\n",
    "#     all_timerange, all_tideheights = tidal_stats(tidepost_lat = tp_y,\n",
    "#                                              tidepost_lon = tp_x)\n",
    "#     ## Save modelled tides as dataframe\n",
    "#         ## Firstly convert the dates to series\n",
    "#     all_timerange = all_timerange.to_series()\n",
    "#         ## Save dates and tideheights to pd.DataFrame\n",
    "#     modelledtides = pd.DataFrame(data={'timerange': all_timerange,\n",
    "#                        'tideheights': all_tideheights})\n",
    "#     '''-------------------'''\n",
    "#     ## Run the exp_model function to generate the exposure dataset\n",
    "#     exp_ds = exp_model(time_start, \n",
    "#                        time_end, \n",
    "#                        modelledtides, \n",
    "#                        time_filter = time_filter, \n",
    "#                        tidepost_lat = tp_y, \n",
    "#                        tidepost_lon = tp_x) \n",
    "    \n",
    "\n",
    "#     ## Calculate the mean of the boolean across the datetime axis (equiv. to % True)\n",
    "#     pxpc = exp_ds.mean('datetime')\n",
    "\n",
    "#     ## Compute the array from dask\n",
    "#     pxpc = pxpc.compute() #%timeit\n",
    "\n",
    "#     ## Name the exposure time array\n",
    "#     pxpc = pxpc.rename('Exposure time (%)')\n",
    "\n",
    "#     ## Mask out non-intertidal areas\n",
    "#     pxpc = pxpc.where(pxpc > 0)\n",
    "    \n",
    "#     ## Save exposure results\n",
    "#     pxpc.drop('time').to_netcdf(\"ID\"\n",
    "#                    + str(row.ID)\n",
    "#                    + \"_tidepost_\"\n",
    "#                    + str(tp_y) \n",
    "#                    + '_'\n",
    "#                    + str(tp_x) \n",
    "#                    + \"_pxpc_for_modelledtides20min_\" \n",
    "#                    + str(time_start)\n",
    "#                    + '_to_'\n",
    "#                    + str(time_end)\n",
    "#                    + \"time_filter_\"\n",
    "#                    + str(time_filter)\n",
    "#                    + \".nc\")\n",
    "#     # ## To save the NIDEM dataset to netcdf, need to remove the time dimension\n",
    "#     ds = ds.squeeze()\n",
    "#     ds = ds.reset_coords()\n",
    "#     ds.nidem.to_netcdf(\"ID\" + str(row.ID) +\"_tidepost_\"+str(tp_y) + '_'+ str(tp_x) +'nidem.nc') \n",
    "    \n",
    "#     ## Stop looping\n",
    "#     if index == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxpc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.nidem.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# pxpc vs ds.nidem\n",
    "plt.scatter(x=pxpc, y=ds.nidem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Save exposure results\n",
    "pxpc.drop('time').to_netcdf(\"ID\"\n",
    "               + str(row.ID)\n",
    "               + \"_tidepost_\"\n",
    "               + str(tp_y) \n",
    "               + '_'\n",
    "               + str(tp_x) \n",
    "               + \"_pxpc_for_modelledtides20min_\" \n",
    "               + str(time_start)\n",
    "               + '_to_'\n",
    "               + str(time_end)\n",
    "               + \"time_filter_\"\n",
    "               + str(time_filter)\n",
    "               + \".nc\")\n",
    "# ## To save the NIDEM dataset to netcdf, need to remove the time dimension\n",
    "ds = ds.squeeze()\n",
    "ds = ds.reset_coords()\n",
    "ds.nidem.to_netcdf(\"ID\" + str(row.ID) +\"_tidepost_\"+str(tp_y) + '_'+ str(tp_x) +'nidem.nc') \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.ausmarinescience.com/marine-science-basics/tides/\n",
    "https://tidesandcurrents.noaa.gov/about_harmonic_constituents.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEMpolygons#['0']['Jan'].compute()\n",
    "# for key in ITEMpolygons:\n",
    "#     for f in ITEMpolygons[key]:\n",
    "#         print(key, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ITEMpolygons['0'])\n",
    "# ds\n",
    "ITEMpolygons['1']['Jan'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEMpolygons['1']['Jan'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
