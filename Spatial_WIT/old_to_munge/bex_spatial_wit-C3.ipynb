{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial display for Wetlands Insight Tool results <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatibility:** Notebook currently compatible with only the `NCI VDI` environment\n",
    "\n",
    "\n",
    "* **Special requirements:** \n",
    "    * If running on the [NCI](https://nci.org.au/), ensure that `module load dea` is   run prior to launching this notebook\n",
    "    * Check you have the latest version of the `wit_tooling package` by \n",
    "      copying and pasting the following code into a cell below and running the cell\n",
    "    `!pip install --user git+git://github.com/GeoscienceAustralia/wit_tooling`\n",
    "      \n",
    "      \n",
    "* **Products used:** \n",
    "    * Collection 2 Landsat Surface Reflectance: \n",
    "    [ls5_nbart_albers](https://explorer.dea.ga.gov.au/ls5_nbart_albers),\n",
    "    [ls7_nbart_albers](https://explorer.dea.ga.gov.au/ls7_nbart_albers),\n",
    "    [ls8_nbart_albers](https://explorer.dea.ga.gov.au/ls8_nbart_albers)\n",
    "    * Collection 2 Landsat Fractional Cover, \n",
    "    generated using the Joint Remote Sensing Research Program algorithm: \n",
    "    [ls5_fc_albers](https://explorer.dea.ga.gov.au/ls5_fc_albers),\n",
    "    [ls7_fc_albers](https://explorer.dea.ga.gov.au/ls7_fc_albers),\n",
    "    [ls8_fc_albers](https://explorer.dea.ga.gov.au/ls8_fc_albers)\n",
    "    * Water Observations from Space, \n",
    "    generated using the Geoscience Australia Algorithm:\n",
    "    [wofs_albers](https://explorer.sandbox.dea.ga.gov.au/wofs_albers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The Spatial Wetlands Insight Tool is a tool in development to display the coverage of water, \"wetness\" and vegetation fractional cover in a wetland spatially. It is generated off existing Wetlands Insight Tool temporal runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook uses an existing Wetlands Insight Tool temporal plot, \n",
    "generated from an existing WIT run, to create a spatial plot of water, \"wetness\", green/photosynthetic vegetation, dry/non-photosynthetic vegetation, and bare soil for a chosen observation date. \n",
    "\n",
    "1. First we load the existing WIT data from either: \n",
    "    * a saved csv location\n",
    "    * a shapefile to retrieve the existing WIT data from the database of previous runs\n",
    "    * a csv from an Amazon s3 data bucket\n",
    "2. Then we choose a time of interest to plot Spatial WIT\n",
    "3. Finally we output Spatial WIT to a file for each cover type\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements - A checklist to remind us if we tick all the boxes\n",
    "---------------------\n",
    "- [ ] Make a nice plot to select a time/ period of interest\n",
    "- [ ] Run WIT on a per-pixel basis\n",
    "- [ ] Return Water/Wet/FC percentage per pixel\n",
    "- [ ] Plot and output WIT spatially, with FC percentage represented as an alpha % for the colour\n",
    "- [ ] Output the results as a ArcGIS-compliant Geotiff (uint8), with the shapefile name and the date in the filename\n",
    "***\n",
    "\n",
    "Functions \n",
    "---------\n",
    "`bokeh wit plot`\n",
    "to do a stack plot of wit data with bokeh\n",
    "\n",
    "input: DataFrame\n",
    "\n",
    "output: stack plot of wit data\n",
    "\n",
    "`load_wit_data(**kwargs)` to load data\n",
    "\n",
    "input: csv file or poly_id in database\n",
    "\n",
    "output: DataFrame\n",
    "\n",
    "`load_wofs_fc(query)` to load the data \n",
    "\n",
    "input: a query dictionary with time and geometry\n",
    "\n",
    "output: an xarray with water/wet/FC percentage\n",
    "\n",
    "`plot_spatial_wit(input_pixels_array)` to plot spatially\n",
    "\n",
    "input: an xarray with water/wet/FC percentage\n",
    "\n",
    "output: 2 dimensional plot of input\n",
    "\n",
    "`write_geotiff(input_pixels_array, file_name)` to output to file\n",
    "\n",
    "input: an xarray with water/wet/FC percentage\n",
    "\n",
    "a string as file name\n",
    "\n",
    "output: a geotiff file with input file name\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook:\n",
    "-----------------------------\n",
    "* Follow the instructions under `Special Requirements` above to load `dea` and install `wit_tooling`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wit_tooling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e06fd6d47d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwit_tooling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_wit_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_timeslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_shape_to_polygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_raster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wit_tooling'"
     ]
    }
   ],
   "source": [
    "# import all the necessary packages in this cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import fiona\n",
    "import yaml\n",
    "from datacube import Datacube\n",
    "from datacube.utils.cog import write_cog\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook, show, push_notebook\n",
    "from bokeh.layouts import layout, column, row, WidgetBox, gridplot\n",
    "from bokeh.models import (CheckboxGroup, Select,  CategoricalColorMapper, ColumnDataSource,HoverTool, Label,\n",
    "                          SingleIntervalTicker, Slider, DatetimeTickFormatter, YearsTicker, Legend, TapTool,\n",
    "                          CustomJS, LegendItem, field, Range1d)\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.models.tickers import DatetimeTicker\n",
    "from bokeh.models import LinearColorMapper\n",
    "from bokeh.colors import RGB\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "from datacube.virtual.impl import VirtualDatasetBox\n",
    "from datacube.virtual import construct\n",
    "from datacube.utils.geometry import CRS, Geometry\n",
    "from shapely.geometry import mapping, box\n",
    "from enum import Enum\n",
    "import os, sys, urllib, logging\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "from wit_tooling import query_wit_data, load_timeslice, convert_shape_to_polygon, generate_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "stdout_hdlr = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('[%(asctime)s.%(msecs)03d - %(levelname)s] %(message)s')\n",
    "stdout_hdlr.setFormatter(formatter)\n",
    "_LOG.addHandler(stdout_hdlr)\n",
    "_LOG.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "If you are using a shapefile, csv file, or Amazon s3 link to the existing WIT run, \n",
    "the path must be set in the cell below this cell:\n",
    "\n",
    "* `shapefile`: NCI path to shapefile \n",
    "(e.g. `'/g/data1a/r78/DEA_Wetlands/shapefiles/ramsar_wetlands_3577_20190403.shp'`). \n",
    "You must have permissions to the project directory,\n",
    "and the shapefile must be in [Australian Albers EPSG 3577 projection](https://spatialreference.org/ref/epsg/gda94-australian-albers/)\n",
    "* `csv_file`: NCI path to WIT results CSV (e.g. `'/g/data1a/u46/users/ea6141/dea-notebooks/Spatial_WIT/sample_data/Western Port_Western Port_VIC_19.csv'`)\n",
    "* `pd_yaml`: Yaml file necessary to generate WIT \n",
    "e.g. `'/g/data/u46/users/ea6141/wit_tooling/aux/fc_pd.yaml'`). \n",
    "Specifies input datasets.\n",
    "* `s3_url`: Amazon s3 url link to pre-generated WIT csvs folder \n",
    "(e.g. `'https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/Wetlands_Insight_Tool/WIT_v3'`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put global variables in this cell\n",
    "\n",
    "shapefile = '/g/data1a/r78/DEA_Wetlands/shapefiles/ramsar_wetlands_3577_20190403.shp'\n",
    "csv_file = '/g/data1a/u46/users/ea6141/dea-notebooks/Spatial_WIT/sample_data/Western Port_Western Port_VIC_19.csv'\n",
    "pd_yaml = '/g/data/u46/users/ea6141/wit_tooling/aux/fc_pd.yaml'\n",
    "s3_url = 'https://dea-public-data-dev.s3-ap-southeast-2.amazonaws.com/Wetlands_Insight_Tool/WIT_v3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used in this notebook to create, display and export Spatial WIT\n",
    "----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokeh_WIT_plot(WITdata, polyName='provided polygon'):\n",
    "    '''\n",
    "    last modified: May 2020\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    WITdata : xarray data array produced by load_wit_data function\n",
    "    polyName : string\n",
    "               A name for the polygon to identify the plot, optional. Defaults to 'provided polygon' \n",
    "                   \n",
    "    Returns\n",
    "    -------\n",
    "    A bokeh stack plot of the contents of the vector file in water, wet, green, dry and bare. Plot can be zoomed in to select a date. \n",
    "    '''\n",
    "    \n",
    "    #set up color palate for bokeh WIT plot\n",
    "    pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "           sns.xkcd_rgb[\"neon blue\"],\n",
    "           sns.xkcd_rgb[\"grass\"],\n",
    "           sns.xkcd_rgb[\"beige\"],\n",
    "           sns.xkcd_rgb[\"brown\"]]  \n",
    "\n",
    "    #these are tools we want to use in the plot\n",
    "    TOOLS = [\"pan, wheel_zoom, box_zoom, reset, tap, save\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_WIT(spatial_wit_xr):\n",
    "    \"\"\"\n",
    "        plot spatial wit\n",
    "        input:\n",
    "            an xarray of spatial wit\n",
    "        output:\n",
    "            figure from bokeh\n",
    "    \"\"\"\n",
    "    image_list = [spatial_wit_xr[var].data[0] for var in spatial_wit_xr.data_vars]\n",
    "    # all below is to setup the pallete\n",
    "    transparent_white = RGB(255, 255, 255, 0)\n",
    "    colbat_blue = [RGB(3, 10, 167, 1)]\n",
    "    neon_blue = [RGB(4, 217, 255, 1)]\n",
    "    grass_green = [RGB(63, 155, 11, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "    soil_brown = [RGB(96, 70, 15, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "    dry_biege = [RGB(230, 218, 166, t) for t in np.arange(0.1, 1, 0.1) ]\n",
    "    var_colors = [soil_brown, grass_green, dry_biege, neon_blue, colbat_blue]\n",
    "    color_map = [LinearColorMapper([transparent_white]+c, low=0, high=100,\n",
    "                                   nan_color=transparent_white) for c in var_colors]\n",
    "    \n",
    "    # do the image plot\n",
    "    p =figure(plot_width=900, plot_height = 900,\n",
    "             tooltips=[(\"x\", \"$x\"), (\"y\", \"$y\"), (\"value\", \"@image\")])\n",
    "\n",
    "    for i in range(5):\n",
    "        p.image(image=image_list[i:i+1], x=fc_wofs_data.x.data.min(), y=fc_wofs_data.y.data.max(),\n",
    "            dh=(fc_wofs_data.x.data.max() - fc_wofs_data.x.data.min()),\n",
    "            dw=(fc_wofs_data.y.data.max() - fc_wofs_data.y.data.min()),\n",
    "            color_mapper = color_map[i])\n",
    "    # to do\n",
    "    # legend, title, tooltip to show rignt value bla...\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geotiff(spatial_wit_xr, filename):\n",
    "    \"\"\"\n",
    "        save spatial WIT result to geotiffs, each band will be output to individual tiff\n",
    "        input:\n",
    "            an xarray Dataset of spatial WIT\n",
    "        output:\n",
    "            multiple cloud-optimized geotiffs (cogs) on disk\n",
    "    \"\"\"\n",
    "    for var in spatial_wit_xr.data_vars:\n",
    "        \n",
    "        #create file name per band\n",
    "        band_output = file_name + \"_\" + var + \".tif\"\n",
    "        #get spatial attributes from the parent dataset\n",
    "        geotiff_out_wit = spatial_wit_xr[var]\n",
    "        geotiff_out_wit.attrs = spatial_wit_xr.attrs\n",
    "        write_cog(geotiff_out_wit, band_output, blocksize=16)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(wit_df):\n",
    "    \"\"\"\n",
    "        Rename and reindex the input DataFrame\n",
    "        input: \n",
    "            loaded wit data as pandas DataFrame\n",
    "        output:\n",
    "            renamed and reindexed pandas DataFrame\n",
    "    \"\"\"\n",
    "    #give the index a name that reflects that it is time, measured in UTC not AEDT/AEST\n",
    "    wit_df = wit_df.set_index('TIME')\n",
    "    wit_df.index.name = 'utc_time'\n",
    "    #format the index of the dataframe as a date, not as a string\n",
    "    wit_df.index = pd.to_datetime(wit_df.index)\n",
    "    #Rename the columns so they are easier to understand and plot\n",
    "    wit_df = wit_df.rename(columns={\"WATER\" : \"water\", \n",
    "                            \"WET\" : \"wet\",\n",
    "                           \"PV\" : \"green\",\n",
    "                           \"NPV\" : \"dry\",\n",
    "                           \"BS\" : \"bare\"}) \n",
    "    #converting to percentages to make plotting easier\n",
    "    #first convert if not already a percentage\n",
    "    if wit_df.max().max() <=1.0:\n",
    "        wit_df = wit_df*100\n",
    "    #WITdata.head()\n",
    "    return wit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wit_data(**kwargs):\n",
    "    \"\"\"\n",
    "        Load pre-computed wit data from 3 different sources with the given parameter. Source is chosen by the key\n",
    "        in kwargs.\n",
    "        input parameters:\n",
    "            csv = csv_path: csv file path\n",
    "            shape = a shape from shape file\n",
    "            s3_url = url of s3 bucket: s3 bucket path\n",
    "        output:\n",
    "            pandas dataframe of wit data\n",
    "    \"\"\"\n",
    "    if kwargs.get(\"csv\") is not None:\n",
    "        wit_data = pd.read_csv(kwargs['csv'])\n",
    "    elif kwargs.get('shape') is not None:\n",
    "        _, wit_data = query_wit_data(kwargs['shape'])\n",
    "        wit_data = pd.DataFrame(data=wit_data, columns=['TIME', 'BS', 'NPV', 'PV', 'WET', 'WATER'])\n",
    "    elif kwargs.get('s3_url') is not None:\n",
    "        wit_data = pd.read_csv(kwargs['s3_url'], infer_datetime_format=True)\n",
    "    return wit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next three functions are used to load fc and wofs data with give geometry and time\n",
    "def construct_product(product_yaml):\n",
    "    \"\"\"\n",
    "        Construct a virtual product with the given yaml file\n",
    "        input:\n",
    "            product_yaml: the yaml file path\n",
    "        output:\n",
    "            virtual product instance\n",
    "    \"\"\"\n",
    "    with open(product_yaml, 'r') as f:\n",
    "        recipe = yaml.safe_load(f)\n",
    "    fc_product = construct(**recipe)\n",
    "    return fc_product\n",
    "\n",
    "def query_datasets(fc_product, shape, crs, time_range):\n",
    "    \"\"\"\n",
    "        Query the datasets in datacube database with the given shape and time period\n",
    "        input:\n",
    "            fc_product: virtual product instance\n",
    "            shape: a shape from shape file\n",
    "            crs: crs string from shape file\n",
    "            time_range: a tuple of (start_time, end_time)\n",
    "        output:\n",
    "            grouped datasets: VirtualDatasetBox\n",
    "    \"\"\"\n",
    "    dc = Datacube()\n",
    "    query_poly = convert_shape_to_polygon(shape['geometry'])\n",
    "    query_poly = Geometry(mapping(box(*query_poly.bounds)), CRS(crs))\n",
    "    query = {'geopolygon': query_poly, 'time': time_range}\n",
    "    datasets = fc_product.query(dc, **query)\n",
    "    grouped = fc_product.group(datasets, **query)\n",
    "    return grouped\n",
    "\n",
    "def load_wofs_fc(fc_product, grouped, time_slice):\n",
    "    \"\"\"\n",
    "        Load cloud free wofs, TCW and FC data with the given time or a tuple of (start_time, end_time)\n",
    "        input:\n",
    "            fc_product: virtual product instance\n",
    "            grouped: grouped datasets\n",
    "            time_slice: a single time or tuple of (start_time, end_time)\n",
    "        output:\n",
    "            wofs, TCW and FC data: xr.Dataset\n",
    "    \"\"\"\n",
    "    if not (isinstance(time_slice, list) or isinstance(time_slice, tuple)):\n",
    "         time_slice = [time_slice]\n",
    "    to_load = VirtualDatasetBox(grouped.box.loc[time_slice], grouped.geobox,\n",
    "                grouped.load_natively, grouped.product_definitions, grouped.geopolygon)\n",
    "    fc_wofs_data = load_timeslice(fc_product, to_load)\n",
    "    return fc_wofs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_wit(fc_wofs_data, mask):\n",
    "    \"\"\"\n",
    "        Compute spatial wit with wofs, TCW and FC data with the given polygon mask\n",
    "        input:\n",
    "            fc_wofs_data: wofs, TCW and FC data: xr.Dataset\n",
    "            mask: a polygon mask: np.array\n",
    "        output:\n",
    "            spatial wit results: xr.Dataset\n",
    "    \"\"\"\n",
    "    none_water_vars = list(fc_wofs_data.data_vars)[:-1]\n",
    "    water_var = list(fc_wofs_data.data_vars)[-1]\n",
    "    fc_data = fc_wofs_data[none_water_vars].where(fc_wofs_data[water_var] < 1, 0)\n",
    "    tcw_percent = fc_data['TCW'] >= -350\n",
    "    fc_percent = fc_data.drop('TCW').where(~tcw_percent, 0)\n",
    "    fc_wofs_perc = xr.merge([fc_percent, (tcw_percent.astype(\"int\") * 100),\n",
    "                             (fc_wofs_data[water_var].astype(\"int\") * 100)])\n",
    "    fc_wofs_perc = fc_wofs_perc.where(mask == int(shape['id']), -127).astype(\"int16\")\n",
    "    fc_wofs_perc.attrs.update(fc_wofs_data.attrs)\n",
    "    for var in fc_wofs_perc.data_vars:\n",
    "        fc_wofs_perc[var].attrs['nodata'] = -127\n",
    "    return fc_wofs_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main : \n",
    "here we run functions and produce outputs\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load WIT data using one of the methods in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wit data from database with a chosen shape\n",
    "with fiona.open(shapefile) as allshapes:\n",
    "    shape_crs = allshapes.crs_wkt\n",
    "    shape = next(iter(allshapes))\n",
    "    wit_data = load_wit_data(shape=shape)\n",
    "\n",
    "# or load from s3 bucket\n",
    "# s3_filename = 'Kerang%20Wetlands_Hird%20Swamp_VIC_17.csv'\n",
    "# wit_data = load_wit_data(s3_url='/'.join([s3_url, s3_filename]))\n",
    "\n",
    "# or load from local csv\n",
    "# wit_data = load_wit_data(csv=csv_file)\n",
    "\n",
    "wit_data = rename_columns(wit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print some details about the shapefile. \n",
    "#You will have to change this for other shapefiles\n",
    "print(f\"loaded shape id {shape['id']},\\\n",
    " {shape['properties']['RAMSAR_NAM']}, {shape['properties']['WETLAND_NA']}\")\n",
    "wit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#---working on stack plot here ---#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wit_data.index[0].to_datetime64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wit_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITdata = wit_data\n",
    "polyName = \"fixme\"\n",
    "\n",
    "from bokeh.models import ColumnDataSource, HoverTool, TapTool, WheelZoomTool, ResetTool, PointDrawTool, BoxZoomTool, SaveTool\n",
    "from bokeh.events import Tap\n",
    "import datetime\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "\n",
    "#try setting the data source explicitly\n",
    "source = ColumnDataSource(data= WITdata)\n",
    "#timesource =ColumnDataSource(data=WITdata.index) -thinking of making new dataframe just for time for the tap tool\n",
    "\n",
    "#set up color palate for bokeh WIT plot\n",
    "pal = [sns.xkcd_rgb[\"cobalt blue\"],\n",
    "       sns.xkcd_rgb[\"neon blue\"],\n",
    "       sns.xkcd_rgb[\"grass\"],\n",
    "       sns.xkcd_rgb[\"beige\"],\n",
    "       sns.xkcd_rgb[\"brown\"]]  \n",
    "\n",
    "#lets put a title on the plot\n",
    "title =f'Percentage of area dominated by WOfS, Wetness, Fractional Cover for {polyName}'    \n",
    "\n",
    "#attempt to get the hovertool running\n",
    "#turn the hover tool off for the slc-off rectangle as it displays information differently\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#set up the x axis to recognise date and time. Note that you will only see the days when you zoom in.\n",
    "p =figure(plot_width=1200, \n",
    "          plot_height = 400, \n",
    "          x_axis_type='datetime',\n",
    "         title=title, tools=[ResetTool(), BoxZoomTool(dimensions=\"width\")])\n",
    "\n",
    "# Configure a renderer to be used upon hover\n",
    "hover_glyph = p.circle(x='utc_time', source=source,\n",
    "                         size=15, alpha=0,\n",
    "                         hover_fill_color='black', hover_alpha=0.5)\n",
    "\n",
    "hover = HoverTool(names = [\"lineplot\"],\n",
    "                  tooltips = [\n",
    "    (\"observation\", \"$index\"),\n",
    "    (\"date\", \"$x{%d/%m/%Y}\"),\n",
    "    (\"bare\",\"@bare{0.0}%\"),\n",
    "    (\"dry\", \"@dry{0.0}%\"),\n",
    "    (\"green\",\"@green{0.0}%\"),\n",
    "    (\"wet\",\"@wet{0.0}%\"),\n",
    "    (\"water\",\"@water{0.0}%\")],     \n",
    "                formatters=\n",
    "    {\"$x\":\"datetime\"})#,\n",
    "           #       renderers=[hover_glyph]\n",
    "#)\n",
    "\n",
    "\n",
    "#trialling different ways of getting the tools to work. Both adding tools and including in the figure work.\n",
    "p.add_tools(hover, TapTool(), WheelZoomTool(), SaveTool())\n",
    "\n",
    "\n",
    "p.sizing_mode = \"scale_width\"\n",
    "\n",
    "#align the title in the centre\n",
    "p.title.align= \"center\"\n",
    "p.title.text_font_size=\"12pt\"\n",
    "\n",
    "#label axes\n",
    "p.yaxis.axis_label=(\"percentage of polygon classified as type\")\n",
    "p.yaxis.axis_label_text_font_size=\"8pt\"\n",
    "\n",
    "#we need screen units to put the attribution label under the plot. Don't ask why.\n",
    "label_opts = dict(\n",
    "    x=0, \n",
    "    y=0,\n",
    "    x_units='screen', \n",
    "    y_units='screen',\n",
    "    text_font_style=\"italic\", \n",
    "    text_font_size=\"8.5pt\")\n",
    "\n",
    "#underplot context\n",
    "msg1 = 'The Fractional Cover algorithm developed by the Joint Remote Sensing Research Program\\n\\\n",
    "and the Water Observations from Space algorithm developed by Geoscience Australia are used in the production of this data'\n",
    "caption1 = Label(text=msg1, **label_opts)\n",
    "\n",
    "p.add_layout(caption1, 'below')\n",
    "\n",
    "p.xaxis.formatter=DatetimeTickFormatter(years =[\"%Y\"], months=[\"%m/%Y\"] ,days=[\"%d/%m/%Y\"])\n",
    "p.xaxis.major_label_orientation = 45\n",
    "\n",
    "#create the actual stack plot using data from the pandas dataframe \n",
    "p.varea_stack(['water', \n",
    "              'wet',\n",
    "              'green',\n",
    "              'dry',\n",
    "              'bare'], x= 'utc_time', name = \"stackplot\", color=pal, fill_alpha=0.7, source = source, \n",
    "              legend_label=[\"water\",\"wet\",\"green\",\"dry\",\"bare\"], muted_color=\"grey\", muted_alpha=0.2)\n",
    "\n",
    "#duplicate the stack plot as a line plot in order to get the hover tool working \n",
    "p.vline_stack(['water', \n",
    "              'wet',\n",
    "              'green',\n",
    "              'dry',\n",
    "              'bare'], x= 'utc_time', name=\"lineplot\", color=pal, line_alpha=0.7, source = source,)# active_tap = Instance)???\n",
    "\n",
    "   \n",
    "#set the new WIT graph ranges.\n",
    "left, right, bottom, top = WITdata.index[0], WITdata.index[-1], 0, 100 #set \n",
    "p.x_range=Range1d(left, right)\n",
    "p.y_range=Range1d(bottom, top)\n",
    "p.xaxis.bounds=(left,right)\n",
    "p.yaxis.bounds=(bottom,top)\n",
    "\n",
    "#now we want to overplot the data on the plot\n",
    "#create rectangle borders for no-data times (SLC-off only)\n",
    "LS5_8_gap_start = datetime.datetime(2011,11,1)\n",
    "LS5_8_gap_end = datetime.datetime(2013,4,1)\n",
    "\n",
    "#plot our dead satellite rectangle\n",
    "p.hbar(y=50, \n",
    "       height=100,\n",
    "       left=LS5_8_gap_start, \n",
    "       right=LS5_8_gap_end, \n",
    "       name =\"LS7 SLC-OFF\",\n",
    "       color=\"white\", \n",
    "       alpha=0.5, \n",
    "       hatch_color=\"white\", \n",
    "       hatch_pattern='/',\n",
    "       hatch_alpha=0.6,\n",
    "       line_color=\"white\",\n",
    "       line_width =2,\n",
    "       line_alpha=0.6)\n",
    "\n",
    "p.legend\n",
    "p.legend.location=\"bottom_left\"\n",
    "p.legend.click_policy=\"mute\"\n",
    "p.legend.background_fill_alpha=0.5\n",
    "p.legend.border_line_alpha=0.5\n",
    "p.legend.label_text_font_size=\"9pt\" \n",
    "\n",
    "#reverse the legend \n",
    "p.legend[0].items.reverse()\n",
    "\n",
    "\n",
    "taptool = p.select(type=TapTool)\n",
    "taptool.callback = print(source.selected)\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack plot of wit\n",
    "plot = bokeh_WIT_plot(wit_data)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the location of all the time slices that could potentially be used to calculate Spatial WIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's helpful to get the location of data rather than load them\n",
    "# and it will save you time without querying database multiple times\n",
    "time_range = (wit_data.index.min(), wit_data.index.max())\n",
    "#build a product for our data using the yaml file to specify which datasets we need\n",
    "fc_product = construct_product(pd_yaml)\n",
    "datasets = query_datasets(fc_product, shape, shape_crs, time_range)\n",
    "_LOG.debug(\"Query datasets %s\", datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide which observation in time to plot in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then decide which time slice(s) you want to load\n",
    "# e.g. 1988-02-18 23:13:23.000  in wit_data concerns you\n",
    "time_slice = np.datetime64(wit_data.index[4])\n",
    "_LOG.debug(\"load time slice %s\", time_slice)\n",
    "fc_wofs_data = load_wofs_fc(fc_product, datasets, time_slice)\n",
    "# mask by the geometry of given polygon\n",
    "# first parameter of generate_raster is a tuple of (shape geometry, [integer of shape id])\n",
    "mask = generate_raster([(shape['geometry'], int(shape['id']))], datasets.geobox)\n",
    "fc_wofs_perc = spatial_wit(fc_wofs_data, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spatial WIT\n",
    "plot = plot_spatial_WIT(fc_wofs_perc)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_wofs_perc.PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_wit_xr = fc_wofs_perc\n",
    "image_list = [spatial_wit_xr[var].data[0] for var in spatial_wit_xr.data_vars]\n",
    "# all below is to setup the pallete\n",
    "transparent_white = RGB(255, 255, 255, 0)\n",
    "colbat_blue = [RGB(3, 10, 167, 1)]\n",
    "neon_blue = [RGB(4, 217, 255, 1)]\n",
    "grass_green = [RGB(63, 155, 11, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "soil_brown = [RGB(96, 70, 15, t) for t in np.arange(0.1, 1, 0.1)]\n",
    "dry_biege = [RGB(230, 218, 166, t) for t in np.arange(0.1, 1, 0.1) ]\n",
    "var_colors = [soil_brown, grass_green, dry_biege, neon_blue, colbat_blue]\n",
    "color_map = [LinearColorMapper([transparent_white]+c, low=0, high=100,\n",
    "                               nan_color=transparent_white) for c in var_colors]\n",
    "\n",
    "# do the image plot\n",
    "p =figure(plot_width=900, plot_height = 900,\n",
    "         tooltips = [\n",
    "    (\"x\", \"$x\"),\n",
    "    (\"y\", \"$y\"),\n",
    "    (\"bare\",\"@BS\"),\n",
    "    (\"dry\", \"NPV\"),\n",
    "    (\"green\",\"PV\"),\n",
    "    (\"wet\",\"@wet\"),\n",
    "    (\"water\",\"@water\")], )\n",
    "\n",
    "for i in range(5):\n",
    "    p.image(image=image_list[i:i+1], x=fc_wofs_data.x.data.min(), y=fc_wofs_data.y.data.max(),\n",
    "        dh=(fc_wofs_data.x.data.max() - fc_wofs_data.x.data.min()),\n",
    "        dw=(fc_wofs_data.y.data.max() - fc_wofs_data.y.data.min()),\n",
    "        color_mapper = color_map[i])\n",
    "# to do\n",
    "# legend, \n",
    "#title, \n",
    "#tooltip to show rignt value bla...\n",
    "#arcgis outputs covered\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save spatial WIT as geotiff\n",
    "# each variable will be output to individual COG\n",
    "# file_name works as prefix, the final output file name will be \"file_name_bandname\", e.g. \"test_BS.tif\"\n",
    "file_name = \"test2\"\n",
    "\n",
    "save_geotiff(fc_wofs_perc, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** June 16 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags**: :index:`no_testing`,:index:`NCI compatible`,:index:`landsat 5`, :index:`landsat 7`,  :index:`landsat 8`, :index:`dea_plotting`, :index:`time series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
